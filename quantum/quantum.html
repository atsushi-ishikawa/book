<!DOCTYPE html>
<html  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Introduction</title>
        <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
        <link rel="apple-touch-icon-precomposed" href="images/apple-touch-icon.png">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/uikit/2.26.4/css/uikit.gradient.css">

        <!-- <link rel="stylesheet" href="style.css"> -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <!-- <script src="uikit.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/uikit.js"></script>
        <!-- <script src="scripts.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/scripts.js"></script>
        <!-- <script src="jquery.sticky-kit.js "></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                        <title>Introduction</title>
        <style type="text/css">code{white-space: pre;}</style>
                                                    <script defer=""
                                                    src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
                                                    <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
                                                    </script>
                                                    <link
                                                    rel="stylesheet"
                                                    href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
                               
    </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

                        <div class="uk-grid" data-uk-grid-margin>
                <div class="uk-width-1-1">
                    <h1 class="uk-heading-large">Introduction</h1>
                                                        </div>
            </div>
            
            <div class="uk-grid" data-uk-grid-margin >          
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul>
                                                        <li><a
                                                        href="#basics-in-theoretical-and-computational-methods"
                                                        id="toc-basics-in-theoretical-and-computational-methods">0.
                                                        Basics in
                                                        Theoretical and
                                                        Computational
                                                        Methods</a></li>
                                                        <li><a
                                                        href="#electronic-structure-theory"
                                                        id="toc-electronic-structure-theory">1.
                                                        Electronic
                                                        Structure
                                                        Theory</a>
                                                        <ul>
                                                        <li><a
                                                        href="#wavefunction-based-theory"
                                                        id="toc-wavefunction-based-theory">1-1.
                                                        Wavefunction
                                                        based
                                                        theory</a></li>
                                                        <li><a
                                                        href="#density-functional-theory"
                                                        id="toc-density-functional-theory">1-2.
                                                        Density
                                                        Functional
                                                        Theory</a></li>
                                                        <li><a
                                                        href="#other-topics"
                                                        id="toc-other-topics">1-3.
                                                        Other
                                                        topics</a></li>
                                                        <li><a
                                                        href="#x.-molecular-dynamics"
                                                        id="toc-x.-molecular-dynamics">1-X.
                                                        Molecular
                                                        dynamics</a></li>
                                                        <li><a
                                                        href="#x.-force-field"
                                                        id="toc-x.-force-field">1-X.
                                                        Force
                                                        field</a></li>
                                                        <li><a
                                                        href="#x.-kinetic-monte-carlo"
                                                        id="toc-x.-kinetic-monte-carlo">1-X.
                                                        Kinetic Monte
                                                        Carlo</a></li>
                                                        <li><a
                                                        href="#x.-machine-learning"
                                                        id="toc-x.-machine-learning">1-X.
                                                        Machine-Learning</a></li>
                                                        <li><a
                                                        href="#x.-electronic-structure-analysis-and-catalysis"
                                                        id="toc-x.-electronic-structure-analysis-and-catalysis">1-X.
                                                        Electronic
                                                        Structure
                                                        Analysis and
                                                        Catalysis</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#chemical-kinetics-and-catalytic-activity"
                                                        id="toc-chemical-kinetics-and-catalytic-activity">2.
                                                        Chemical
                                                        Kinetics and
                                                        Catalytic
                                                        Activity</a>
                                                        <ul>
                                                        <li><a
                                                        href="#transition-state-theory"
                                                        id="toc-transition-state-theory">Transition
                                                        state
                                                        theory</a></li>
                                                        <li><a
                                                        href="#statistical-mechanics"
                                                        id="toc-statistical-mechanics">Statistical
                                                        mechanics</a></li>
                                                        <li><a
                                                        href="#the-ideal-gas-rigid-rotor-harmonic-oscillator-approximation"
                                                        id="toc-the-ideal-gas-rigid-rotor-harmonic-oscillator-approximation">The
                                                        ideal gas,
                                                        rigid-rotor
                                                        harmonic-oscillator
                                                        approximation</a></li>
                                                        <li><a
                                                        href="#thermodynamics"
                                                        id="toc-thermodynamics">2-1.
                                                        Thermodynamics</a></li>
                                                        <li><a
                                                        href="#chemical-kinetics"
                                                        id="toc-chemical-kinetics">2-2.
                                                        Chemical
                                                        Kinetics</a></li>
                                                        <li><a
                                                        href="#x.-chemical-process-on-surface"
                                                        id="toc-x.-chemical-process-on-surface">3-X.
                                                        Chemical Process
                                                        on
                                                        Surface</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#theoreticalcomputational-approach-for-reaction-engineering"
                                                        id="toc-theoreticalcomputational-approach-for-reaction-engineering">3.
                                                        Theoretical/Computational
                                                        Approach for
                                                        Reaction
                                                        Engineering</a>
                                                        <ul>
                                                        <li><a
                                                        href="#reactor-and-reaction-engineering"
                                                        id="toc-reactor-and-reaction-engineering">3-1.
                                                        Reactor and
                                                        Reaction
                                                        Engineering</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#theoretical-background-of-electrocatalysis"
                                                        id="toc-theoretical-background-of-electrocatalysis">4.
                                                        Theoretical
                                                        Background of
                                                        Electrocatalysis</a></li>
                                                        <li><a
                                                        href="#modelling-catalytic-systems"
                                                        id="toc-modelling-catalytic-systems">5.
                                                        Modelling
                                                        Catalytic
                                                        Systems</a>
                                                        <ul>
                                                        <li><a
                                                        href="#modeling-heterogeneous-systems"
                                                        id="toc-modeling-heterogeneous-systems">5-1.
                                                        Modeling
                                                        Heterogeneous
                                                        Systems</a></li>
                                                        <li><a
                                                        href="#modeling-homogeneous-systems"
                                                        id="toc-modeling-homogeneous-systems">5-2.
                                                        Modeling
                                                        Homogeneous
                                                        Systems</a></li>
                                                        <li><a
                                                        href="#comparing-experiment-and-computational-results"
                                                        id="toc-comparing-experiment-and-computational-results">5-3.
                                                        Comparing
                                                        Experiment and
                                                        Computational
                                                        Results</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#computational-tools-for-catalytic-chemistry"
                                                        id="toc-computational-tools-for-catalytic-chemistry">6.
                                                        Computational
                                                        Tools for
                                                        Catalytic
                                                        Chemistry</a>
                                                        <ul>
                                                        <li><a
                                                        href="#tools-in-electronic-structure-theory"
                                                        id="toc-tools-in-electronic-structure-theory">6-1.
                                                        Tools in
                                                        Electronic
                                                        Structure
                                                        Theory</a></li>
                                                        <li><a
                                                        href="#tools-in-chemical-kinetics"
                                                        id="toc-tools-in-chemical-kinetics">6-2.
                                                        Tools in
                                                        Chemical
                                                        Kinetics</a></li>
                                                        <li><a
                                                        href="#tools-in-chemical-engineering"
                                                        id="toc-tools-in-chemical-engineering">6-3.
                                                        Tools in
                                                        Chemical
                                                        Engineering</a></li>
                                                        </ul></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">

                    
<ul>
<li><p>Most of the chemical reactions employed in the chemical industry
are performed in the presence of a catalyst. This is because catalysts
are useful in promoting the chemical reaction, and consequently higher
product yield can be expected.</p></li>
<li><p>Another popular usage of catalysts is to convert hazardous waste
into less harmful products. This is often related to the automobiles, as
catalysts are used to convert the harmful nitrogen oxides (NOx), carbon
monooxides (CO), and unburnt hydrocarbons in car exhaust.</p></li>
<li><p>In addition, there is a growing consensus that the world’s
increased demand for fuels and base chemicals will need to be met by
so-called “carbon-neutral” technologies. For example, researchers are
trying to convert the carbon dioxides (CO2) into the useful hydrocarbon
compounds. Catalysts are of great importance for this purpose, meaning
the catalytic science is definitely a key technology for the global
environmental issues.</p></li>
<li><p>Traditionally, the field for catalytic science is divided into
three areas: heterogeneous, homogeneous, and enzyme catalysis.</p></li>
<li><p>Heterogeneous catalysis are present in a phase that is different
from that of the reactants: typically, the reactants are in gas or
liquid phase but the catalyst is a solid material. Thus the reactions
mainly take place at the surface of the solid material.</p></li>
<li><p>Homogeneous catalysts operate in the same phase as the reactants.
This category involves many important reactions in organic chemistry,
where the molecular catalyst such as transition metal complexes work as
catalyst and convert the reactant species into product species. As a
result the homogeneous catalysis plays a significant role in drug
synthesis or polymer science.</p></li>
<li><p>Enzyme catalysts are specialized proteins. The chemically active
part of enzymes is often a tiny part of the protein, and enzyme
catalysis can be viewed as a special kind of heterogeneous catalysis.
Obviously, this field is important in biochemistry or
pharmacology.</p></li>
</ul>
<h1 id="basics-in-theoretical-and-computational-methods">0. Basics in
Theoretical and Computational Methods</h1>
<ul>
<li>The fundamental players in the catalytic science is atoms and
molecules, as the catalysis is the object that is promoting chemical
reactions.</li>
<li>Chemical reactions involve the formation and the breaking of the
chemical bond, and because of this electrons consisting the chemical
bond is also a matter of subject.</li>
<li>Since the behavior of microparticles such as electrons or nucleus is
described the quantum physics, we should start from such area. In other
words, catalytic science (and also surface science) is a research field
at the border between chemistry and physics. Most of the theoretical
methods have been derived either from quantum physics or from condensed
matter physics.</li>
</ul>
<h1 id="electronic-structure-theory">1. Electronic Structure Theory</h1>
<ul>
<li><p>The behavior of the particles is governed by the equation of
motion, and its classical mechanical version is known as the Newton’s
law.</p></li>
<li><p>Since we are interested with microscopic particles like electrons
or atoms, the proper description should be given by the laws of quantum
mechanics.</p></li>
<li><p>For this reason, we need to consider the <strong>Schrödinger
equation</strong>, which is a quantum-mechanical version of the equation
of motion.</p></li>
<li><p>If the solutions of the Schrodinger equations are generated
without reference to experimental data, the methods are usually called
“ab initio” (latin: “from the beginning”) or “first principle”.</p></li>
<li><p>The relativistic version of the Schrödinger equation, known as
<strong>Dirac equation</strong>, provides more accurate description of
microparticles. However, for most of chemistry problems,
non-relativistic Schrödinger equation under the Born-Oppenheimer
approximation is sufficient. This is mainly because the relativistic
effect is large for core electrons but its effect to valence electrons
are smaller. The problems for core electrons and valence electrons can
be separated to each other by introducing pseudopotentials. Thus
researchers often concentrate on the Schrodinger equation for valence
electrons. The details of the pseudopotentials will be discussed in the
later chapters.</p></li>
<li><p>From above reasons, we consider the Schrödinger equation under
following approximations throughout the book;</p>
<ol type="1">
<li>Time-independent.</li>
<li>When only valence electrons are considered, the relativistic effect
is small.</li>
<li>electron and nuclear motions are decoupled.</li>
</ol></li>
<li><p>It is convenient to use the Dirac’s “bra-ket notation” for wave
functions and multi-dimensional integrals in electronic structure theory
in order to simplify the notation. The equivalences are defined as <span
class="math display">
\begin{align*}
\ket{\Psi} \equiv \Psi;&amp;\ \bra{\Psi} \equiv \Psi^{*} \\
\int{\Psi^{*}\Psi d{\bf r}} &amp;= \braket{\Psi|\Psi} \\
\int{\Psi^{*}\hat{H}\Psi d{\bf r}} &amp;= \braket{\Psi|\hat{H}|\Psi}
\end{align*}
</span> The ket <span class="math inline">\ket{m}</span> denotes a wave
function with quantum number <span class="math inline">m</span> standing
to the right of the operator, while the bra <span
class="math inline">\bra{n}</span> denotes a complex conjugate wave
function with quantum number <span class="math inline">n</span> standing
to the left of the operator. The combined braket denotes that the whole
expression should be integrated over all coordinates.</p></li>
</ul>
<h3 id="born-oppenheimer-approximation">Born-Oppenheimer
Approximation</h3>
<ul>
<li>All physical and chemical properties of any system can be derived
from its Hamiltonian.</li>
<li>In this section, we derive the quantum-mechanical Hamiltonian under
the Born-Oppenheimer approximation as this is the basics for the most of
the chemistry problems.</li>
<li>Except for hydrogen and helium, atoms have a mass that is <span
class="math inline">10^4</span> to <span class="math inline">10^5</span>
times heavier than the mass of an electron. Consequently, at the same
kinetic energy, electrons moves <span class="math inline">10^2</span> to
<span class="math inline">10^3</span> times faster than the nuclei.
Hence one supposes that the electrons follow the motion of the nuclei
almost instantaneously.</li>
<li>Since the motion of nucleus is much less than that of electrons, we
can consider the nucleus to be fixed while electrons are moving. Because
of this, we can separate the electrons’ degree of freedom by the
nucleus’ degree of freedom.</li>
<li>The Schrödinger equation for the electrons for a fixed nuclear
coordinate is then <span class="math display">
H_{el}(\left\{ {\bf R} \right\}) \Psi(r, \left\{ {\bf R} \right\}) =
E_{el}(\left\{ {\bf R} \right\}) \Psi(r, \left\{ {\bf R} \right\})
</span></li>
<li>Again, the nuclear coordinates <span class="math inline">\left\{
{\bf R} \right\}</span> are not meant to be variables but parameters
i.e. the R-values does not change when solving the above equation.</li>
<li>From the nucleus side, the electrons’ motion is separated out and
the motion of electron is not explicitly coupled to the nucleus motion.
In other words, for nucleus, the electrons act as the “field” and not
the freely-moving particles.</li>
<li>By using the Born-Oppenheimer approximation, one can make the direct
functional relationship (or “mapping”) between the nuclear coordinates
<span class="math inline">\{{\bf R}\}</span> and the electronic energy
<span class="math inline">E_{el}</span>. It is quite informative to
visualize <span class="math inline">E_{el}(\left\{ {\bf R}
\right\})</span> as the function of {R}, which is often called
<strong>potential energy surface</strong> (Fig.X).</li>
<li>Since the geometry or structures of molecules, bulk materials,
surfaces are all described by their nuclear coordinates, this mapping
provides the relationship between the molecular geometry and the energy.
The energy is related with the stability of the molecules via chemical
bond formation/breaking, thus it is a fundamental property for
discussing the reactivity of the molecules. For this reason, the
property of catalysts can be finally reduced to the atomic or molecular
quantum physics within the Born-Oppenheimer approximation.</li>
<li>For this reason, all the discussions in the following book are based
on the Born-Oppenheimer approximation.</li>
</ul>
<h2 id="wavefunction-based-theory">1-1. Wavefunction based theory</h2>
<ul>
<li><p>Quantum chemical methods usually describe the electrons by a
localized basis set (or basis function) derived from atomic
orbitals.</p></li>
<li><p>Historically, two localized basis set is commonly used; the
Slater type functions <span class="math inline">\exp(-\alpha
r_{iA})</span> or the Gaussian type functions <span
class="math inline">\exp(-\alpha r_{iA}^2)</span>. Here, <span
class="math inline">\alpha</span> is the exponent of the function and
<span class="math inline">r_{iA}</span> is the distance between the
electron <span class="math inline">i</span> and the nucleus <span
class="math inline">A</span>. The Gaussian type function is more often
used because they allow the analytic evaluation of the matrix elements
necessary to perform an electronic structure calculation. The most
popular electronic structure code in this line is the GAUSSIAN program.
However, some code (such as Amsterdam Density Functional package) uses
the Slater type functions in their calculation.</p></li>
<li><p>When the N-body wave function is expressed as the form of the
product of the one-electron functions, it becomes like <span
class="math display">
Hartree-product
</span> This is called the <em>Hartree-product</em>.</p></li>
</ul>
<h3 id="hartree-fock-method">Hartree-Fock method</h3>
<ul>
<li>The Hartree product obeys the Pauli principle only to some extent,
by populating each electronic state once. However, it does not take into
account the anti-symmetry of the wave function.</li>
<li>The Pauli principle requires that the sign of <span
class="math inline">\Psi</span> changes when two electrons are
exchanged.</li>
<li>The simplest ansatz obeying the anti-symmetry requirement is to
replace the product wave function by a single <strong>Slater
determinant</strong>.</li>
<li>The Slater determinant is constructed from the single-particle wave
functions by <span class="math display">
\Psi({\bf r_1, r_2}\cdots {\bf r_N})
= \frac{1}{\sqrt{N!}}
\begin{vmatrix}
\psi_1({\bf r_1}) &amp; \cdots &amp; \psi_1({\bf r_N}) \\
\vdots            &amp; \ddots &amp; \vdots \\
\psi_N({\bf r_1}) &amp; \cdots &amp; \psi_N({\bf r_N}) \\
\end{vmatrix}
</span></li>
<li>Then the expectation value of the total energy becomes <span
class="math display">
\begin{split}
\braket{\Psi|H|\Psi}
&amp;= \sum_{i=1}^N\int d^3r \psi_i^*({\bf r})
\left(-\frac{\hbar^2}{2m}\nabla^2 + v_{ext}({\bf r}) \right) \psi_i({\bf
r}) \\
+&amp; \frac{1}{2}\sum_{i,j=1}^N\int d^3r d^3r&#39;
\frac{e^2}{|r-r&#39;|}
\psi_i^*({\bf r})\psi_i({\bf r})\psi_j^*({\bf r&#39;})\psi_j({\bf
r&#39;}) \\
-&amp; \frac{1}{2}\sum_{i,j=1}^N\int d^3r d^3r&#39;
\frac{e^2}{|r-r&#39;|}
\psi_i^*({\bf r})\psi_i({\bf r&#39;})\psi_j^*({\bf r&#39;})\psi_j({\bf
r}) \\
+&amp; V_{nuc-nuc}
\end{split}
</span></li>
<li>The last term is called <strong>exchange term</strong>.</li>
<li>If we minimize the above expression with respect to the <span
class="math inline">\psi_i^*</span> under the constraint of
normalization, we have <strong>Hartree-Fock equation</strong>. <span
class="math display">
\begin{split}
&amp;\left\{ -\frac{1}{2}\nabla^2 + v_{ext}({\bf r}) + v_H({\bf r})
\right\} \psi_i({\bf r}) \\
&amp; -\sum\int\frac{e^2}{|r-r&#39;|}\psi_j^*({\bf r&#39;})\psi_i({\bf
r&#39;})\psi_j({\bf r}) = \epsilon_i \psi_i({\bf r})
\end{split}
</span></li>
</ul>
<h3 id="electron-correlation">Electron correlation</h3>
<ul>
<li>The Hartree-Fock method generates solutions to the Schrodinger
equation where the real electron-electron interaction is replaced by an
average interaction. In a sufficiently large basis set, the HF wave
function accounts for ~99% of the total energy, but the remaining 1% is
often very important for describing chemical phenomena such as chemical
bond formation or breaking.</li>
<li>The difference in energy between the HF and the lowest possible
energy in the given basis set is called the <em>electron correlation
energy</em>.</li>
<li>Physically, it corresponds to the motion of the electrons being
correlated, i.e. on the average they are further apart than described by
the HF wave function.</li>
<li>The HF method determines the energetically best one-determinant
trial wave function (within the given basis set). It is therefore clear
that, in order to improve on the HF results, the starting point must be
a trial wave function that contains more than one Slater
determinant.</li>
<li>As the HF solution usually gives ~99% of the correct answer,
electron correlation methods normally use the HF wave function as a
starting point for improvements.</li>
</ul>
<h4 id="excited-determinants">Excited determinants</h4>
<ul>
<li>The starting point is usually an restricted Hartree-Fock (RHF)
calculation where a solution of the Roothaan-Hall equations for a system
with <span class="math inline">N_{elec}</span> electrons and <span
class="math inline">M_{basis}</span> basis functions will yield <span
class="math inline">1/2 N_{elec}</span> occupied MOs and <span
class="math inline">M_{basis} - 1/2 N_{elec}</span> unoccupied (virtual)
MOs. Except for a minimal basis, there will always be more virtual than
occupied MOs.</li>
<li>A whole series of determinants may be generated by replacing MOs
that are occupied in the HF determinant by MOs that are unoccupied.
There can be denoted according to how many occupied HF MOs have been
replaced by unoccupied MOs; Slater determinants that are singly, doubly,
triply, quadruply etc., excited relative to the HF determinant, up to a
maximum of <span class="math inline">N_{elec}</span> excited electrons.
These determinants are often referred as singles (S), doubles (D),
triples (T), quadruples (Q), etc.</li>
</ul>
<h4 id="configuration-interaction">Configuration interaction</h4>
<ul>
<li>The trial wave function is written as a linear combination of
determinants with the expansion coefficient determined by requiring that
the energy should be minimum. This procedure is known as
<strong>configuration interaction (CI)</strong>. The MOs used for
building the excited Slater determinants taken from a Hartree-Fock
calculation, and its MO coefficients are held fixed. Subscripts S, D,
etc. indicate determinants that are singly, double, etc. excited
relative to the Hartree-Fock configuration. <span class="math display">
\Psi_{CI} = a_0\Psi_{HF} + \sum_{S}a_S\Psi_S + \sum_{D}a_D\Psi_D +
\cdots = \sum_{i=0}a_i\Psi_i
</span></li>
<li>The coefficients <span class="math inline">a_i</span> is determined
by solving the CI secular equations. Solving the secular equation is
equivalent to diagonalization.</li>
</ul>
<h4 id="mcscf">MCSCF</h4>
<ul>
<li>The <strong>multi-configurational self-consistent field
(MCSCF)</strong> method can be considered as a CI where not only are the
coefficients in front of the determinants but the MOs used for
constructing the determinants are also optimized.</li>
<li>The MCSCF optimization is iterative like the SCF procedure.</li>
<li>The major problem with the MCSCF method is selecting which electron
configurations are necessary for the property of interest. One of the
most popular approaches is the <em>complete active space self-consistent
field (CASSCF)</em> method.</li>
<li>Here the selection of configurations is done by partitioning the MOs
into active and inactive spaces (Fig.X). The active MOs will typically
be some of the highest occupied and some of the lowest unoccupied MOs
from a RHF calculation.</li>
<li>The inactive MOs have either 2 or 0 electrons, i.e. always either
doubly occupied or empty.</li>
<li>Within the active MOs a full CI is performed and all the proper
symmetry-adapted configurations are included in the MCSCF
optimization.</li>
<li>Which MOs to include in the active space must be decided manually,
by considering the problem at hand and the computational expense.</li>
</ul>
<h4 id="moller-plesset-perturbation-theory">Moller-Plesset perturbation
theory</h4>
<ul>
<li>The idea in the perturbation methods is that the problem at hand
only differs slightly from a problem that has already been solved
(exactly or approximately). The solution to the given problem should
therefore in some sense be close to the solution to the already known
system. This is described mathematically by defining a Hamiltonian
operator that consists of two parts, a reference and a
perturbation.</li>
<li>Since the solutions to the unperturbed Schrödinger equation generate
a complete set of functions, the unknown first-order correction to the
wave function can be expanded in these functions. This is known as
<strong>Rayleigh-Schrodinger perturbation theory</strong>.</li>
<li>In order to apply the perturbation theory to the calculation of
correlation energy, the unperturbed Hamiltonian must be selected. The
most common choice is to take this as sum over Fock operators; this
method is called <strong>Moller-Plesset perturbation theory</strong>. In
this method, the zeroth-order wave function is the Hartree-Fock
determinant, and the zeroth-order energy is just a sum of MO
energies.</li>
<li>By using the sum of the Fock operator as the zeroth-order
Hamiltonian, the first-order energy correction becomes the (half of)
electron-electron repulsion energy, and the summation of the zeroth- and
first-order energies gives the Hartree-Fock energy. Therefore the
second-order correction to the energy is the first contribution to the
electron correlation energy. This involves a sum over doubly excited
determinants, which is generated by promoting two electrons from
occupied orbital <span class="math inline">i</span> and <span
class="math inline">j</span> to virtual orbitals <span
class="math inline">a</span> and <span class="math inline">b</span>.
<span class="math display">
W_2 = \sum_{i&lt;j}^{occ}\sum_{a&lt;b}^{vir}
          \frac{ \braket{\Psi_0|H&#39;|\Psi_{ij}^{ab}}
                 \braket{\Psi_{ij}^{ab}|H&#39;|\Psi_0} }
                 {E_0-E_{ij}^{ab} }
</span></li>
<li>The matrix elements between the HF and a double excited state are
given by two-electron integrals over MOs. The difference in total energy
between two Slater determinants becomes a difference in MO energies.
Thus the explicit formula for the second-order Moller-Plesset correction
is <span class="math display">
E(MP2) = \sum_{i&lt;j}^{occ}\sum_{a&lt;b}^{vir}
               \frac{ \braket{\phi_i\phi_j|\phi_a\phi_b}
                    - \braket{\phi_i\phi_j|\phi_b\phi_a} }
{\varepsilon_i + \varepsilon_j - \varepsilon_a - \varepsilon_b}
</span></li>
<li>Once the two-electron integrals over MOs are available, the
second-order energy correction can be calculated as a sum over such
integrals.</li>
<li>MP2 typically accounts for 80-90% of the correlation energy, and it
is the most economical method for including electron correlation. In
practical calculations, the MP2 energy for systems with a few hundred
basis functions can be calculated at a cost similar to or less than what
is required for calculating the HF energy. It is also possible to
include the higher order perturbation correction; the n-th order
Moller-Plesset perturbation theory is often denoted as <em>MPn</em>
method, and MP2 to MP4 is used in practical calculations.</li>
<li>One should note that when the reference wave function contains
substantial multi-reference character (e.g. at the bond-dissociation
limit), a perturbation expansion based on a single determination is no
longer valid.</li>
<li>There are now several different implementation for the
multi-reference many-body perturbation theory; the most popular one is
to use the CASSCF as a reference, denoted as the <em>complete
active-space second-order perturbation theory (CASPT2)</em>.</li>
</ul>
<h4 id="coupled-cluster-method">Coupled cluster method</h4>
<ul>
<li>Perturbation methods add all types of corrections (S, D, T, etc.) to
the reference wave function to a given order (2, 3, etc.). The idea in
<strong>coupled cluster</strong> methods is to include all excited
determinants of a given type.</li>
<li>Define an excitation operator as <span class="math display">
T=T_1 + T_2 + T_3 + \cdots + T_{N_{elec}}
</span></li>
<li>The <span class="math inline">T_i</span> operator acting on the HF
reference wave function <span class="math inline">\Psi_o</span>
generates all i-th excited Slater determinants. <span
class="math display">
T_1\Psi_0 = \sum_i^{occ}\sum_j^{vir}t_i^a\Psi_i^a \\
T_2\Psi_0 =
\sum_{i&lt;j}^{occ}\sum_{a&lt;b}^{vir}t_{ij}^{ab}\Psi_{ij}^{ab}
</span></li>
<li>In coupled cluster theory, it is customary to use the terms
<em>amplitudes</em> for the expansion coefficient <span
class="math inline">t</span>.</li>
<li>The coupled cluster wave function is defined as <span
class="math display">
\Psi_{CC} = \exp(T)\Psi_0 \\
\exp(T) = 1 + T + \frac{1}{2}T^2 + \frac{1}{6}T^3 + \cdots =
\sum_{k=0}^{\infty}\frac{1}{k!}T^k
</span></li>
<li>Usually, the <span class="math inline">T</span> operator is
truncated some of the terms. For example, using <span
class="math inline">T=T_1+T_2</span> gives the coupled cluster singles
and doubles (CCSD) method.</li>
<li>Unfortunately, a straightforward application of the variational
principle to the coupled cluster wave function i.e. variational coupled
cluster approach leads a large number of excitation operators, thus it
can be solved only for small systems. Instead, projecting the
Schrodinger equation for the coupled cluster wave function onto the
reference (such as Hartree-Fock) wave function <span
class="math inline">\Psi_0</span> is often done (non-variational coupled
cluster). <span class="math display">
\braket{\Psi_0|H\exp(T)|\Psi_0} = E_{CC}\braket{\Psi_0|\exp(T)\Psi_0}
</span></li>
<li>Expanding out the exponential and using the fact that the
Hamiltonian operator contains only one- and two-electron operators, we
get <span class="math display">
E_{CC} = \braket{\Psi_0|H(1 + T_1 + T_2 + 1/2 T_1^2)|\Psi_0} \\
E_{CC} = \braket{\Psi_0|H|\Psi_0} + \braket{\Psi_0|H|T_1\Psi_0} +
\braket{\Psi_0|H|T_2\Psi_0} + \frac{1}{2}\braket{\Psi|H|T_1^2\Psi_0} \\
E_{CC} = E_0 + \sum_i^{occ}\sum_a^{vir}t_i^a\braket{\Psi_0|H|\Psi_i^a} +
\sum_i^{occ}\sum_a^{vir}(t_{ij}^{ab} + t_i^a t_j^b - t_i^b
t_j^a)\braket{\Psi_0|H|\Psi_{ij}^{ab}}
</span></li>
<li>Then the coupled cluster energy is given by <span
class="math display">
E_{CC} = E_0 + \sum_{i&lt;j}^{occ}\sum_{a&lt;b}^{vir}(t_{ij}^{ab}+t_i^a
t_j^b - t_i^b
t_j^a)(\braket{\phi_i\phi_j|\phi_a\phi_b}-\braket{\phi_i\phi_j|\phi_b\phi_a})
</span> where the equations for amplitude should be solved in an
iterative manner since the parameters enter in an non-linear
fashion.</li>
<li>If all cluster operators up to <span class="math inline">T_N</span>
are included in <span class="math inline">T</span>, all possible excited
determinants are generated and the coupled cluster wave function is
equivalent to full CI. This is, as already stated, impossible for all
but the smallest systems.</li>
<li>The cluster operator must therefore be truncated at some excitation
level. Using <span class="math inline">T = T_1 + T_2</span> gives the
<em>coupled cluster with singles and doubles (CCSD)</em> model, and
<span class="math inline">T = T_1 + T_2 + T_3</span> gives the
<em>coupled cluster with singles, doubles, and triples (CCSDT)</em>.
However, CCSDT is only applicable to small systems.</li>
<li>Instead of including <span class="math inline">T_3</span> in the
cluster operator <span class="math inline">T</span>, the triples
contribution may be evaluated by perturbation theory and added to the
CCSD results. The most commonly such approach is the <em>CCSD(T)</em>
method. In this case, the triples contribution is calculated from the
formula given by MP4, but using the CCSD amplitudes instead of the
perturbation coefficients for the wave function correction.</li>
<li>The CCSD(T) method with reasonable size of the basis set (at least
better than double-zeta plus polarization function) is called <em>golden
standard</em> for quantum chemistry calculations, because usually one
can expect the <em>chemical accuracy</em> (at kcal/mol level accuracy)
with this level.</li>
</ul>
<h2 id="density-functional-theory">1-2. Density Functional Theory</h2>
<!-- Jensen start -->
<ul>
<li>A <em>function</em> is a prescription for producing a number from a
set of <em>variables</em>. A <em>functional</em> is a prescription for
producing a number from a <em>function</em>, which in turn depends on
variables. A wave function and the electron density are thus
<em>functions</em>, while the energy depending on a wave function or an
electron density is a <em>functional</em>. In this book, we will denote
a function depending on a set of variables <span
class="math inline">{\bf x}</span> with <span class="math inline">f({\bf
x})</span>, while a functional depending on a function <span
class="math inline">f</span> is denoted as <span
class="math inline">F[f]</span>.</li>
</ul>
<h3 id="orbital-free-dft">Orbital-free DFT</h3>
<ul>
<li>The electronic energy functional of electron density <span
class="math inline">\rho</span> can be divided into three parts; kinetic
energy functional <span class="math inline">T[\rho]</span>, the
nuclei-electron attraction energy functional <span
class="math inline">E_{ne}[\rho]</span>, and the electron-electron
repulsion energy functional <span
class="math inline">E_{ee}[\rho]</span>.</li>
<li>With reference to the Hartree-Fock theory, <span
class="math inline">E_{ee}[\rho]</span> may be divided into Coulomb and
exchange parts, <span class="math inline">J[\rho]</span> and <span
class="math inline">K[\rho]</span>.</li>
<li>Among these energy functionals, <span
class="math inline">E_{ne}[\rho]</span> and <span
class="math inline">J[\rho]</span> can be interpreted by the classical
electrodynamics, <span class="math display">
E_{ne}[\rho] = -\sum_i^{N_{nuc}}\int\frac{Z_a(R_a)\rho({\bf r})}{|{\bf
R}_a - {\bf r}|}d{\bf r} \\
J[\rho] = \frac{1}{2}\int\int\frac{\rho({\bf r})\rho({\bf
r&#39;})}{|{\bf r} - {\bf r&#39;}|}d{\bf r}d{\bf r&#39;}
</span></li>
<li>Here, the factor of 1/2 in <span class="math inline">J[\rho]</span>
allows the integration to be done over all space fo both <span
class="math inline">{\bf r}</span> and <span class="math inline">{\bf
r&#39;}</span> variables. Unlike these energy components, exchange part
<span class="math inline">K[\rho]</span> can only be interpreted by the
quantum mechanics.</li>
<li>Early attempts of deducing functionals for the kinetic and exchange
energies considered a uniform electrons gas where it may be shown that
<span class="math inline">T[\rho]</span> and <span
class="math inline">K[\rho]</span> are given by <span
class="math display">
T_{TF}[\rho] = C_F \int \rho^{5/3}({\bf r})d{\bf r} \\
K_D[\rho] = -C_X \int \rho^{4/3}({\bf r})d{\bf r} \\
C_F = \frac{3}{10}(3\pi^2)^{2/3}, \ C_X = \frac{3}{4}\left(
\frac{3}{\pi} \right)^{1/3}
</span></li>
<li>The energy functional <span class="math inline">E_{TF}[\rho] =
T_{TF}[\rho] + E_{ne}[\rho] + J[\rho]</span> is known as
<em>Thomas-Fermi theory</em>, while including <span
class="math inline">K_D[\rho]</span> exchange part constitutes the
<em>Thomas-Fermi-Dirac model</em>.</li>
<li>Since <span class="math inline">T[\rho]</span> and <span
class="math inline">K[\rho]</span> functionals are depending directly on
the electron density, these methods are called <em>orbital-free
DFT</em>, as opposed to the Kohn-Sham theory discussed in the next
section.</li>
<li>Unfortunately, the accuracy of the orbital-free DFT is too low to be
of general use.</li>
</ul>
<h3 id="kohn-sham-theory">Kohn-Sham theory</h3>
<ul>
<li>The success of modern DFT method is based on the suggestion by Kohn
and Sham in 1965 that the electron kinetic energy should be calculated
from an auxiliary set of orbitals used for representing the electron
density.</li>
<li>The main drawback in the orbital-free DFT is the poor representation
of the kinetic energy, and the idea in the Kohn-Sham formalism is to
split the kinetic energy functional into two parts, one which can be
calculated exactly, and a small correction term.</li>
<li>Assume for the moment a Hamiltonian operator of the form with <span
class="math inline">0 \le \lambda \le 1</span>. <span
class="math display">
H_{\lambda} = {\bf T} + {\bf V}_{ext}(\lambda) + \lambda {\bf V}_{ee}
</span></li>
<li>The external potential operator <span class="math inline">{\bf
V}_{ext}</span> is equal to <span class="math inline">{\bf
V}_{ee}</span> for <span class="math inline">\lambda = 1</span>, but for
intermediate <span class="math inline">\lambda</span> value it is
assumed that <span class="math inline">{\bf V}_{ext}(\lambda)</span> is
adjusted such that the same density is obtained for <span
class="math inline">\lambda = 1</span> (the real system), for <span
class="math inline">\lambda = 0</span> (a hypothetical system with
non-interaction electrons) and for all intermediate <span
class="math inline">\lambda</span> values.</li>
<li>For the <span class="math inline">\lambda = 0</span> case, the
electrons are non-interacting, and the exact solution to the Schrodinger
equation is given as a Slater determinant composed of molecular orbitals
<span class="math inline">\phi_i</span>. Then the exact kinetic energy
functional is <span class="math display">
T_{KS} = \sum_i^{N_{el}}\braket{\phi_i|-\frac{1}{2}\nabla^2|\phi_i}
</span></li>
<li>The <span class="math inline">\lambda = 1</span> corresponds to
interacting electrons, and Eq.X is therefore only an approximation to
the real kinetic energy.</li>
<li>The key to Kohn-Sham theory is to calculated the kinetic energy
under the assumption of non-interacting electrons (in the sense that the
HF orbitals in the wave function theory).</li>
<li>In reality, the electrons are interacting, and Eq.X does not provide
the total kinetic energy. However, just as HF theory provides ~99% of
the correct answer, the difference between the exact kinetic energy and
that calculated by assuming non-interacting orbitals is small.</li>
<li>The remaining kinetic energy is absorbed into an
exchange-correlation term, and a general DFT energy expression can be
<span class="math display">
E_{DFT}[\rho] = T_{KS}[\rho] + E_{ne}[\rho] + J[\rho] + E_{XC}[\rho]
</span></li>
<li>By equating <span class="math inline">E_{DFT}</span> to the exact
energy, the above expression actually defines <span
class="math inline">E_{XC}</span> i.e. it is the part that remains after
subtraction of the non-interacting kinetic energy, and <span
class="math inline">E_{ee}</span> and <span class="math inline">J</span>
potential energy terms; <span class="math display">
E_{XC}[\rho] = (T[\rho] - T_{KS}[\rho]) + (E_{ee}[\rho] - J[\rho])
</span></li>
<li>The task in developing orbital-free DFT is to derive approximations
to the kinetic, exchange, and correlation energy functionals, while the
corresponding task in Kohn-Sham theory is to derive approximations to
the exchange-correlation energy functional only.</li>
<li>Since the exchange-correlation energy is roughly a factor of 10
smaller than the kinetic energy, the Kohn-Sham theory is much less
sensitive to inaccuracies in the functionals than the orbital-free
DFT.</li>
<li>The division of the electron kinetic energy into two parts, with the
major contribution being equivalent to the Hartree-Fock energy, can be
justified as follows.</li>
</ul>
<h3 id="exchange-correlation-hole">Exchange-correlation hole</h3>
<ul>
<li>Electrons avoid each other owing to their electric charges, and the
energy associated with this repulsion is given classically by the
Coulomb’s law.</li>
<li>Quantum mechanically, however, this repulsion must be modified to
take into account that electrons have spins of 1/2. The Pauli principle
states that two Fermions (particles with half-integer spin) cannot
occupy the same spatial position, or equivalently, that the total wave
function must be antisymmetric upon interchange of any two
particles.</li>
<li>These quantitative considerations can be put into quantitative terms
by probability holes, or specifically exchange and correlation
holes.</li>
<li>To this aim, here we define the <em>one-electron density</em> <span
class="math inline">\rho_1</span> and the <em>electron-pair density</em>
<span class="math inline">\rho_2</span>. The former is <span
class="math display">
\rho_1({\bf r}_1) = N_{el}\int
\Psi^{*}({\bf r}_1; {\bf r}_2, \cdots, {\bf r}_{N_{el}})
\Psi({\bf r}_1; {\bf r}_2, \cdots, {\bf r}_{N_{el}})d{\bf r}_2 \cdots
d{\bf r}_{N_{el}}
</span></li>
<li>Note that the integration is done for <span class="math inline">{\bf
r}_2</span> to <span class="math inline">{\bf r}_{N_{el}}</span>, thus
<span class="math inline">\rho_1</span> is the function of only <span
class="math inline">{\bf r}_1</span>. The integral is the probability of
finding an electron a position <span class="math inline">{\bf
r}_1</span>, and the <span class="math inline">N_{el}</span> prefactor
ensures that the integral value equals the number of electrons.</li>
<li>The electron-pair density is <span class="math display">
\rho_2({\bf r}_1, {\bf r}_2) = N_{el}(N_{el}-1)\int
\Psi^{*}({\bf r}_1, {\bf r}_2; {\bf r}_3, \cdots, {\bf r}_{N_{el}})
\Psi({\bf r}_1, {\bf r}_2; {\bf r}_3, \cdots, {\bf r}_{N_{el}})d{\bf
r}_3 \cdots d{\bf r}_{N_{el}}
</span></li>
<li>Here, the integration is done for <span class="math inline">{\bf
r}_3</span> to <span class="math inline">{\bf r}_{N_{el}}</span> thus
<span class="math inline">\rho_2</span> has two set of variables,
i.e. <span class="math inline">{\bf r}_1</span> and <span
class="math inline">{\bf r}_2</span>. <span
class="math inline">\rho_2</span> means the probability of finding an
electron at position <span class="math inline">{\bf r}_1</span> and
another electron at position <span class="math inline">{\bf r}_2</span>,
and the <span class="math inline">N_{el}(N_{el}-1)</span> prefactor
ensures that <span class="math inline">\rho_2</span> integrates to the
number of electron pairs.</li>
<li>Let us go back to the exchange-correlation hole issue. If electrons
did not have charge or spin, the probability of finding an electron at a
given position would be independent of the position of a second
electron, and <span class="math inline">\rho_2</span> would be given as
a simple product of two <span class="math inline">\rho_1</span>, with a
proper normalization factor. <span class="math display">
\rho_2^{indep}({\bf r}_1, {\bf r}_2) =
\frac{N_{el}-1}{N_{el}}\rho_1({\bf r}_2)\rho_1({\bf r}_2)
= \left( 1-\frac{1}{N_{el}}\right)\rho_1({\bf r}_2)\rho_1({\bf r}_2)
</span></li>
<li>Since electrons have both charge and spin, however, there is a
reduced probability of finding an electron near another electron. We can
write this formally in terms of a conditional probability factor <span
class="math inline">h_{xc}({\bf r}_1, {\bf r}_2)</span> as <span
class="math display">
\rho_2({\bf r}_1, {\bf r}_2) = \rho_1({\bf r}_1)\rho_1({\bf r}_2) +
\rho_1({\bf r}_1)h_{xc}({\bf r}_1, {\bf r}_2)
</span></li>
<li>The reduced probability is called the <em>exchange-correlation
hole</em>, and can be written in terms of <span
class="math inline">\rho_1</span> and <span
class="math inline">\rho_2</span> as <span class="math display">
h_{xc}({\bf r}_1, {\bf r}_2) = \frac{\rho_2({\bf r}_1, {\bf
r}_2)}{\rho_1({\bf r}_1)} - \rho_1({\bf r}_2)
</span></li>
<li>The exchange-correlation hole represents the reduced probability of
finding electron 2 at position <span class="math inline">{\bf
r}_2</span> given that electron 1 is located at <span
class="math inline">{\bf r}_1</span> (see Fig 6.1 of Jensen).</li>
<li>The exchange part of <span class="math inline">h_{xc}</span> is
called the Fermi hole, while the correlation part is the Coulomb
hole.</li>
<li>Since exchange only occurs between electrons of the same spin, the
total hole can also be written in terms of individual spin
contributions. <span class="math display">
h_{xc} = h_x + h_c \\
h_x = h_x^{\alpha\alpha} + h_x^{\beta\beta} \\
h_c = h_c^{\alpha\alpha} + h_c^{\beta\beta} + h_c^{\alpha\beta}
</span></li>
<li>From the definitions of <span class="math inline">\rho_1</span> and
<span class="math inline">\rho_2</span>, it follows that the integral of
<span class="math inline">h_{xc}</span> over <span
class="math inline">{\bf r}_2</span> gives -1; <span
class="math display">
\int h_{xc}({\bf r}_1, {\bf r}_2)d{\bf r}_2 = \int\frac{\rho_2({\bf
r}_1, {\bf r}_2)}{\rho_1({\bf r}_1)}d{\bf r}_1 d{\bf r}_2 - \int
\rho_1({\bf r}_2)d{\bf r}_2
= \frac{N_{el}(N_{el}-1)}{N_{el}} - N_{el} = -1
</span></li>
<li>This means that the Fermi hole integrates to -1 (and always <span
class="math inline">h_x</span> takes negative value). The Fermi hole
describes a static reduction in the probability function corresponding
one-electron. On the other hand, the Coulomb hole takes both positive
and negative values, and it integrates to 0. This means that the Coulomb
hole reduced the probability of finding an electron near the reference
electron but increases the probability of finding it far from the
reference electron.</li>
<li>The exchange-correlation hle is necessary condition that the exact
exchange-correlation functional should satisfy. Therefore this property
is an important guideline in deriving an approximate
exchange-correlation functional, as we will see them in the next
sections.</li>
</ul>
<h3 id="exchange-correlation-functionals">Exchange-correlation
functionals</h3>
<ul>
<li>The difference between various DFT methods is the choice of
functional form in the exchange-correlation (XC) energy.</li>
<li>It can be proven that the XC potential is a unique functional, valid
for all systems.</li>
<li>However, an explicit functional form of this potential has been
elusive, except for special cases such as an uniform electron gas.</li>
<li>XC functionals have a mathematical form containing parameters. There
are two main philosophies for assigning values to these parameters,
either by requiring the functional to fulfill the necessary condition
that the exact functional has to satisfy, or by fitting the parameters
to experimental data. Often, a combination of these two approaches is
needed in practice.</li>
<li>It is possible to separate the XC energy <span
class="math inline">E_{xc}</span> into two parts; a pure exchange energy
<span class="math inline">E_x</span> and a correlation energy <span
class="math inline">E_c</span>, but the current trend is to construct
the two parts in a combined fashion.</li>
</ul>
<h3 id="lda">LDA</h3>
<ul>
<li>In the <em>Local Density Approximation (LDA)</em>, it is assumed
that the electron density can be treated locally as an uniform electron
gas. The exchange energy <span class="math inline">E_x</span> for a
uniform electron gas is given by the Dirac formula, <span
class="math display">
E_x^{LDA}[\rho] = -C_x\int\rho^{4/3}({\bf r})d{\bf r} \\
\epsilon_x^{LDA} = -C_x \rho^{1/3}({\bf r})
</span></li>
<li>In the more general case, where <span
class="math inline">\alpha</span> and <span
class="math inline">\beta</span> densities are not equal, the <em>Local
Spin Density Approximation (LSDA)</em> is used; <span
class="math display">
E_x^{LSDA}[\rho] = -2^{1/3}C_x\int(\rho_{\alpha}^{4/3}({\bf r}) +
\rho_{\beta}^{4/3}({\bf r}))d{\bf r}
</span></li>
<li>The analytical form for the correlation energy of an uniform
electron gas, which is purely dynamical correlation, has been derived in
the high and low density limits. For intermediate densities, the
correlation energy has been determined to a high precision by quantum
Monte Carlo calculation; the resulting functional is known as VWN
functional, named after Vosko, Wilk, and Nasair.</li>
</ul>
<h3 id="gga">GGA</h3>
<ul>
<li>In the <em>Generalized Gradient Approximation (GGA)</em> methods,
the first derivative of the density is included as a variable, and in
addition it is required that the Fermi and Coulomb holes integrate to
the required values of -1 and 0, respectively.</li>
<li>One of the earliest GGA functional was proposed by A. D. Becke as a
correction to the LSDA exchange energy. This is called B88 (Becke, 1988)
exchange functional.</li>
<li>A popular correlation functional at GGA level is LYP functional,
proposed by Lee, Yang, and Parr.</li>
<li>J. P. Perdew and co-workers have proposed several XC functionals
based on removing spurious oscillations in the Taylor-like expansion to
the first-order, and also ensuring that the exchange and correlation
holes integrate to -1 and 0. The resulting functional are PW86
(Perdew-Wang 1986), PW91 (Perdew-Wang 1991), and PBE
(Perdew-Burke-Ernzerhof).</li>
</ul>
<h3 id="meta-gga">meta-GGA</h3>
<ul>
<li>The logical extension of GGA method is to allow the EX functional to
include the variables of higher order derivatives of the electron
density, for example the Laplacian (<span class="math inline">\nabla^2
\rho</span>) as the second-order derivative term.</li>
<li>The same information is actually gained by introducing the orbital
kinetic energy density <span class="math inline">\tau</span>, which is
<span class="math display">
\tau({\bf r}) = \frac{1}{2}\sum_i^{occ}|\nabla \phi_i({\bf r})|^2
</span></li>
<li>and this approach is more often used.</li>
<li>Including of either the Laplacian or the orbital kinetic energy
density <span class="math inline">\tau</span> as a variable leads to
so-called <em>meta-GGA functionals</em>.</li>
</ul>
<h3 id="computational-issue">Computational issue</h3>
<ul>
<li>Once an XC functional has been selected, the computational problem
of the Kohn-Sham DFT is very similar to the Hartree-Fock theory;
determine a set of orthogonal orbitals that minimizes the energy.</li>
<li>The orbital orthogonality constraint may be enforced by the Lagrange
method, where Lagrangian is defined as <span class="math display">
L[\rho] = E_{DFT}[\rho] -
\sum_{ij}^{N_{orb}}\lambda_{ij}\left(\braket{\phi_i|\phi_j}-\delta_{ij}\right)
</span></li>
<li>Requiring the variation of <span class="math inline">L</span> to
vanish provides a set of equations involving an effective one-electron
operator <span class="math inline">h_{KS}</span>, as <span
class="math display">
h_{KS}\phi_i = \sum_j^{N_{orb}}\lambda_{ij}\phi_j \\
h_{KS} = -\frac{1}{2}\nabla^2 + v_{eff} \\
v_{eff} = v_{ne}({\bf r}) + \int\frac{\rho({\bf r}&#39;)}{|{\bf r} -
{\bf r}&#39;|}d{\bf r}&#39; + v_{xc}({\bf r})
</span></li>
<li>The effective potential <span class="math inline">v_{eff}</span>
contain the nuclear-electron contribution <span
class="math inline">v_{ne}</span>, the Coulomb repulsion, and the XC
potential <span class="math inline">v_{xc}</span>. This term is given as
the functional derivative of the XC energy with respect to the density,
as <span class="math display">
\begin{align*}
v_{xc}({\bf r}) &amp;= \frac{\delta E_{xc}[\rho]}{\delta \rho({\bf r})}
\\
&amp;= \epsilon_{xc}[\rho] + \int \rho({\bf r}&#39;)\frac{\delta
\epsilon_{xc}({\bf r}&#39;)}{\delta \rho({\bf r}&#39;)}d{\bf r}&#39;
\end{align*}
</span></li>
<li>By making the matrix of the Lagrange multiplier to be a diagonal
matrix, one obtains the canonical Kohn-Sham equation <span
class="math display">
h_{KS}\phi_i = \epsilon_i \phi_i
</span></li>
<li>Employing an expansion of the Kohn-Sham orbitals <span
class="math inline">\phi_i</span> by atomic basis set gives <span
class="math display">
\phi_i = \sum_{\alpha}^{M_{basis}}C_{\alpha i}\chi_{\alpha}
</span></li>
<li>The variational procedure again leads to a matrix equation in the
atomic orbital basis <span class="math display">
{\bf h}_{KS}{\bf C} = {\bf S}{\bf C}{\bf \epsilon} \\
h_{\alpha\beta} = \braket{\chi_\alpha | h_{KS} | \chi_\beta} \\
S_{\alpha\beta} = \braket{\chi_\alpha | \chi_\beta}
</span></li>
<li>Since <span class="math inline">V_{xc}</span> functional depends on
the integration variable implicitly via <span
class="math inline">\rho</span>, these integrals cannot be evaluated
analytically. For this reason, a numerical integration is often
performed thus we need to set up some grid points.</li>
</ul>
<!-- Jensen end -->
<ul>
<li><p>As stated, the density functional theory (DFT) is the one
approach to solve the Schrodinger equation, which is clearly different
from the wave-function-based methods discussed in the previous chapter.
The fundamental object in the DFT is the electron density, and not the
wave function.</p></li>
<li><p>DFT originated from the work by Llewellyn H. Thomas and Enrico
Fermi in 1927. In this work, using the uniform electron gas as the
model, they proposed the kinetic energy as the functional of electron
density.[Math Proc Camb., 1926, 21, 542–6; ZS f Phys, 1928, 48, 73–9]
This is known as the Thomas-Fermi model.</p></li>
<li><p>The electron density is rather expressed as a sum over
single-particle states <span class="math display">
n({\bf r}) = \sum_{i=1}^N |\psi_i({\bf r})|^2
</span></p></li>
<li><p><strong>The first Hohenberg-Kohn theorem</strong> states that the
ground-state energy from the Schrodinger equation is a unique functional
of the electron density. This theorem states that there exists a
one-to-one mapping between the ground-state wave function and the
ground-state electron density.</p></li>
<li><p><strong>The second Hohenberg-Kohn theorem</strong> states the
electron density that minimizes the energy of the overall functional is
the true electron density corresponding to the full solution of the
Schrödinger equation.</p></li>
<li><p>The energy functional can be written as <span
class="math display">
\begin{split}
E[\left\{ \psi_i\ \right\}]
=&amp; \frac{\hbar^2}{m}\sum\int\psi_i^* \nabla_i^2 \psi_i d^3 r \\
&amp;+ \int V({\bf r})n({\bf r})d^3 r\\
&amp;+ \frac{e^2}{2}\int\int\frac{n({\bf r})n({\bf r}&#39;)}{|{\bf
r}-{\bf r}&#39;|}\\
&amp;+ E_{ion}\\
&amp;+ E_{xc}[\left\{ \psi_i \right\}]
\end{split}
</span> These terms are electron kinetic energy, e-N Coulomb, e-e
Coulomb, N-N Coulomb, and exchange-correlation energy, respectively. We
can write down the term in a simple analytic form, except for the <span
class="math inline">E_{xc}</span>.</p></li>
<li><p>Now we make use of the variational principle for the energy
functional and minimize <span class="math inline">E[n]</span> with
respect to the single particle states under the constraint of
normalization. This procedure is entirely equivalent to the derivation
of the Hartree and the Hartree-Fock equations. By this, we obtain the
<strong>Kohn-Sham equation</strong> <span class="math display">
\left\{ -\frac{\hbar^2}{2m}\nabla^2 + v_{eff}({\bf r}) \right\}
\psi_i({\bf r}) = \epsilon_i \psi_i({\bf r})
</span></p></li>
<li><p>The effective one-electron potential acting on the electrons is
given as <span class="math display">
v_{eff}({\bf r}) = v_{ext}({\bf r}) + v_H({\bf r}) + v_{xc}({\bf r})
</span></p></li>
<li><p><span class="math inline">v_{ext}</span> is the external
potential, which describes the e-N Coulomb interaction. (CHECK)</p></li>
<li><p>The Hartree potential <span class="math display">
v_{H} = e^2 \int d^3r&#39; \frac{n({\bf r&#39;})}{|{\bf r}-{\bf
r&#39;}|}
</span> describes the Coulomb repulsion between the electrons being
considered in one of the Kohn-Sham equations and the total electron
density defined by all the electrons in the problem.</p></li>
<li><p><span class="math inline">v_H</span> includes a so-called self
interaction, which is a problematic issue present in the DFT (but not in
wave-function-based theory). The reason for this is because the electron
we are describing in the Kohn-Sham equation is also part of the total
electron density, thus <span class="math inline">v_H</span> involves the
Coulomb interaction between the electron and itself. The
self-interaction is unphysical, and the correction for it is partially
done with <span class="math inline">v_{xc}</span>. Unfortunately, the
perfect solution to the self-interaction problem is not obtained
yet.</p></li>
<li><p>The exchange-correlation potential <span
class="math inline">v_{xc}({\bf r})</span> is the functional derivative
of the <strong>exchange-correlation (XC) functional</strong> <span
class="math inline">E_{xc}[n]</span> with respect to the electron
density <span class="math inline">n</span>. <span class="math display">
v_{xc}({\bf r}) = \frac{\delta E_{xc}[n]}{\delta n}
</span></p></li>
<li><p>From this, <span class="math inline">E_{xc}[n]</span> can be
written as an integral form like <span class="math display">
E_{xc}[n] = \int d^3 r n({\bf r}) \epsilon_{xc}[n]({\bf r})
</span> where <span class="math inline">\epsilon_{xc}[n]({\bf r})</span>
is the exchange-correlation energy per particle at the point <span
class="math inline">{\bf r}</span>, but depends on the whole electron
density distribution <span class="math inline">n({\bf
r})</span>.</p></li>
<li><p>Historically, a lot of XC functionals has been proposed by many
researchers. These functionals are ranked by the variables used in the
XC functional, and sometimes expressed as <strong>Jacob’s
ladder</strong> (Fig.X) starting from the earth (“Hartree world”) to the
heaven (chemical accuracy). For example, the first level is the local
density approximation (LDA), which uses only the electron density <span
class="math inline">n</span> as variable. The second one is generalized
gradient approximation (GGA), which uses <span
class="math inline">n</span> and the gradient of the electron density
(<span class="math inline">\Delta n</span>). The third one is called
meta-GGA, where the kinetic energy density <span
class="math inline">\tau</span> is added to the variables. The fourth
one is hybrid GGA, which uses the Hartree-Fock exchange (or exact
exchange) information. Up to this level is commonly used, while the
higher ladder is possible if the state-of-art methods like double
hybrid, random phase approximation (RPA) etc. is used.</p></li>
<li><p>In the following, we look into the XC functionals at each level
of the Jacob’s ladder.</p></li>
</ul>
<h4 id="lda-1">LDA</h4>
<ul>
<li>There is one case where the XC functional can be derived exactly:
this situation is called the uniform electron gas. In this case, the
electron density is constant at all points in the space; that is, <span
class="math inline">n({\bf r}) = {\rm constant}</span>. This
approximation uses only the local density to define the XC functional,
so it is called the <strong>local density approximation (LDA)</strong>,
which is the simplest approximation to the true XC functional. <span
class="math display">
E_{xc}^{LDA}[n] = \int d^3 r n({\bf r}) \epsilon_{xc}^{LDA}\left( n({\bf
r}) \right)
</span></li>
<li>For some regimes, these results were determined from quantum Monte
Carlo calculations, as this gives the accurate solution of the
Schrodinger equation, although it is quite computationally
expensive.</li>
<li>The LDA is exact in the uniform density limit, which says that in
the limit of uniform density the XC energy should be the exact energy of
the uniform electron gas at that density.</li>
<li>In a wide range of bulk and surface problems, the LDA has been
surprisingly successful. However, the LDA results are not sufficiently
accurate for atoms and molecules. This is related to the constancy of
the electron density, because the LDA is exact in the uniform density
limit. Thus the LDA is more accurate when electron density is slowly
varying, which is not at all true for atoms and molecules. Practically,
the LDA often shows over-binding, i.e. adsorption energies or cohesive
energies being too large compared with experimental values. This leads
too short lattice constant in solid case, and too short bond length in
molecules. The band gap is also inaccurate, as the deviation from
experimental value amount to be ~50% in cases.</li>
</ul>
<h4 id="gga-1">GGA</h4>
<ul>
<li>The next-generation XC functional to the LDA is the
<strong>generalized gradient approximation (GGA)</strong>. The physical
idea behind the GGA is simple; real electron densities are not uniform,
so including information on the spatial variation in the electron
density would make a functional more flexible.</li>
<li>In the GGA, the XC functional is expressed using both the local
electron density <span class="math inline">n({\bf r})</span> and the
gradient in the electron density <span class="math inline">\nabla n({\bf
r})</span>; <span class="math display">
E_{xc}^{GGA}[n] = \int d^3 r n({\bf r}) \epsilon_{xc}^{GGA}\left( n({\bf
r}), |\nabla n ({\bf r})| \right)
</span></li>
<li>Because there are many ways to include <span
class="math inline">\nabla n({\bf r})</span> in a XC functional, a lot
of GGA functional have been proposed. Two of the most widely used
functionals in the solid-state physics calculations are the
Perdew-Burke-Ernzerhof (PBE) and the Perdew-Wang (PW91) functionals.
These two functionals satisfy the uniform density limit, and also the
exact properties of the XC hole near nuclei.</li>
<li>DFT calculations in the GGA achieve chemical accuracy (error &lt;=
0.1 eV) for many chemical reactions.</li>
<li>The application of the semiconductor needs to go beyond the GGA,
mainly because of the well-known underestimation of the band gaps of
semiconductors.</li>
<li>Also, the GGA has the tendency to delocalize the electronic
state.[Cohen,A.J.;Mori-Sańchez,P.;Yang,W.Science, 2008, 321,
792−794.]</li>
</ul>
<h4 id="meta-gga-1">Meta-GGA</h4>
<ul>
<li>The third rung of the Jacob’s ladder is defined by the
<strong>meta-GGA</strong> functionals, which include information from
<span class="math inline">n({\bf r})</span>, <span
class="math inline">\nabla n({\bf r})</span>, and <span
class="math inline">\nabla^2 n({\bf r})</span>. In practice, the kinetic
energy density of the Kohn-Sham orbitals, <span class="math display">
\tau({\bf r}) = \frac{1}{2}\sum_\text{occupied states}|\nabla
\varphi_i({\bf r})|^2
</span> contains the same physical information as the Laplacian of the
electron density, and using these quantities has a number of advantages;
so <span class="math inline">\tau({\bf r})</span> may be used in the
meta-GGA functionals instead of <span class="math inline">\nabla^2
n({\bf r})</span>.</li>
<li>Popular functionals in this level are SCAN, TPSS, MS etc., and their
variants.</li>
</ul>
<h4 id="hybrid-functional">Hybrid functional</h4>
<ul>
<li>The fourth rung of the ladder is important because it is the most
common functional in quantum chemistry calculations with localized basis
sets.</li>
<li>The exact exchange energy can be derived from the exchange energy
density, which can be written in terms of the Kohn-Sham orbitals as
<span class="math display">
E^{ex}({\bf r})
= -\frac{1}{2n({\bf r})}\int d^3 r&#39;
\frac{|\sum_{occ}\varphi_i^{*}({\bf r}&#39;)\varphi_i({\bf
r})|^2}{|r-r&#39;|}
</span></li>
<li>A critical feature of this quantity is that it is nonlocal, that is,
a functional based on this quantity cannot be evaluated at one
particular spatial location unless the electron density is known for all
spatial locations.</li>
<li>Functionals that include contributions from the exact exchange
energy within a GGA functional are called the <strong>hybrid
functional</strong>.</li>
<li>Hybrid functionals describe exchange using a mixture of the exact
exchange and a GGA exchange functional. By far the most widely used of
these functionals in for solids systems are PBE0 and HSE, and for
molecular systems the B3LYP functional is most widely used. For example,
the B3LYP functional has the following form; <span class="math display">
\begin{align*}
\epsilon_{xc}^{B3LYP} = \epsilon_{XC}^{LDA} &amp;+ \alpha_1 (E^{ex} -
\epsilon_{X}^{LDA}) \\
  &amp;+ \alpha_2 (\epsilon_{X}^{GGA} - \epsilon_{X}^{LDA}) \\
  &amp;+ \alpha_3 (\epsilon_{C}^{GGA} - \epsilon_{C}^{LDA})
\end{align*}
</span></li>
<li>Here, <span class="math inline">\epsilon_{X}^{GGA}</span> is the
Becke 88 exchange functional, <span
class="math inline">\epsilon_{C}^{GGA}</span> is the Lee-Yang-Parr
correlation functional, and <span class="math inline">\alpha_i (i = 1,
2, 3)</span> are three numerical parameters. The three parameters were
chosen empirically to optimize the performance of the functional for a
sizable test set of molecular properties.</li>
<li>Because of the numerical details associated with solving the
Kohn-Sham equations in a plane-wave basis set, introducing the
non-locality of exact exchange greatly increases the numerical burden of
solving these equations. This difficulty is not so severe when localized
basis sets are used, thus hybrid functional is relatively common in
quantum chemistry community than solid-state physics community.</li>
<li>This numerical difficulty is partly resolved by using the screened
hybrid functionals. In this approach, the exchange interaction is split
into two components, a long-range and a short-range one. A degree of the
exact exchange is applied only to the short-range portion. The HSE
functional is based on this approach, and is also widely used in
plane-wave basis set.</li>
</ul>
<h3 id="van-der-waals-interaction">van der Waals interaction</h3>
<ul>
<li>Dispersion interaction (also known as van der Waals interaction or
London force) is a direct result of long-range electron correlation.
This interaction plays an incredibly important role in our everyday
lives. Consider the gasoline or diesel that all of us rely on as
transportation fuels. The huge global infrastructure that exist to
deliver and use these fuels heavily relies on the fact that they are
liquids. The fact that nonpolar molecules such as hexane readily form
liquids is a signature of the net attractive interactions that exist
between hexane molecules. These attractive interaction arise directly as
a result of dispersion interaction.</li>
<li>The relationship between electron correlation and long-range forces
between atoms was initially examined in the 1930s by London. He realized
that although the time-averaged electron density around an atom or
nonpolar molecules has no dipole moment, electron oscillations lead to
deformations of the density resulting in a transient dipole moment.</li>
<li>This instantaneous dipole moment can induce a temporary dipole
moment (called induced dipole moment) on other atoms or molecules by
distorting their electron density. London showed that the general form
of the interaction between two spherically symmetric atoms at large
distance was <span class="math display">
V^{\rm dispersion} = -\frac{C}{r^6}
</span> where <span class="math inline">r</span> is the distance between
the atoms and <span class="math inline">C</span> is a collection of
physical constants.</li>
<li>Several studies illustrate the limitations of DFT calculations with
respect to the dispersion interactions.</li>
<li>One conceptually simple remedy for the shortcomings of DFT regarding
dispersion forces is to simply add a dispersion-like contribution to the
total energy between each pair of atoms in a material.</li>
<li>This method is called the <strong>DFT-D</strong> method.</li>
<li>In the DFT-D calculations, the total energy of a collection of atoms
as calculated with DFT, <span class="math inline">E_{\rm DFT}</span>, is
augmented as follows: <span class="math display">
E_{\rm DFT-D} = E_{\rm DFT} - S\sum_{i \ne
j}\frac{C_{ij}}{r_{ij}^6}f_{\rm damp}(r_{ij})
</span></li>
<li>Here <span class="math inline">r_{ij}</span> is the distance between
atoms i and j, <span class="math inline">C_{ij}</span> is a dispersion
coefficient for atoms i and j, which can be calculated directly from
tabulated properties of individual atoms, and <span
class="math inline">f_{\rm damp}(r_{ij})</span> is a damping function to
avoid unphysical behavior of the dispersion term for small distances.
<span class="math inline">S</span> is the empirical scaling factor
applied uniformly to all pairs of atoms.</li>
</ul>
<h3 id="dft-u">DFT + U</h3>
<ul>
<li><p>Other than the XC functionals introduced above, another popular
DFT method is the DFT + U method. This should be considered as a variant
(or branch) from the Jacobs’ ladder, because the empirical parameter is
used.</p></li>
<li><p>DFT + U method is often used in the materials with the strong
correlation, because the GGA often fails to properly describe the
electronic property of these systems such as band-gap.</p></li>
<li><p>Many semi-conductors are grouped in this category.</p></li>
<li><p>The DFT + U method is usually used with the GGA functional, and
the deficiency of the GGA is corrected via the <span
class="math inline">U</span> parameter.</p></li>
<li><p>The <span class="math inline">U</span> parameter is called
on-site Coulomb parameter. The <span class="math inline">U</span> in GGA
+ U refers to the strong correlation repulsion energy of electrons with
opposite spins in the Hubberd model.</p></li>
</ul>
<h3 id="random-phase-approximation">Random phase approximation</h3>
<ul>
<li></li>
</ul>
<h2 id="other-topics">1-3. Other topics</h2>
<h3 id="basis-set">Basis set</h3>
<h4 id="choice-of-the-basis-function-form">Choice of the basis function
form</h4>
<ul>
<li>In solving the Schrodinger equation, we need to express the wave
function by some known mathematical functions. In other words, we need
“expand” the wave function by some analytic functions. These analytic
functions are mathematically called <strong>basis set</strong> or
<strong>basis functions</strong>.</li>
<li>In principle, any type of basis functions may be used; exponential,
Gaussian, polynomial, wavelets, plane waves, etc.</li>
<li>There are, however, two guidelines for choosing the basis
functions</li>
</ul>
<ol type="1">
<li>they should have a behavior that agrees with the physics of the
problem. For this reason, the basis function is often the exact solution
for the simple model systems; for the periodic systems, the plane waves
(<span class="math inline">\sin</span> or <span
class="math inline">\cos</span> functions) are the exact solution and
these functions satisfies a necessary condition for the system
i.e. periodicity of the bulk system. For atomic systems, the exponential
functions is the exact solution of the hydrogen atom, and it satisfies a
necessary condition for the electronic wave function of atoms; it should
decay toward zero when the distance between the nucleus and the electron
becomes large. Thus, these functions or similar ones are often used as
the basis set, and we need to select an appropriate basis set for the
problem in hand.</li>
<li>the second condition is a practical one: the chosen functions should
make it easy to calculate all the required integrals. For this reason,
the Gaussian type orbitals are preferred over the Slater type orbitals,
as will be discussed later.</li>
</ol>
<h4 id="atomic-orbitals-and-the-roothaan-hall-equation.">Atomic orbitals
and the Roothaan-Hall equation.</h4>
<ul>
<li><p>Each MO <span class="math inline">\phi</span> is expanded by the
basis functions <span class="math inline">\chi</span>, conventionally
called <strong>atomic orbitals</strong> <span class="math display">
\phi_i = \sum_{\alpha}^{N_{bas}}c_{\alpha i}\chi_{\alpha}
</span></p></li>
<li><p>The Hartree-Fock equation may be written as <span
class="math display">
{\bf F}_i\sum_{\alpha}c_{\alpha i}\chi_{\alpha} = \epsilon_i
\sum_{\alpha}c_{\alpha i}\chi_{\alpha}
</span></p></li>
<li><p>Multiplying from the left by a specific basis function and
integrating yields the <em>Roothaan-Hall equations</em>. These are the
Hartree-Fock equations in the atomic orbital basis, and all the <span
class="math inline">N_{bas}</span> equations may be collected in a
matrix notation. <span class="math display">
\begin{align*}
{\bf FC} &amp;= {\bf SC \epsilon} \\
F_{\alpha \beta} &amp;= \braket{\chi_{\alpha}|{\bf F}|\chi_{\beta}} \\
S_{\alpha \beta} &amp;= \braket{\chi_{\alpha}|\chi_{\beta}}
\end{align*}
</span></p></li>
<li><p>The <span class="math inline">{\bf S}</span> matrix contains the
overlap elements between basis functions, and the <span
class="math inline">{\bf F}</span> matrix contains the Fock matrix
elements.</p></li>
<li><p>There are two types of basis functions in atomic or molecular
electronic structure calculations; Slater type orbitals (STO) and
Gaussian type orbitals (GTO).</p></li>
<li><p>STOs have the functional form as <span class="math display">
\chi_{\xi,n,l,m}(r, \theta, \varphi) = N
Y_{l,m}(\theta,\varphi)r^{n-1}\exp(-\xi r)
</span></p></li>
<li><p>Here <span class="math inline">N</span> is a normalization
constant and <span class="math inline">Y_{l,m}</span> are spherical
harmonic functions. The exponential dependence on the distance between
the nucleus and electron comes from the nature of the exact wave
function of the hydrogen atom.</p></li>
<li><p>Although STOs have clear physical origin, the calculation of
three- and four-electron two-electron integrals cannot be performed
analytically.</p></li>
<li><p>GTOs can be written in terms of polar or Cartesian coordinates as
<span class="math display">
\begin{align*}
\chi_{\xi,n,l,m}(r,\theta,\varphi) &amp;= N
Y_{l,m}(\theta,\varphi)r^{2n-2-l}\exp(-\xi r^2) \\
\chi_{\xi,n,l,m}(x,y,z) &amp;= N x^{l_x}y^{l_y}z^{l_z}\exp(-\xi r^2)
\end{align*}
</span></p></li>
<li><p>The sum of <span class="math inline">l_x</span>, <span
class="math inline">l_y</span>, and <span class="math inline">l_z</span>
determines the type of the orbital; <span class="math inline">l_x + l_y
+ l_z = 0, 1, 2, 3</span> are s-, p-, d- and f-orbitals,
respectively.</p></li>
<li><p>Because of the <span class="math inline">r^2</span>-dependence in
the exponential of GTOs, they have poorer description than STOs for the
“cusp” (discontinuous derivative) at <span class="math inline">r =
0</span>. This is often alleviated by increasing the number of GTO
functions with high exponent <span class="math inline">\xi</span> values
(thus “sharp” function at small <span
class="math inline">r</span>).</p></li>
<li><p>Having decided on the type of the functions (STO or GTO), the
most important factor is the number of functions to be used. The
smallest number of functions possible is a minimal basis set. Only
enough functions are employed to contain all the electrons of the
neutral atoms. For hydrogen and helium, this means a single s-function.
For the first row in the periodic table, it means two s-functions (1s
and 2s) and one set of p-functions (2px, 2py, and 2pz).</p></li>
<li><p>The next improvement of the basis set is a doubling of all basis
functions, producing ad Double Zeta (DZ) type basis. The chemical
bonding occurs between valence orbitals. Doubling the 1s-functions in
for example carbon allows for a better description of the 1s-electrons.
However, the 1s-orbital is essentially independent of the chemical
environment.</p></li>
<li><p>A variation of the DZ type basis only doubles the number of
valence orbitals, producing a split valence basis. In actual
calculations, a doubling of the core orbitals would rarely be
considered, and the term DZ basis is used also for split valence basis
set or sometimes referred as VDZ, for valence double zeta.</p></li>
<li><p>In most cases, higher angular momentum functions are also
important, and these are denoted <em>polarization
functions</em>.</p></li>
<li><p>If methods including electron correlation are used, higher
angular momentum functions are essential.</p></li>
<li><p>Polarization functions can be added to the chosen basis set.
Adding a single set of polarization functions (p-functions on hydrogens
and d-functions on non-hydrogen atoms) to the DZ basis forms the
<em>Double Zeta plus Polarization (DZP)</em> type basis set.</p></li>
<li><p>There is a variation where the polarization functions are only
added to non-hydrogen atoms. As hydrogen often accounts for a large
number of atoms in the system, a saving of three (px, py, and pz) basis
functions for each hydrogen is significant. If hydrogen plays an
important role in the property of interest, it is of course not a good
idea to neglect polarization functions on hydrogen.</p></li>
<li><p>In some cases, extra basis functions called <em>diffuse
functions</em> are added to the basis set. These are functions with
small exponents, and are needed whenever loosely bound electrons are
present (for example, anions or excited states).</p></li>
</ul>
<h4 id="contracted-basis-set">Contracted basis set</h4>
<ul>
<li>The inner-shell or core electrons are more energetically important
than the valence electrons, as these are closer to the nucleus. However,
chemistry is mainly dependent on the valence electrons because chemical
bonds are always formed using the valence electrons.</li>
<li>The fact that many basis functions focus on describing the
energetically important, but chemically unimportant, core electrons is
the foundation for contracted basis set.</li>
<li>Consider for example a basis set consisting of ten s-functions (and
some p-functions) for a carbon atom. Optimization of these ten exponents
by variational calculation is presumably leads the basis set well
describing the 1s-orbital.</li>
<li>The important chemical regions is however the outer valence. Out of
the ten functions, a few basis functions are actually used for
describing the chemically interesting phenomena.</li>
<li>As the core orbitals change very little depending on the chemical
bond situation, the MO expansion coefficients in front of these inner
basis functions also change very little. The majority of the
computational effort is therefore spent in describing the chemically
unimportant part of the wave function, which is a problematic.</li>
<li>Considering now making the variational coefficient in front of the
inner basis functions constant, i.e. they are no longer parameters to be
determined by the variational principle. The 1s-orbital in this case is,
thus, described by a fixed linear combination of, say, six basis
functions.</li>
<li>Similarly, the remaining four basis functions may be contracted into
only twos functions, for example by fixing the coefficient in front of
the inner three functions. In doing this, the number of basis functions
to be handled by the variational principle has been reduced from ten to
three.</li>
<li>Combining the full set of basis functions, known as the
<em>primitive GTOs</em>, into a small set of functions by forming
<em>fixed</em> linear combinations is known as <em>basis set
contraction</em>, and resulting functions are called the <em>contracted
GTOs</em>. <span class="math display">
\chi({\rm contracted}) = \sum_i a_i \chi_i({\rm primitive})
</span></li>
</ul>
<h4 id="plane-wave-basis-functions">Plane wave basis functions</h4>
<ul>
<li><p>The outer valence electrons in metals behave almost like free
electrons, which leads to the idea of using solutions for the free
electrons as basis functions. The solutions to the Schrodinger equation
for a free electron in one dimension can be written either in terms of
complex exponential or cosine and sine functions. <span
class="math display">
\phi(x) = A\exp(ikx) + B\exp(-ikx) \\
\phi(x) = A\cos(kx) + B\sin(kx) \\
E = \frac{1}{2}k^2
</span></p></li>
<li><p>For infinite systems, the molecular orbitals coalesce into bands,
since the energy spacing between distinct level vanishes.</p></li>
<li><p>The electrons in a band can be described by orbitals expanded in
a basis set of plane waves, which in three dimensions can be written as
a complex function <span class="math display">
\chi_k({\bf r}) = \exp(i{\bf k}\cdot{\bf r})
</span></p></li>
<li><p>Here, <span class="math inline">k = |{\bf k}|</span>. The wave
vector <span class="math inline">{\bf k}</span> plays the same role as
the exponent <span class="math inline">\zeta</span> in GTO or STO, and
is related to the energy by means of Eq.X. <span
class="math inline">{\bf k}</span> can be also thought of as a frequency
factor, with high <span class="math inline">{\bf k}</span> values
indicating a rapid oscillation.</p></li>
<li><p>Plane wave basis functions are ideal for describing delocalized
slowly varying electron densities, such as valence bands in a
metal.</p></li>
<li><p>Describing the core region adequately with plane waves requires a
large number of rapidly oscillating functions, i.e. basis with very high
<span class="math inline">{\bf k}</span> values.</p></li>
<li><p>Quantum chemists have developed a particular nomenclature to
describe the quality of a basis set.</p></li>
<li><p>The simplest choice of just one atomic orbital per valence state
is called “minimal basis set” or “single zeta”. It is also possible to
use multiple functions to the valence state; when two functions are
used, it is called the “double zeta (DZ)” basis set. Three functions are
used it becomes “triple zeta (TZ)”. There also exists quadruple zeta
(QZ) or quintuple zeta (5Z), but these are usually used for very
accurate calculations.</p></li>
<li><p>The polarization functions describe small displacements of the
atomic orbitals from the nuclear centers. Then a “P” is added to the
acronym of the basis set resulting in e.g., DZ2P.</p></li>
<li><p>For rather delocalized states such as anionic or Rydberg excited
states, diffuse functions are added.</p></li>
<li><p>The plane wave basis set is used in the solid-physics type
calculations.</p></li>
</ul>
<h3 id="pseudopotentials">Pseudopotentials</h3>
<ul>
<li>Systems involving elements from the lower part of the periodic table
have a large number of core electrons. These core electrons are
unimportant in a chemical sense, but they should be included to properly
describe the valence orbitals.</li>
<li>Relativistic effects further complicate matters in the lower part of
the periodic table.</li>
<li>These two problems may be “detoured” simultaneously by modelling the
core electrons by a suitable function, and treating only the valence
electrons explicitly.</li>
<li>The function modeling the core electrons is usually called an
<em>effective core potential (ECP)</em> in the chemistry community,
while the physics community uses the term <em>pseudopotential
(PP)</em>.</li>
<li>There are four major steps in designing a pseudopotential;
<ol type="1">
<li>generate a good-quality all wave function for the atom. Typically,
numerical Hartree-Fock, Dirac-Hartree-Fock, or DFT is used.</li>
<li>replace the valence orbitals by a set of nodeless pseudo-orbitals.
The pseudo-orbitals are designed such that they behave correctly in the
outer part, but without the nodal structure in the core region.</li>
<li>replace the core electrons by a potential, and expand them by a
suitable set of analytical functions of the nuclear-electron distance.
For example, a set of spherical Bessel or Gaussian function are used.
The potential may be different for each angular momentum.</li>
<li>fit the parameters of the above potential such that the
pseudo-orbitals matches the all-electron valence orbitals.</li>
</ol></li>
<li>The pseudopotentials are typically characterized by a “core radius”
<span class="math inline">r_c</span> (which may depend on the angular
momentum of the valence orbitals).</li>
<li>The potential for distances smaller than <span
class="math inline">r_c</span> is described by the pseudo-wave function
(some analytical function), and its first and second derivatives are
required to match those of the reference wave function at <span
class="math inline">r_c</span>.</li>
<li>It is clear that a “hard” (small <span
class="math inline">r_c</span>) pseudopotential require more plane wave
basis functions for describing the region beyond <span
class="math inline">r_c</span> than a “soft” (large <span
class="math inline">r_c</span>) pseudopotential, but a too large <span
class="math inline">r_c</span> will deteriorate the quality of the
calculated results and also make pseudopotential less
transferrable.</li>
<li>The <em>norm-conserving</em> pseudopotential by Hamman, Schluter,
and Chaing require in addition to the above matching conditions at <span
class="math inline">r_c</span> that the integral of the square of the
reference and pseudo-wave from 0 to <span class="math inline">r_c</span>
to be same, i.e. conservation of the “wave function norm”.</li>
<li>These pseudopotentials are rather “hard” and therefore require a
relatively large energy cutoff for the plane waves.</li>
<li>Vanderbilt proposed to relax the norm-conserving requirement to give
the so-called <em>ultrasoft</em> pseudopotentials, thereby reducing the
necessary number of plane waves for expanding valence orbitals by
roughly a factor of two.</li>
<li>The <em>projector augmented wave (PAW)</em> method is usually also
considered as a pseudopotential method, although it formally retains all
the core electrons.</li>
<li>The PAW wave function is written as a valence term expanded in a
plane wave basis plus a contribution from the region within the core
radius.</li>
<li>The contribution from a core region is expanded as a difference
between two sets of densities, one arising from the all-electron atomic
orbitals, and the other is from a set of nodeless pseudo-atomic
orbitals. This terms allow the wave function within the core region to
adjust for different environments. In all the applications so far, the
all-electron atomic orbitals have been kept fixed from the isolated
atoms.</li>
</ul>
<h3 id="population-analysis">Population analysis</h3>
<h4 id="mulliken">Mulliken</h4>
<ul>
<li>The electron density <span class="math inline">\rho</span> is a
probability of finding an electron at a certain position <span
class="math inline">{\bf r}</span>, and we can calculate it for a single
MO containing one electron as <span class="math display">
\rho_i({\bf r}) = \phi_i^2({\bf r})
</span></li>
<li>Assuming that the MO is expanded in a set of normalized but
non-orthogonal basis function <span class="math inline">\chi</span>,
this can be written as <span class="math display">
\phi_i   = \sum_{\alpha}^{M_{basis}}c_{\alpha i}\chi_\alpha \\
\phi_i^2 = \sum_{\alpha\beta}c_{\alpha i}c_{\beta i}\chi_\alpha
\chi_\beta
</span></li>
<li>Integrating and summing over all occupied MOs (<span
class="math inline">N_{occ}</span>) gives the total number of electrons
<span class="math inline">N_{elec}</span>, as <span
class="math display">
\begin{align*}
\sum_i^{N_{occ}}\int\phi_i({\bf r})^2 d{\bf r}
&amp;= \sum_i^{N_{occ}}\sum_{\alpha\beta}^{M_{basis}}c_{\alpha
i}c_{\beta i}\int\chi_\alpha\chi_\beta d{\bf r} \\
&amp;= \sum_{\alpha\beta}^{M_{basis}}c_{\alpha i}c_{\beta
i}\braket{\chi_\alpha | \chi_\beta}
= \sum_i^{N_{occ}}\sum_{\alpha\beta}^{M_{basis}}c_{\alpha i}c_{\beta
i}S_{\alpha\beta}
= N_{elec}
\end{align*}
</span></li>
<li>We may generalize this by introducing an <em>occupation number</em>
<span class="math inline">n</span> for each MO. For a single-determinant
wave function, <span class="math inline">n</span> is either 0, 1, or 2,
and the above equation is rewritten as <span class="math display">
\sum_i^{N_{orb}}n_i\int\phi_i({\bf r})^2 d{\bf r} =
\sum_{\alpha\beta}^{M_{basis}}\left( \sum_i^{N_{orb}}n_i c_{\alpha
i}c_{\beta i} \right) S_{\alpha\beta} =
\sum_{\alpha\beta}D_{\alpha\beta}S_{\alpha\beta} = N_{elec}
</span></li>
<li>The sum of the product of MO coefficients and the occupation number
is the <em>density matrix</em>, and the sum over the product of the
density and overlap matrices elements is the number of electrons</li>
<li>The <strong>Mulliken population analysis</strong> uses the <span
class="math inline">{\bf D}\cdot{\bf S}</span> matrix for distributing
the electrons into atomic contributions. A diagonal element <span
class="math inline">D_{\alpha\alpha}S_{\alpha\alpha}</span> is the
number of electrons in the <span class="math inline">\alpha</span> AO
(<span class="math inline">\chi_\alpha</span>), and the off-diagonal
element <span class="math inline">D_{\alpha\beta}S_{\alpha\beta}</span>
is (half) the number of electrons shared by AO <span
class="math inline">\alpha</span> and <span
class="math inline">\beta</span> (there is an equivalent <span
class="math inline">D_{\beta\alpha}S_{\beta\alpha}</span> element).</li>
<li>The contribution from all MOs located on a given atom A may be
summed up to give the number of electrons associated with atom A.</li>
<li>This requires a decision on how a contribution involving basis
function on different atoms should be divided. The simplest, and the one
used in the Mulliken scheme, is to partition the contribution equally
between two atoms.</li>
<li>The Mulliken electron population is thereby defined as <span
class="math display">
\rho_A = \sum_{\alpha \in
A}^{M_{basis}}\sum_\beta^{M_{basis}}D_{\alpha\beta}S_{\alpha\beta}
</span></li>
<li>The net charge on atom A is then the sum of the nuclear contribution
<span class="math inline">Z_A</span> and the electronic contribution
<span class="math inline">\rho_A</span>, noting that electrons have
negative charge; <span class="math inline">Q_A = Z_A -
\rho_A</span>.</li>
</ul>
<h4 id="bader-atoms-in-molecules">Bader (Atoms in Molecules)</h4>
<ul>
<li><p>The population analysis shown in the previous section is based on
the wave function. However, it is also possible to use the electron
density for this purpose.</p></li>
<li><p>However, the problem is the definition of an “atom” within a
molecule, and we need to divide the electron density into the atomic
basins, and several different schemes to this have been
proposed.</p></li>
<li><p>Perhaps the most rigorous way of divide a molecular volume into
atomic subspaces is the <strong>Atoms in Molecules (AIM)</strong> method
of R. Bader.</p></li>
<li><p>The electron density is a function of three spatial coordinates,
and it may be analyzed in terms of its topology (maxima, minima, and
saddle points).</p></li>
<li><p>In most cases, it is found that the only maxima in the electron
density occur at the nuclei, as these are the only sources of positive
charge. The nuclei tus act as <em>attractors</em> of the electron
density.</p></li>
<li><p>At each point in space, the gradient of the electron density
points the direction of the strongest attractor nearby. This forms a way
of dividing the physical space into atomic subspaces; starting from a
given point in space, a series of small steps may be taken in the
gradient direction until an attractor is encountered. The collection of
all such points forms the atomic basis associated with the attractor
(nucleus).</p></li>
<li><p>Once the molecular volume has been divided up, the electron
density may be integrated within each of the atomic basins to give
atomic charges, and dipole moments, quadrupole moments, etc.</p></li>
<li><p>For a point on a dividing surface between two atomic basins, the
gradient path for such a point leads to a stationary point on the
surface where the total derivative is zero.</p></li>
<li><p>The basin attractor is also a stationary point on the electron
density surface. The second derivative of the electron density, the
Hessian, is a function of the three (Cartesian) coordinates, i.e. it is
a 3x3 matrix.</p></li>
<li><p>At stationary points, it may be diagonalized and the number of
negative eigenvalues are determined. The basin attractor is an overall
maximum, so it has three negative eigenvalues.</p></li>
<li><p>Another type of stationary points i.e. saddle points are found
and indeed they have chemically interesting character. Saddle points are
usually found between a pair of nuclei that are “chemically bonded”.
Such points have a minimum in the electron density in the direction of
the nuclei, while a maximum in the perpendicular directions; there is
one positive and two negative eigenvalues in the Hessian. These points
are known as <em>bond critical points</em>.</p></li>
<li><p>A bond critical point thus correspond to a saddle point in the
electron density, and thus is similar to the transition state in the
potential energy surface (Section X.X).</p></li>
<li><p>The second derivative of the electron density, the Laplacian
<span class="math inline">\nabla^2\rho</span>, provides information on
where the electron density is depleted or increased. At a bond critical
point, the sign of the Laplacian has been used for characterizing the
nature of the bond, i.e. a negative value indicates a covalent bond,
while a positive value indicates an ionic bond or a van der Waals
interaction.</p></li>
</ul>
<h3 id="geometry-optimization">Geometry optimization</h3>
<ul>
<li></li>
</ul>
<h4 id="local-optimization">Local optimization</h4>
<ul>
<li></li>
</ul>
<h4 id="global-optimization">Global optimization</h4>
<ul>
<li></li>
</ul>
<h3 id="vibrational-analysis">Vibrational analysis</h3>
<ul>
<li>The matrix of all the second derivatives is called <strong>Hessian
or Hesse matrix</strong>, and it expresses a linear system of
differential equations <span class="math display">
{\bf H}{\bf u}_k = \omega_k^2 {\bf M}{\bf u}_k
</span> for the vibrational eigenmode <span
class="math inline">u_k</span> and their frequencies <span
class="math inline">\omega_k</span> that will characterize the
collective movement of the atoms.</li>
<li>Using the finite difference method, the Hessian can be approximated
as <span class="math display">
H_{ij} = \left. \frac{\partial E^2}{\partial u_i \partial u_j} \right|_0
= -\frac{\partial F_j}{\partial u_i}
</span> where <span class="math inline">F_j</span> is the forces.</li>
</ul>
<h3 id="transition-state-search">Transition state search</h3>
<ul>
<li>The transition state is connecting the two energy minima in the PES,
and these PES are usually correspond to some stable molecular
structure.</li>
<li>A clear example of this is that the bond dissociation or formation
process (Fig.X). The minimum at right corresponds to the state that has
the O-H bond in this example, while the left minimum corresponds to the
state with N-H bond. There is a saddle point between them, and the
activation energy (Ea) can be measured by the energy difference between
minima and the saddle point. This topic is also discussed in the later
section.</li>
<li>Since we need to evaluate the Ea for the calculation of the rate
constant in the reaction rate, obtaining the transition state structure
is critically important topic in the computational catalytic science and
many numerical methods have been developed for this task.</li>
</ul>
<h4 id="nudged-elastic-band">Nudged elastic band</h4>
<ul>
<li>The method that is most widely used for finding transition states in
plane-wave DFT calculation is the nudged elastic band (NEB) method.</li>
<li>This method was developed by Hannes Tonsson and co-workers as a
refinement of earlier “chain-of-states” method. The aim of a
chain-of-states calculation is to define the minimum energy path (MEP)
between two local minima.</li>
<li>If you remember that the forces on the atoms in any configuration
are defined by <span class="math inline">F = -\nabla E(r)</span>, where
<span class="math inline">r</span> is the set of coordinates of the
atom, then images can be separated into two groups; the starting and the
final images are located at local minima, so <span class="math inline">F
= 0</span>. for all the other images, the forces on the atoms are
nonzero.</li>
<li>Now let us move to elastic band method. This method is based on the
concept that images along the MEP should use the lowest among of energy
to define a path between the two minima and that the images should be
evenly spaced along the path. These two ideas can be expressed
mathematically for a set of images <span class="math inline">r_0, r_1,
\cdots, r_p</span> by defining the objective function <span
class="math display">
M(r_1, r_2, \cdots, r_p) = \sum_i E(r_i) + \sum_i \frac{K}{2}(r_i -
r_{i-1})^2
</span></li>
<li>Here, <span class="math inline">E(r_i)</span> is the total energy of
the i-th image, and <span class="math inline">K</span> is a constant
that defines the stiffness of the harmonic springs (the “elastic band”)
connecting adjacent images.</li>
<li>The objective function does not include the images 0 or P, because
those images are held fixed at the energy minima.</li>
<li>The minimization of this objective function moves all the images
closer to the true MEP.</li>
<li>The <strong>nudged elastic band (NEB)</strong> is defined to improve
upon the elastic band method. From the current position of the images,
we can estimate the direction of the path defined by the image.</li>
<li>A useful estimate for this direction is to define th path direction
for image i, <span class="math inline">\hat{\tau_i}</span> as unit
vector pointing along the line defined by the two adjacent images, <span
class="math inline">r_{i+1}-r_i</span>.</li>
<li>The images will satisfy the definition of a MEP, given above if the
component of the force not pointing along the path direction is zero,
that is, <span class="math inline">F_i^{\perp} = F_i -
(F_i\cdot\hat{\tau_i})\hat{\tau_i} = 0</span>.</li>
<li>This description suggests a simple strategy for adjusting the images
- move each of them “downhill” along the direction defined by <span
class="math inline">F_i^{\perp}</span></li>
<li>If we want to include harmonic springs between images, the nwe also
need to include the spring forces in defining this downhill
direction.</li>
<li>A useful way to do this is to define <span class="math display">
F_{i, \rm{update}} = F_{i}^{\perp} + F_{i, \rm{spring}}
                 = F_{i}^{\perp} + K(|r_{i+1}-r_i| - |r_i - r_{i-1}|)
</span></li>
<li>We want the spring forces to act only to keep the images evenly
spread out along the path, and we do not want the spring forces to pull
the images away from the MEP.</li>
<li>To do this, we define <span class="math display">
F_{i, \rm{spring}}^{\parallel} = (F_{i,
\rm{spring}}\cdot\hat{\tau_i})\hat{\tau_i}
</span> and then the update the positions using <span
class="math display">
F_{i, \rm{update}} = F_i^{\perp} + F_{i, \rm{spring}}^{\parallel}
</span></li>
<li>If all the images in the calculation lie on an MEP, then this update
force is zero for every image and the calculation has converged.</li>
</ul>
<h4 id="dimer-method">Dimer method</h4>
<ul>
<li></li>
</ul>
<h2 id="x.-molecular-dynamics">1-X. Molecular dynamics</h2>
<h3 id="constrained-and-biased-sampling-methods">Constrained and biased
sampling methods</h3>
<ul>
<li>A straightforward sampling of the reaction path is not possible
since the dynamics at ordinary temperatures only very rarely visit the
high-energy region near the TS( unless the activation energy is close to
zero).</li>
<li>In order to achieve a sampling of a specific region of the free
energy surface with MD, the sampling must be giased toward a specific
volume of phase space.</li>
<li>A central component in biased sampling method is the selection of
one or a few <em>collective variables (CV)</em> that can be used to
describe the reaction path.</li>
<li>A CV can be any function of atomic coordinates, but it must be
selected and defined by the user based on the given application.</li>
<li>A CV can be in the simplest case be the position of a point, a
distance between two points, an angle between three points or torsional
angle between four points, where the points can either be single atoms
or center of mass for a large group of atoms.</li>
<li>Once a set of CVs have been selected, the biasing can be done by two
different methods, the penalty approach or the Lagrange type approach,
analogously to the optimization of function with constraints.</li>
<li>A number of closely related methods have been proposed for
performing simulations with bias potentials, typically with the aim of
calculating free energy profiles along a suitable reaction coordinate,
and the following describe some of these approaches.</li>
<li>The penalty approach corresponds to augumenting the energy surface
with a biasing potential <span class="math inline">\mathcal{U}</span>,
for example a harmonic function centered at position <span
class="math inline">\xi_0</span> of the CV with a suitable width <span
class="math inline">k_{\mathcal{U}}</span>: <span class="math display">
\mathcal{V}_{\text{umbrella}}(\xi) = \mathcal{V}(\xi) + \mathcal{U}(\xi)
\\
\mathcal{U}(\xi) = k_{\mathcal{U}}\left(\xi - \xi_0\right)^2
</span></li>
<li>By making the potential <span class="math inline">\mathcal{U}</span>
sufficiently steep (large <span
class="math inline">k_{\mathcal{U}}</span>), the energy of the augmented
energy surface far from <span class="math inline">\xi_0</span> will be
come so high in energy that only the region near <span
class="math inline">\xi_0</span> will be sample at ambient temperatures.
This technique is called <em>umbrella sampling</em>.</li>
<li>The ensemble calculated with the augmented potential <span
class="math inline">\mathcal{V}_\text{umbrella}</span> will of course be
non-Boltzmann, but this can be deconvoluted as shown for a property
<span class="math inline">P</span>. <span class="math display">
\braket{P} = \frac{\braket{P(\xi)\exp(\mathcal{U}/k_B
T)}_{\mathcal{V}_\text{umbrella}}}{\braket{\exp(\mathcal{U}(\xi)/k_B
T)}_{\mathcal{V}_\text{umbrella}}}
</span></li>
<li>Here <span class="math inline">\braket{\
}_{\mathcal{V}_\text{umbrella}}</span> indicates an average over the
ensemble generated by the augmented potential. By performing a series of
simulations with biasing potential located at different positions along
the reaction path, the free energy along the reaction path often called
the <em>potential of mean force (PMF)</em>, can be calculated.</li>
<li>The Lagrange approach constrains the sampling to the <span
class="math inline">N-1</span> dimensional subspace corresponding to a
specific value of the CV, where the constraint is fulfilled by means of
an additional term in the Hamiltonian onvolving a Lagrange multiplier.
This is related to the extended Lagrange techniques, and is usually
referred to as <em>Blue moon sampling</em> in the literature (the term
“Blue moon” denotes the relatively rare phenomenon).</li>
</ul>
<h3 id="metadynamics">Metadynamics</h3>
<ul>
<li>A common feature of umbiased MD is the tendency of the simulation to
revisit the same region of phase space by random thermal motion due to
the presence of energy barriers substantially larger than the available
thermal energy.</li>
<li><strong>Metadynamics</strong> attempts to prevent this situation by
gradually adding repulsive Gaussian-shaped potential based on the
sampling history and can be thought of as gradually filling up the
energy minimum currently being sampled until the thermal energy is
sufficient for escaping to another minimum.</li>
<li>The bias potential is defiend in terms of CV and is for a single CV
given by <span class="math display">
\mathcal{U}_\text{metadyn}(\xi) = \sum_{t_0=0, \Delta, 2\Delta,
\cdots}^{t-\Delta}W\exp\left[-\frac{\left\{\xi(t)-\xi(t_0)\right\}^2}{2\sigma^2}\right]
</span></li>
<li>Here <span class="math inline">W</span> and <span
class="math inline">\sigma</span> are user-defined parameters
controlling the height and width of the Gaussian, and <span
class="math inline">\Delta</span> is the time interval between points on
the trajectory where the bias potential are placed. Equation above is
readily extended to include more than one C by simply including an
additional term in the exponential function for each additional CV.</li>
</ul>
<h2 id="x.-force-field">1-X. Force field</h2>
<ul>
<li>In force field method (also referred as molecular mechanics method),
calculation of the electronic energy for a given nuclear coordinate is
bypassed by writing the electronic energy as a parametric function of
the nuclear coordinates.</li>
<li>Parameters included in this function is fitted to experimental data
or higher level computational data, such as ab initio method.</li>
<li>The fundamental objects in the force field method are atoms, so
electrons are not considered as individual particles. This means that
bonding information must be provided explicitly rather than being the
result of solving the electronic Schrodinger equation.</li>
<li>This also means that the quantum aspects of the nuclear motion are
neglected, ans the dynamics of the atoms is treated by classical
mechanics, i.e. the Newton’s equation of motion.</li>
<li>Molecules, bulk materials, and surfaces are all described by a “ball
and spring” model in the force field method, with atom having different
sizes and “softness” and bonds having different length and
“stiffness”.</li>
<li>The idea of molecules being composed of atoms, which are
structurally similar in different molecules, is implemented in force
field as atom types. The atom type depends on the atomic number and the
type of chemical bonding it is involved in. For example, sp2-hybridized
carbon and sp3-hybridized carbon atoms are in different atom types.</li>
<li>The force field energy is written as a sum of terms, each describing
the energy required to distorting a molecule in a specific manner.</li>
<li><span class="math inline">E_{str}</span> is the energy function for
stretching a bond between two atoms, <span
class="math inline">E_{bend}</span> represents the energy required for
bending an angle, <span class="math inline">E_{tor}</span> is the
torsional energy for rotation around a bond. <span
class="math inline">E_{vdw}</span> and <span
class="math inline">E_{el}</span> describe the van der Waals and
electrostatic atom-atom interactions, and finally <span
class="math inline">E_{cross}</span> describe the coupling between the
first three terms.</li>
</ul>
<h3 id="advantage-and-limitation">Advantage and limitation</h3>
<ul>
<li>The main advantage of force field methods is the speed with which
calculations can be performed, enabling large systems to be treated.
Even with a laptop computers, molecules with several thousand atoms can
be optimized. This puts the applications in the regions of modeling
biomolecules such as proteins and DNA. Molecular modeling is now used by
many pharmaceutical companies.</li>
<li>For systems where good parameters are available, it is possible to
make very good predictions of geometries and relative energies. One of
ths main problems is of course the lack of parameters; if the molecule
is slightly out of the common dataset, it is very like that only poor
quality parameters exist, or not at all. This often happens for systems
containing the transition metal elements.</li>
</ul>
<h3 id="ensemble">Ensemble</h3>
<ul>
<li></li>
</ul>
<h2 id="x.-kinetic-monte-carlo">1-X. Kinetic Monte Carlo</h2>
<ul>
<li><p>Nowadays kinetic Monte Carlo (KMC) method is a popular tool to
describe a variety of phenomena related to e.g. transport (diffusion),
structures and properties of materials (e.g., crystal growth) or
equilibrium and non-equilibrium chemistry (catalysis).</p></li>
<li><p>Many elementary processes involved at surfaces of solids exhibit
high activation barriers. These barriers are usually much larger than
<span class="math inline">k_B T</span> and the corresponding processes
are thus classified as rare events, if only thermal energy is there to
drive them.</p></li>
<li><p>While the motion of of atoms occurs on picosecond time scales,
the time between consecutive high-barrier events can therefore be many
orders of magnitude longer.</p></li>
<li><p>The “life” of our system in the long time span between these rare
events is filled with vibrational motion around a single minimum on the
PES.</p></li>
<li><p>The relevant transitions to other (meta)stable states (or PES
basins) occur only occasionally.</p></li>
<li><p>On a mesoscopic time scale, the time evolution of our system
therefore manifests itself as a series of consecutive jumps from state
to state.</p></li>
<li><p>The longer the time the system spends in one basin, the more it
“forgets” how it actually got there. In other words, the state-to-state
jumps of the system constitute a so-called <em>Markov
chain</em>.</p></li>
<li><p>The change of the probability <span
class="math inline">P_i(t)</span> of the system to actually be in state
<span class="math inline">i</span> at time <span
class="math inline">t</span> depends only on the probabilities of
hopping out of the current state <span class="math inline">i</span> into
any other state <span class="math inline">j</span>, which is denoted as
<span class="math inline">k_{ij}</span>.</p></li>
<li><p>In the present context of chemical kinetics, these hopping
probabilities are expressed as rate constants of the elementary
processes with units <span class="math inline">{\rm
time}^{-1}</span>.</p></li>
<li><p>The overall change in <span class="math inline">P_i(t)</span> is
thus governed by a simple balancing equation, called a <strong>master
equation</strong>, that only contains these rate constants: <span
class="math display">
</span></p></li>
<li><p>As discussed above, the real trick of KMC is the KMC algorithm
that generates stochastic trajectories in such a way that their
appropriate averaging yields the time evolution of the probability <span
class="math inline">P_i(t)</span> in the master equation.</p></li>
<li><p>One of the most commonly used such KMC algorithm, initially
developed by Bortz et al. in 1975 for Ising spin systems, is known as
the <em>BKL algorithm</em>. This is also called as the <em>variable step
size method</em> or <em>direct method</em>.</p></li>
<li><p>Here for simplicity, let us consider a system in which only two
states <span class="math inline">A</span> and <span
class="math inline">B</span> connected by a barrier with associated rate
constants <span class="math inline">k_{AB}</span> and <span
class="math inline">k_{BA}</span> for the forward and backward
transitions, respectively.</p></li>
<li><p>In this system, only two elementary processes are possible; the
system is sitting in state <span class="math inline">A</span>, it can
hop to <span class="math inline">B</span>. As the rate constant for this
is <span class="math inline">k_{AB}</span>, one may naively think that
the average time that will passed until such an event occurs is <span
class="math inline">\Delta t_{AB} = k_{AB}^{-1}</span>, as the unit of
<span class="math inline">k_{AB}</span> is <span
class="math inline">{\rm time}^{-1}</span>. Obviously, for the hop back
from state <span class="math inline">B</span> to <span
class="math inline">A</span>, the average time would be <span
class="math inline">\Delta t_{BA} = k_{BA}^{-1}</span>.</p></li>
<li><p>Consequently, a KMC algorithm would generate a trajectory where
after each hop the time is incremented by <span
class="math inline">\Delta t_{AB}</span> or <span
class="math inline">\Delta t_{BA}</span>.</p></li>
<li><p>Mathematically, this naive thinking is not entirely correct. In
reality, while being in state <span class="math inline">A</span> for
each short increment of time, the system will have the same probability
of finding the escape path. This generates an exponentially decaying
survival statistics, whose derivative represents the probability
distribution <span class="math inline">p_{AB}</span> for the true time
of first escape as <span class="math display">
</span></p></li>
<li><p>The average escape time thus has to be appropriately weighted by
this Poisson distribution. It can be shown that this is achieved by
advancing the system clock by <span class="math display">
</span> where <span class="math inline">\rho_2 \in [0,1]</span> is a
randomly drawn number.</p></li>
</ul>
<h3 id="application-of-the-kmc">Application of the KMC</h3>
<ul>
<li><p>In this model, the RuO2(110) surface is considered to contain two
times of active sites; bride (br) and coordinately unsaturated (cus)
sites. Each site can be either empty or occupied by O or CO. A total of
26 processes are possible in this system, covering non-dissociative CO
adsorption/desorption, dissociative O2 adsorption/desorption, diffusion
of O and CO, and CO2 formation. The formed CO2 is assumed to desorb
instantaneously and irreversibly due to its weak binding to the
surface.</p></li>
<li><p>The Figure X shows the temporal evolution of the system at 1 bar
O2 and CO2 pressure and 450 K. The evolution starts from an empty RuO2
surface.</p></li>
<li><p>In the very first KMC steps, the coverage builds up quickly; the
O coverage builds up roughly double as fast as the CO coverage, as every
O2 dissociative adsorption yields two O atoms.</p></li>
<li><p>Once the steady-state solution has been reached, one can make use
of the ergodicity of the KMC simulation to calculate the desired
quantities as time averages instead of ensemble averages. Such
quantities are surface composition, occurrence of various elementary
steps, TOFs etc.</p></li>
<li><p>The average reaction rate is, for example, can be calculated as
follows; <span class="math display">
</span></p></li>
<li><p>Here <span class="math inline">t_{\rm KMC}</span> is the total
KMC simulation time, the first sum runs over all KMC steps <span
class="math inline">n</span> (up to a total <span
class="math inline">N_{\rm KMC}</span> steps), the second sum runs over
all states <span class="math inline">j</span> that are accessible from
the current state <span class="math inline">i</span>, <span
class="math inline">k_{ij}^{\beta}</span> is the rate constant for a
process involving the production of the molecule <span
class="math inline">\beta</span>, and <span class="math inline">\Delta
t_{\rm escape, n}</span> is the escape time for KMC step <span
class="math inline">n</span>.</p></li>
<li><p>The total simulation time should be chosen long enough to reduce
the statistical error on the sample quantities to a desired
value.</p></li>
</ul>
<h2 id="x.-machine-learning">1-X. Machine-Learning</h2>
<ul>
<li>The effective use of ML not only facilitates the discovery of
materials, but also helps to establish a deeper understanding of the
relationships between the properties of materials and their
functionalities.</li>
<li>In this section, we overview the application of the ML technique to
the catalytic chemistry.</li>
<li>The basic tools for the ML is first presented, and the application
to the catalytic chemistry is discussed later.</li>
</ul>
<h3 id="regression">regression</h3>
<ul>
<li><p>From the regression coefficient, one can identify the important
descriptor for the target variables.</p></li>
<li><p>Fig.X shows the heatmap of the regression coefficient on the
adsorption energy(?) calculated by the DFT method.</p></li>
<li><p>One can see that XXX is the most important descriptor.</p></li>
</ul>
<h3 id="machine-learning-force-field">Machine-learning force field</h3>
<ul>
<li><p>To perform MD simulations, typically the Newtonian equations of
motions are integrated numerically. This requires knowledge of the
forces acting on individual atoms at each time step of the
simulation.</p></li>
<li><p>In principle, the most accurate way to obtain these forces is by
solving the Schrodinger equation at each time step. However, this is
prohibitively demanding in terms of computational cost and
time.</p></li>
<li><p>Instead, simple empirical functions are commonly used to model
the relevant interactions. These are called force fields (FFs), and
atomic forces can be readily derived analytically. (Details of FF –&gt;
other part)</p></li>
<li><p>Machine learning (ML) methods could help in closing the gap
between the accuracy of ab initio methods and the efficiency of
classical FFs.</p></li>
<li><p>ML methods aim to learn the functional relationship between
inputs (chemical descriptors) and outputs (properties) from patterns of
structure in the data.</p></li>
<li><p>Practically, ML models can take a shortcut by not having to solve
any equations that follow from the physical laws governing the
structure-property relation.</p></li>
<li><p>For constructing ML-FFs, suitable reference data to learn the
relevant structure-property relation include energy, forces, or a
combination of both, obtained from ab initio calculations.</p></li>
<li><p>By introducing a parametric dependency between energy and nuclei,
the Born-Oppenheimer approximation implies the existence of a functional
relation <span class="math inline">f: \left\{ Z, r \right\}_{i=1}^N
\rightarrow E</span>, which maps the nuclear charges <span
class="math inline">Z_i</span> and positions <span
class="math inline">{\bf r}_i</span> of <span
class="math inline">N</span> atoms directly to their potential energy
<span class="math inline">E</span>.</p></li>
<li><p>This function, called the potential energy surface (PES), governs
the dynamics of a chemical system.</p></li>
<li><p>At each time step of a dynamics simulation, the forces <span
class="math inline">{\bf F}_i</span> acting on each atom <span
class="math inline">i</span> must be known so that the equation of
motion can be integrated numerically. They can be derived from the PES
by using the relation <span class="math inline">{\bf F}_i =
-\nabla_{{\bf r}_i}E</span>, that is, the forces are the negative
gradient of the potential energy <span class="math inline">E</span> with
respect to the atomic positions <span class="math inline">{\bf
r}_i</span>.</p></li>
</ul>
<h4 id="nn">NN</h4>
<ul>
<li>In the simplest case, the fundamental building blocks of neural
networks (NNs) are dense (or “fully-connected”) layers; linear
transformations from input vectors <span class="math inline">{\bf x}\in
\mathbb{R}^{n_{in}}</span> to output vectors <span
class="math inline">{\bf y} \in \mathbb{R}^{n_{out}}</span> according to
<span class="math display">
{\bf y} = {\bf W x} + {\bf b}
</span> where both weights <span class="math inline">W</span> and biases
<span class="math inline">b</span> are parameters, and <span
class="math inline">n_{in}</span> and <span
class="math inline">n_{out}</span> denote the number of dimensions of
<span class="math inline">{\bf x}</span> and <span
class="math inline">{\bf y}</span>, respectively.</li>
<li>Evidently, a single dense layer can only express linear
functions.</li>
<li>Nonlinear relations between inputs and outputs can only be modeled
when at least two dense layers are stacked and combined with a nonlinear
activation function <span class="math inline">\sigma</span>: <span
class="math display">
</span></li>
<li>Provided that the number of dimensions of the “hidden layer” <span
class="math inline">h</span> is large enough, this arrangement can
approximate any mapping between inputs <span
class="math inline">x</span> and outputs <span
class="math inline">y</span> to arbitrary precision, i.e. it is a
generation function approximator.</li>
<li>In theory, shallow NNs as shown above are sufficient to approximate
any functional relationship. However, deep NNs with multiple hidden
layers are often superior and were shown to be more
parameter-efficient.[153-156].</li>
<li>To construct a deep NN, L hidden layers are combined sequentially
<span class="math display">
</span> mapping the input <span class="math inline">{\bf x}</span> to
several intermediate feature representations <span
class="math inline">h_l</span>, until the output <span
class="math inline">y</span> is obtained by a linear regression on the
features <span class="math inline">h_L</span> in the final layer.</li>
<li>For PES construction, typically, the NN maps a representation of
chemical structure <span class="math inline">{\bf x}</span> to a
one-dimensional output representing the energy.</li>
<li>The parameters <span class="math inline">{\bf W}</span>, <span
class="math inline">{\bf b}</span> of and NN cannot be fitted in closed
form. Instead, they are initialized randomly and optimized (usually
using a variant of stochastic gradient descent) to minimize a loss
function that measures the discrepancy between the output of the NN and
the reference data, such as the means squared error (MSE).</li>
</ul>
<h4 id="neutral-network-potentials">Neutral network potentials</h4>
<ul>
<li><p>The first neural network potentials (NNPs) used a set of internal
coordinates, for example, distances and angles, as structural
representation to model the PES.[183-187]</p></li>
<li><p>Behller and Parrinello were the first to propose so-called
high-dimensional neutral network potentials (HDNNPs) where the total
energy of a chemical system is expressed as a sum over atomic
contributions.[114]</p></li>
<li><p>The total energy <span class="math inline">E</span> of the system
is obtained as the sum over all <span class="math inline">N_{\rm
atoms}</span> atoms in the system, as <span class="math display">
E = \sum_{\mu=1}^{N_{\rm atoms}}E_{\mu}
</span></p></li>
<li><p>For a multi-component system containing <span
class="math inline">N_{\rm elem}</span> elements, this equation becomes
a sum over all the atomic energy contributions of the elements. <span
class="math display">
E = \sum_{\nu=1}^{N_{\rm elem}}\sum_{\mu=1}^{N_{\rm atoms}}E_{\mu}^{\nu}
</span></p></li>
<li><p>For a given element, the atomic NNs are constrained to have the
same architecture – specifying the number of hidden layers and neurons –
and the same weight parameters.</p></li>
<li><p>The input of each atomic NN is a vector of atom-centered symmetry
functions, which describes the local chemical environments of the atoms.
These are defined by a cutoff radius <span
class="math inline">R_c</span>.</p></li>
<li><p>Several types of symmetry functions are available. These are all
many-body functions that depend simultaneously on the positions of all
the atoms inside <span class="math inline">R_c</span>. Their numerical
values are invariant with respect to rotation and translation as well as
the order of the neighboring atoms, and, thus, possess all the required
invariances.</p></li>
<li><p>At the cutoff radius, they decay to zero in both the value and
slope, according to the cutoff function <span class="math display">
f_c(R_{ij}) =
\begin{cases}
0.5\left[\cos\left(\frac{\pi R_{ij}}{R_c}\right)+1\right] &amp; (R_{ij}
\leq R_c) \\
0 &amp; (R_{ij} \gt R_c)
\end{cases}
</span> where <span class="math inline">R_{ij}</span> is the distance
between the central atom <span class="math inline">i</span> and its
neighbor <span class="math inline">j</span>.</p></li>
<li><p>The radial symmetry function is <span class="math display">
G_i^2 = \sum_j \exp\left[-\eta(R_{ij}-R_S)^2\right]\cdot f_c(R_{ij})
</span></p></li>
<li><p>This is a sum of products of a Gaussian function of the
interatomic distance and the cutoff function <span
class="math inline">f</span>. Radial functions with different Gaussian
exponents <span class="math inline">\eta</span> provides a radial
fingerprint of the neighboring atoms. The parameter <span
class="math inline">R_S</span> can be used to shift he centers of the
Gaussians to specific interatomic distances.</p></li>
<li><p>Since the radial functions alone are unable to distinguish
different angular arrangements of neighbors, a set of “angular
functions” should be used, which is <span class="math display">
G_i^4 = 2^{1-\zeta}\sum_j\sum_{k\neq
j}(1+\lambda\cos\theta_{ijk})^{\zeta}\cdot
f_c(R_{ij})f_c(R_{ik})f_c(R_{jk})
</span></p></li>
<li><p>This depends on the angles <span
class="math inline">\theta_{ijk}</span> centered at atom <span
class="math inline">i</span> and formed with neighbors <span
class="math inline">j</span> and <span class="math inline">k</span>,
which both needed to be within <span class="math inline">R_c</span>. The
use of a set of functions with different exponents <span
class="math inline">\zeta</span> allows a fingerprint of the angular
distribution to be obtained, while <span class="math inline">\lambda =
\pm 1</span> can be used to adjust the positions of the maxima and
minima of these functions.</p></li>
<li><p>The underlying assumption is that the energetic contribution
<span class="math inline">E_i</span> of each atom depends mainly on its
local chemical environment.</p></li>
<li><p>The introduction of HDNNPs inspired many NN architectures that
can be broadly categorized into two types; descriptor-based NNPs [116,
191-193] or the end-to-end NNPs.[160, 196-198].</p></li>
</ul>
<h5 id="steps">steps</h5>
<ul>
<li>The construction of any MLP consists of several steps.</li>
<li>First, an electronic structure method is chosen as a reference,
which is able to capture the correct physical behavior of the system.
This is very important, because the goal of the subsequent construction
of the MLP is to reacy a close numerical agreement of the energies (and
forces) with this reference method.</li>
<li>The construction of this reference set is often the computational
bottleneck in the construction of MLPs.</li>
<li>The structures must be carefully chosen to ensure that the important
features of the PES are present in the data set.</li>
<li>In a second step, the data are prepared for training the ML method.
This is done by transforming the atomic positions into a special set of
coordinates that has to meet several requirements. It is followed by the
fitting process, in which the parameters of the ML method are adjusted
to reproduce the reference data as accurately as possible. This is an
essential step, because the functional forms of ML methods have no
physical meaning, and the correct shape of the PES has to be learned
from the available electronic structure data.</li>
<li>Once the MLP is carefully validated, it is ready for
applications.</li>
<li>The training of the NN parameters can be carried out using total
energies and, if desired, using forces, which provide valuable local
information about the shape of the PES.</li>
<li>As a consequence of the locality of the atomic interactions, it is
possible to train HDNNPs by using small systems containing only a few
hundred atoms, and once constructed, they can be applied to much larger
systems.</li>
</ul>
<h4 id="descriptor-based-nnps">Descriptor-based NNPs</h4>
<ul>
<li>The first descriptor-based NNP introduced by Behller and Parrinello
uses atom-centered symmetry functions (ACSFs) consisting of two-body
terms <span class="math inline">G_i^2</span> and three-body terms <span
class="math inline">G_i^3</span>.</li>
<li>When sufficiently many <span class="math inline">G_i^2</span> and
<span class="math inline">G_i^3</span> with different parameters are
combined and stored in a vector <span class="math inline">x</span>, they
form a “fingerprint” of the local environment of atom <span
class="math inline">i</span>. This environment descriptor is then used
as input for a NN for predicting the energy contributions <span
class="math inline">E_i</span> of atoms <span
class="math inline">i</span> and the total energy <span
class="math inline">E</span> which is obtained by summation.</li>
<li>Since the ACSFs only use geometric information, they work best for
systems containing only atoms of one element, for example crystalline
silicon.[114] To describe multi-component systems, the symmetry
functions are duplicated for each combination of elements and separate
NNs are used to predict the energy contributions for atoms of the same
type.[205]</li>
<li>Most descriptor-based NNPs, such as ANI [194] and TensorMol,[195]
use variations of <span class="math inline">G_i^2</span> and <span
class="math inline">G_i^3</span> or Behller-Parrinello to construct the
environment descriptors <span class="math inline">x_i</span>.</li>
<li>The common feature for all variations of the descriptor-based NNPs
is that the functional form of the environment descriptor is
predetermined and manually designed.</li>
</ul>
<h4 id="end-to-end-nns">End-to-End NNs</h4>
<ul>
<li>A potential drawback of the previously introduced ACSFs is that they
must be chosen by an expert before training the NNs. If the choice of
symmetry functions is poor, for example when the resulting descriptor is
(nearly) identical for two very different structures, the expressive
power of the NNs and the achievable accuracy are limited.</li>
<li>Additionally, a glowing number of input dimensions can quickly
become computationally expensive, both for calculating the descriptors
and for evaluating NN. This is especially the case when modeling
multi-component systems.</li>
<li>In contrast to this, end-to-end NNPs directly take atomic types and
positions as inputs to learn suitable representations from the reference
data.</li>
<li>Likewise the descriptor-based NNPs, many end-to-end NNPs obtain the
total energy <span class="math inline">E</span> as a sum of atomic
contributions <span class="math inline">E_i</span>. However, those are
predicted from learned features <span class="math inline">x_i</span>
encoding information about the local chemical environment of each atom
<span class="math inline">i</span>. This allows them to adapt the
features based on the size and distribution of the training set as well
as the chemical property of interest during the training process.</li>
<li>Within the deep tensor neural network framework,[160], this is
achieved by iteratively refining the atomic features <span
class="math inline">x_i</span> based on neighboring atoms.</li>
<li>The atomic features <span class="math inline">x_i</span> can be
written in general as <span class="math display">
</span></li>
<li>Here the summation runs over all atoms within a distance <span
class="math inline">r_{\rm cut}</span> and a cutoff function <span
class="math inline">f_{\rm cut}</span> ensures smooth behavior when
atoms cross the cutoff. The “atom-wise” function <span
class="math inline">G^t</span> is used to refing the atomic features
after they have been updated with information from neighboring atoms
through the interaction function <span
class="math inline">F^t</span>.</li>
<li>Both <span class="math inline">F^t</span> and <span
class="math inline">G^t</span> functions are NNs, and varing between
specific end-to-end NNPs.</li>
<li>As only pairwise distances are used and the order of atoms is
irrelevant due to the commutative property of summation, the features
<span class="math inline">x_i</span> by Eq.X are automatically
rototranslationally and permutationally invariant.</li>
<li>Glimer et al. have cast graph networks of this structure as
message-passing neutral networks and proposed a variant that uses a
set2set decoder instead of a sum over energy contributions.[198,
208]</li>
<li>SchNet takes an alternative view of the problems and models
interactions between atoms with convolutions.[109]</li>
<li>PhysNet modified the energy function to include explicit terms for
electrostatic and dispersion interaction.[108]</li>
</ul>
<h5 id="data-collection">Data collection</h5>
<ul>
<li>A good starting point to assemble the reference data set is by
sampling the PES using ab initio molecular dynamics (AIMD).</li>
<li>Here, the temperature of the simulation determines which regions of
the PES and what energy ranges are explored. Sampling at higher
temperatures ensures that the model does not enter the “extrapolation
regime”, in which the NNPs are trained sufficiently. However, pure AIMD
sampling is only advisable when the intended application of the final ML
model involves the MD simulation for equilibrium or close to equilibrium
properties, where rate events do not play a major role.</li>
</ul>
<h2 id="x.-electronic-structure-analysis-and-catalysis">1-X. Electronic
Structure Analysis and Catalysis</h2>
<ul>
<li>Computational chemistry provides many types of information: the
electronic state, energetics, structures, optical properties, magnetic
properties, and so on.</li>
<li>Finding the relationship among these properties is helpful for
understanding and predicting the functions of materials.</li>
<li>For example, the relationship between electronic structure and the
energetics is useful for identifying the adsorption/desorption event or
chemical reactivity.</li>
<li>One of the most commonly used used way for this the d-band center
theory.</li>
</ul>
<h3 id="sabatier-principle">Sabatier principle</h3>
<ul>
<li>Optimal catalysts should bind the reactants strongly to break
required chemical bonds, but weakly enough to allow the removal of
intermediates or products. This physicochemical phenomenon is known as
<strong>Sabatier principle</strong>.</li>
<li>This principle is extremely useful for guiding the discovery of
catalytic materials with improved performance, but also imposes serious
constraints on design flexibilities and attainable outcomes.</li>
</ul>
<h3 id="density-of-state-dos">Density of state (DOS)</h3>
<ul>
<li>One of the primary quantities used to describe the electronic state
of a material is the electronic <strong>density of states
(DOS)</strong>; <span class="math display">
\rho(E) dE = \text{\{number of electronic states in } (E, E+dE)
\text{\}}
</span></li>
<li>Once a DFT calculation has been performed, the electronic DOS can be
determined by integrating the resulting electronic density in k-space.
As the details of the DOS are affected by the integration accuracy in
k-space, it is generally recommended to use a large number of k-points
to calculate the DOS.</li>
<li>The most straightforward definition of a metal is that metals are
materials with a nonzero DOS at the Fermi level.</li>
<li>One useful way to think about this is to consider what happens when
an electric field is applied to the metal. An electric field will
accelerate electrons to higher energies than the electrons have when
there is no field. In a metal, there are electronic states just above
the Fermi level that can be populated by these accelerated electrons,
and as a result the material can readily conduct electricity.</li>
<li>The DOS of the insulators have a different picture; its DOS can be
divided into two separate regions, the valence band and the conduction
band. The valence band is the collection of all occupied electronic
states, while all states in the conduction band are unoccupied (at T = 0
K). The region of energy that separates the valence and conduction bands
contains no electronic states at all; this is the band gap.</li>
<li>Materials with a band gap are classified as either semiconductors if
their band gap is “small”, or insulators if their band gap is “wide”.
The distinction between these two types of materials is somewhat
arbitrary, but band gaps larger than ~3 eV are typically considered as
wide band gaps.</li>
</ul>
<h4 id="ldos">LDOS</h4>
<ul>
<li>To interpret the electronic structure of a material, it is often
useful to understand what states are important in the vicinity of
specific atoms.</li>
<li>One standard way to do this is to use the <strong>local density of
states (LDOS)</strong>, defined as the number of electronic states at a
specified energy weighted by the fraction of the total electron density
for those states that appears in a specified volume around a
nuclei.</li>
<li>Typically, this volume is simply taken to be spherical; so to
calculate the LDOS we must specify the effective radii of each atom of
interest. This definition cannot be made unambiguously. If a radius that
is too small is used, information on electronic states that are
genuinely associated with the nuclei will be missed. If the radius is
too large, the LDOS will include contributions from other atoms.</li>
</ul>
<h4 id="bader-charge">Bader charge</h4>
<ul>
<li>It is often convenient to thing of atoms within bulk materials or
molecules as having net charges. In an ionic material such as <span
class="math inline">\ce{NaCl}</span>, for example, it is convenient to
associate charges of +1 and -1 (in units of electron charge) to <span
class="math inline">\ce{Na}</span> and <span
class="math inline">\ce{Cl}</span> atoms.</li>
<li>The ambiguity in defining the volumes used for LDOS calculations
illustrates why making this assignment from a calculated electron
density is not necessarily a simple task.</li>
<li>A widely used method within the plane-wave calculations is the
<strong>Bader decomposition</strong>, which uses stationary points in
the three-dimensional electron density to partition electrons among
different atoms.</li>
</ul>
<h3 id="d-band-model">d-band model</h3>
<ul>
<li><p>In the first-principle calculation, the analysis of the bulk or
surface by the DOS is often done especially when the adsorption
phenomena is important.</p></li>
<li><p>To analyze the interaction between adsorbate and surface, the
analysis based on <strong>d-band model</strong> is often carried out,
which uses the electronic DOS of the surface.</p></li>
<li><p>As the adsorbate approaches the surface, the adsorbate electronic
state will begin to interact with the electronic state of the
surface.</p></li>
<li><p>It is useful to divide the electronic states of transition metal
surfaces into two types: the sp-bands and the d-bands. The sp-bands
originate from the metal valence s and p atomic orbitals that interact
to form broad overlapping bands. The valence d orbitals of transition
metals are more localized than the s and p orbitals, and they
interaction more weakly and form narrower band close to the highest
occupied state, the Fermi level.</p></li>
<li><p>The metal-<span class="math inline">\sigma_u^*</span> interaction
usually leads to an attraction because the <span
class="math inline">\sigma_u^*</span>-derived anti-bonding level remains
unoccupied.</p></li>
<li><p>It depends on the position of the Fermi level whether the overall
interaction is purely attractive or not.</p></li>
<li><p>For transition metals, the Fermi level lies within the d-band
thus both the <span class="math inline">\sigma_g</span> and <span
class="math inline">\sigma_u^*</span>-derived bonding levels are
occupied while the anti-bonding states are empty. This causes an
attractive interaction.</p></li>
<li><p>For a noble metal, both the bonding and anti-bonding state of the
<span class="math inline">\sigma_g-d</span> interaction are occupied,
making this interaction repulsive. This is the reason why nobel metals
are noble i.e., less reactive than transition metals.</p></li>
<li><p>Recently, several improvements of d-band center theory e.g. its
spin-polarized version [Bhattacharjee, SciRep, 2016] or using upper
d-band edge instead of the d-band center has been proposed.[Xin, PRB,
2014]</p></li>
<li><p>The DOS projected onto the d-states that interact with the
adsorbate state can be characterized by the moments of the d DOS. The
first moment is the d-band center: <span class="math display">
\epsilon_d = \frac{\int_{-\infty}^{\infty}n_d(\epsilon)\epsilon
d\epsilon}{\int_{-\infty}^{\infty}n_d(\epsilon) d\epsilon}
</span> and the higher moments (n &gt; 1) <span class="math display">
\epsilon_d^{(n)} = \frac{\int_{-\infty}^{\infty}n_d(\epsilon)(\epsilon -
\epsilon_d)^n d\epsilon}{\int_{-\infty}^{\infty}n_d(\epsilon) d\epsilon}
</span> describe the shape of the band in more detail; the width (n =
2), the skewness (n = 3), and the kurtosis (n = 4).</p></li>
</ul>
<h1 id="chemical-kinetics-and-catalytic-activity">2. Chemical Kinetics
and Catalytic Activity</h1>
<!-- Jensen begin -->
<h2 id="transition-state-theory">Transition state theory</h2>
<ul>
<li>Consider a chemical reaction of the type <span class="math inline">A
+ B \rightarrow C + D</span>. The rate of reaction may be written as
<span class="math display">
\frac{d[C]}{dt} = \frac{d[D]}{dt} = -\frac{d[A]}{dt} = -\frac{d[B]}{dt}
= k[A][B]
</span></li>
<li>Here <span class="math inline">k</span> being the rate
constant.</li>
<li>If <span class="math inline">k</span> is known, the concentration of
the various species can be calculated at any given time from the initial
concentrations. At the microscopic level, the rate constant is a
function of the quantum states of <span class="math inline">A</span>,
<span class="math inline">B</span>, <span class="math inline">C</span>
and <span class="math inline">D</span>, that is the translational,
rotational, vibrational, and electronic quantum numbers.</li>
<li>The macroscopic rate constant is an average over such “microscopic”
rate constants, weighted by the probability of finding a molecule with a
given set of quantum numbers.</li>
<li>For systems in equilibrium, the probability of finding a molecule in
a certain state depends on its energy by means of the Boltzmann
distribution and the macroscopic rate constant thereby becomes a
function of temperature.</li>
<li>Stable molecules correspond to minima on the potential energy
surface within the Born-Oppenheimer approximation and a chemical
reaction can be described as nuclei moving from one minimum to
another.</li>
<li>In the lowest level of approximation, the motion is assumed to occur
along the path of least energy and this path forms the basis for the
<strong>transition state theory (TST)</strong>.</li>
<li>The <em>transition state (TS)</em> is the configuration that divides
the reactant and product parts of the potential energy surface.</li>
<li>In the multidimensional case, the TS is a first-order saddle point
on the potential energy surface, a maximum in the reaction coordinate
direction and a minimum along all other directions.</li>
<li>TST is a semi-classical theory where the motion along the reaction
coordinate is treated clasically, while the perpendicular directions
take into account the quantization of, for example, the vibrational
energy.</li>
<li>The probability of finding a molecule in a given quantum state is
proportional to <span class="math inline">\exp(-\Delta E/k_B T)</span>,
which is a Boltzmann distribution.</li>
<li>Assuming that the molecules at the TS are in equilibrium with the
reactant, the macroscopic rate constant can be expressed as <span
class="math display">
</span></li>
<li><span class="math inline">\Delta G^{\ddagger}</span> is the Gibbs
free energy difference between the TS and reactant, and <span
class="math inline">k_B</span> is the Boltzmann’s constant.</li>
<li>The TST expression only holds if all molecules that pass from the
reactant over the TS go on to the product.</li>
<li>The dividing surface separating the reactant from the product is a
hyperplane perpendicular to the reaction coordinate at the TS.</li>
<li>The TST assumption is that no-crossings occur, that is all molecules
passing through the dividing surface will go on to form the product.
These assumptions mean that the rate constant calculated from Eq.(14.2)
will be an upper limit to the true rate constant.</li>
</ul>
<h2 id="statistical-mechanics">Statistical mechanics</h2>
<ul>
<li>Most experiments are performed on macroscopic samples, which usually
contains ~<span class="math inline">10^20</span> particles.
Calculations, on the other hand, are performed on relatively few
particles, typically <span class="math inline">1-10^3</span>
particles.</li>
<li>The macroscopic result of an experimental measurement can be
connected with properties of the microscopic system. The temperature,
for example, is related to the average kinetic energy of the particles,
as <span class="math display">
\braket{E_{kin}} = \frac{3}{2}RT
</span></li>
<li>The connection between properties of a microscopic system and a
macroscopic sample is provided by statistical mechanics.</li>
<li>At a temperature of 0 K, all molecules are in their energetic ground
state but at a finite temperature there is a distribution of molecules
in all possible quantum energy states.</li>
<li>The relative probability <span class="math inline">P</span> of a
molecule being in a state with an energy <span
class="math inline">\mathcal{E}</span> at a temperature <span
class="math inline">T</span> is given by a Boltzmann factor, as <span
class="math display">
P \propto \exp\left(-\frac{\mathcal{E}}{k_B T}\right)
</span></li>
<li>The exponential dependence on the energy means that there is a low
(but non-zero) probability for finding a molecule in a high-energy
state.</li>
<li>The key feature in statistical mechanics is the <strong>partition
function</strong>. Just as the wave function is the cornerstone in
quantum mechanics, the partition function allows calculation of all
macroscopic functions in statistical mechanics.</li>
<li>The partition function for a single molecule is usually denoted
<span class="math inline">q</span>, and is defined as a sum of
exponential terms involving all possible quantum energy states. <span
class="math display">
q = \sum_{i={\rm states}}^\infty \exp\left(-\frac{\mathcal{E}_i}{k_B
T}\right)
</span></li>
<li>The partition function can also be written as a sum over all
distinct energy levels, multiplied with a degeneracy factor <span
class="math inline">g_i</span> that indicates how many states are with
the same energy <span class="math inline">\mathcal{E}_i</span>. <span
class="math display">
q = \sum_{i={\rm levels}}^\infty g_i \exp\left(-\frac{\mathcal{E}_i}{k_B
T}\right)
</span></li>
<li>The partition function may also viewed as the normalization factor
for the Boltzmann probability distribution, as <span
class="math display">
P(\mathcal{E}_i) = \frac{\exp\left(-\frac{\mathcal{E}_i}{k_B
T}\right)}{q}
</span></li>
<li><span class="math inline">q</span> is the partition function for a
single particle, and corresponding quantity <span
class="math inline">Q</span> for a collection on <span
class="math inline">N</span> non-interacting particles (ideal gas) is
given as <span class="math display">
Q = q^N \ \ (\text{different particles}) \\
Q = \frac{q^N}{N!} \ \ (\text{identical particles})
</span></li>
<li>If the particles are interacting (liquid or solid states), the
partition function <span class="math inline">Q</span> must be calculated
by summing over all energy states <span
class="math inline">\mathcal{E}_i</span> for the whole system.</li>
<li>The significance of the partition function <span
class="math inline">Q</span> is that thermodynamic functions, such as
the internal energy <span class="math inline">U</span> and Helmholtz
free energy <span class="math inline">A \ (A=U-TS)</span> can be
calculated from it. <span class="math display">
U = k_B T^2 \left(\frac{\partial \ln Q}{\partial T}\right)_V \\
A = -k_B T \ln Q
</span></li>
<li>Macroscopic observables, such as pressure <span
class="math inline">P</span> and heat capacity (at constant volume)
<span class="math inline">C_V</span>, may be calculated as derivatives
of thermodynamic functions. <span class="math display">
P = \left(\frac{\partial A}{\partial V}\right)_T = k_B T
\left(\frac{\partial \ln Q}{\partial V}\right)_T \\
C_V = \left(\frac{\partial U}{\partial T}\right)_V =
2 K_B T \left(\frac{\partial \ln Q}{\partial T}\right)_V + k_B T ^2
\left(\frac{\partial^2 \ln Q}{\partial T^2}\right)_V
</span></li>
<li>Other thermodynamic functions, such as the enthalpy <span
class="math inline">H</span>, the entropy <span
class="math inline">S</span>, and Gibbs free energy <span
class="math inline">G</span> may be constructed from these relations
<span class="math display">
H = U + PV = k_B T^2 \left(\frac{\partial \ln Q}{\partial T}\right)_V +
k_B T V \left(\frac{\partial \ln Q}{\partial V}\right)_T \\
S = \frac{U-A}{T} = k_B T \left(\frac{\partial \ln Q}{\partial
T}\right)_V + k_B \ln Q \\
G = H - TS = k_B T V \left(\frac{\partial \ln Q}{\partial V}\right)_T -
k_B T \ln Q
</span></li>
<li>In order to calculate the partition function, one needs to know all
possible quantum states for the system. In principle, these can be
calculated by solving the nuclear Schrodinger equation.</li>
<li>For an isolated polyatomic molecule, the energy levels for a single
conformation can be calculated within the <em>rigid-rotor harmonic
oscillator approximation</em>, where the electronic, vibrational,
rotational, and translational degrees of freedom are assumed to be
separable.</li>
</ul>
<h2 id="the-ideal-gas-rigid-rotor-harmonic-oscillator-approximation">The
ideal gas, rigid-rotor harmonic-oscillator approximation</h2>
<ul>
<li>For an isolated molecule, the total energy can be approximated as a
sum of terms involving translational, rotational, vibrational, and
electronic states, and this is a good approximation for the large
majority of the systems.</li>
<li>The assumption that the energy can be written as a sum of terms
implies that the partition function can be written as a product of
terms.</li>
<li>As the enthalpy and entropy contributions involve taking the
logarithm of <span class="math inline">q</span>, the product of <span
class="math inline">q</span>’s thus transforms into sums of enthalpy and
entropy contributions. <span class="math display">
\mathcal{E}_{tot} = \mathcal{E}_{trans} + \mathcal{E}_{rot} +
\mathcal{E}_{vib} + \mathcal{E}_{elec} \\
H_{tot} = H_{trans} + H_{rot} + H_{vib} + H_{elec} \\
S_{tot} = S_{trans} + S_{rot} + S_{vib} + S_{elec} \\
q_{tot} = q_{trans}q_{rot}q_{vib}q_{elec}
</span></li>
<li>For each of the partition functions, the sum over allowed quantum
states runs to infinity.</li>
<li>However, since the energies becomes larger, the partition functions
are finite. Let us examine each of the <span
class="math inline">q</span> factors in a little more detail.</li>
</ul>
<h3 id="translational-degrees-of-freedom">Translational degrees of
freedom</h3>
<ul>
<li>The translational degrees of freedom can be exactly separated from
the other <span class="math inline">3N-3</span> coordinates.</li>
<li>The allowed quantum states for the translational energy are
determined by placing the molecule in a “box”, i.e. the potential is
zero inside the box but infinite outside.</li>
<li>The solutions to the Schrodinger equation for such a “particle in a
box” are standing waves, cosine and sine functions.</li>
<li>The energy levels are associated with a quantum number <span
class="math inline">n</span>, and depend only on the total molecular
mass <span class="math inline">M</span>, <span class="math display">
\mathcal{E}_n = \frac{n^2h^2}{8\pi^2 M}
</span></li>
<li>Although the energy levels are quantized, the energy difference
between levels is so small that the distribution can be treated as
continuous.</li>
<li>The summation involved in the partition function can therefore be
replaced by an integral (an integral is just a sum in the limit of
infinitely small contributions). <span class="math display">
q_{trans} = \sum_{n=0}^\infty\exp\left(-\frac{\mathcal{E}_n}{k_B
T}\right)
  \approx \int_{n=0}^\infty dn \exp\left(-\frac{\mathcal{E}_n}{k_B
T}\right)
</span></li>
<li>Inserting the energy expression and performing the integration gives
<span class="math display">
q_{trans} = \left(\frac{2\pi M k_B T}{h^2}\right)V
</span></li>
<li>The only molecular parameter that enters is the total molecular mass
<span class="math inline">M</span>.</li>
<li>The volume <span class="math inline">V</span> depends on the number
of particles, and it is customary to work on a molar scale, in which
<span class="math inline">V</span> is the volume of 1 mol of (ideal)
gas.</li>
</ul>
<h3 id="rotational-degrees-of-freedom">Rotational degrees of
freedom</h3>
<ul>
<li>Within the rigid-rotor approximation, the rotation of the molecule
is assumed to occur with a fixed geometry.</li>
<li>The energy levels calculated from the rotational Schrodinger
equation for a diatomic “rigid rotor” are given in terms of a quantum
number <span class="math inline">J</span> and the moment of inertia
<span class="math inline">I</span>. <span class="math display">
\mathcal{E}_J = J(J+1)\frac{h^2}{8\pi^2 I}
</span></li>
<li><span class="math inline">J</span> runs from zero to infinity.</li>
<li>The moment of inertia is calculated from the atomic masses <span
class="math inline">m_1</span> and <span class="math inline">m_2</span>
and the distances <span class="math inline">r_1</span> and <span
class="math inline">r_2</span> of the nuclei relative to the center of
mass. <span class="math display">
I = m_1 r_1^2 + m_2 r_2^2
</span></li>
<li>For all molecules except very light species such as H2 or LiH, the
moment of inertia is so large that the spacing between the rotational
energy levels is much smaller than <span class="math inline">k_B
T</span> at ambient temperatures.</li>
<li>As for <span class="math inline">q_{trans}</span>, this means that
the summation in Eq.(13.10) can be replaced by an integral. <span
class="math display">
q_{rot} = \sum_{J=0}^\infty \exp\left(-\frac{\mathcal{E}_J}{k_B
T}\right) \approx \int_0^\infty dJ \exp\left(-\frac{\mathcal{E}_J}{k_B
T}\right)
</span></li>
<li>This yields <span class="math display">
q_{rot} = \frac{8\pi^2 I k_B T}{h^2 \sigma^2}
</span></li>
<li>The symmetry number <span class="math inline">\sigma</span> is 2 for
homonuclear system and 1 for a heteronuclear diatomic molecule.</li>
<li>For a polyatomic molecule, the equivalent of Eq.(13.24) is a 3x3
matrix, <span class="math display">
{\bf I} =
\begin{pmatrix}
\sum_i m_i (y_i^2 + z_i^2) &amp; -\sum_i m_i x_i y_i &amp; -\sum_i m_i
x_i z_i \\
-\sum_i m_i x_i y_i &amp; \sum_i m_i (x_i^2 + z_i^2) &amp; -\sum_i m_i
y_i z_i \\
-\sum_i m_i x_i z_i &amp; -\sum_i m_i y_i z_i &amp; \sum_i m_i (x_i^2 +
y_i^2)
\end{pmatrix}
</span></li>
<li>Here the coordinates are again relative to the center of mass.</li>
<li>By choosing a suitable coordinate transformation, this matrix may be
diagonalized, with the eigenvalues being the <em>moments of inertia</em>
and the eigenvectors called <em>principle axes of inertia</em>.</li>
<li>For a general polyatomic molecule, the rotational energy levels
cannot be written in a simple form. A good approximation, however, can
be obtained from classical mechanics, resulting in the following
partition function <span class="math display">
q_{rot} = \frac{\sqrt{\pi}}{\sigma}\left(\frac{8\pi^2k_B
T}{h^2}\right)^{3/2}\sqrt{I_1 I_2 I_3}
</span></li>
<li>Here <span class="math inline">I_i</span> are the three moments of
inertia.</li>
<li>The symmetry number <span class="math inline">\sigma</span> is the
order of the rotational subgroup in the molecular point group.</li>
<li>The rotational partition function requires only information about
the atomic masses and positions, i.e. the molecular geometry.</li>
</ul>
<h3 id="vibrational-degrees-of-freedom">Vibrational degrees of
freedom</h3>
<ul>
<li>In the lowest approximation level, the molecular vibrations may be
described by a harmonic oscillator. This can be derived by expanding the
energy as a function of the nuclear coordinates <span
class="math inline">R</span> in a Talyer series around the equilibrium
geometry <span class="math inline">R_0</span>. <span
class="math display">
E(R) = E(R_0) + \frac{dE}{dR}(R-R_0) +
\frac{1}{2}\frac{d^2E}{dR^2}(R-R_0)^2 + \cdots
</span></li>
<li>The first term may be taken as zero, since this is just the zero
point for the energy. The second term vanishes since the expansion is
around the equilibrium geometry.</li>
<li>Keeping only the lowest non-zero term results in the harmonic
approximation, where <span class="math inline">k</span> is the force
constant. <span class="math display">
E(\Delta R) \approx \frac{1}{2}\frac{d^2E}{dR^2}\Delta R^2 =
\frac{1}{2}k\Delta R^2
</span></li>
<li>Thus the energy levels obtained from the Schrodinger equation for a
one-dimensional harmonic oscillator (diatomic system) are given as <span
class="math display">
\begin{align*}
\epsilon_n &amp;= \left( n + \frac{1}{2} \right) h\nu \\
\nu &amp;= \frac{1}{2\pi}\sqrt{\frac{k}{\mu}} \\
\mu &amp;= \frac{m_1 m_2}{m_1 + m_2}
\end{align*}
</span></li>
<li>Here, <span class="math inline">n</span> is the vibrational quantum
number running from zero to infinity and <span
class="math inline">nu</span> is the vibrational frequency given in
terms of the force constant <span class="math inline">k</span> (<span
class="math inline">=\frac{d^2 E}{dR^2}</span>) and the reduced mass
<span class="math inline">\mu</span>.</li>
<li>In contrast to the translational and rotational energy levels, the
spacing between vibrational energy levels is comparable to <span
class="math inline">k_B T</span> for <span class="math inline">T</span>
around 300 K. Thus the summation for the vibrational partition function
<span class="math inline">q_{vib}</span> cannot be replaced by an
integral. However, due to the regular spacing, the infinite summation
can be written in a closed form as <span class="math display">
\begin{align*}
q_{vib}
&amp;= \sum_{n=0}^\infty \exp(-\epsilon_n/k_B T) = \exp(-h\nu/2k_B T) +
\exp(-3h\nu/2k_B T) + \exp(-5h\nu/2k_B T) + \cdots \\
&amp;= \exp(-h\nu/2k_B T)\left\{ 1 + \exp(-h\nu/k_B T) + \exp(-2h\nu/k_B
T) + \cdots \right\} \\
&amp;= \frac{\exp(-h\nu/2k_B T)}{1 - \exp(-h\nu/k_B T)}
\end{align*}
</span></li>
<li>In the infinite sum, each successive term is smaller than the
previous one by a constant factor <span
class="math inline">\exp(-h\nu/k_B T)</span>, which is smaller than one.
Therefore, the infinite sum can be expressed in a closed form.</li>
<li>For a polyatomic molecule, the force constant <span
class="math inline">k</span> is replaced by <span
class="math inline">3N_{atom} \times 3N_{atom}</span> matrix (the
Hessian matrix) containing the second derivative of energy with respect
to the coordinate as its matrix element.</li>
<li>By mass-weighting and diagonalizing this matrix, a new coordinate
system called as the <em>vibrational normal modes</em> is obtained.</li>
<li>In the vibrational normal modes, the 3N-dimensional Schrodinger
equation can be separated into 3N one-dimensional equations, each having
the form of a harmonic oscillator.</li>
<li>Of these 3N modes, three modes describe the translational motion,
and three (non-linear molecule) or two (linear molecule) modes describe
the rotational motion. Thus, <span class="math inline">3N-6</span> or
<span class="math inline">3N-5</span> modes describe the vibration.</li>
<li>In summary, within the harmonic approximation, the vibrational
degrees of freedom are decoupled in the normal modes. Since the energy
of the <span class="math inline">3N-6</span> vibrations can be written
as a sum the partition function can be written as a product over <span
class="math inline">3N-6</span> vibration partition functions, as <span
class="math display">
E_{vib} = \sum_{i=0}^{3N-6}\left( n_i + \frac{1}{2} \right)h\nu_i \\
q_{vib} = \sum_{i=0}^{3N-6}\frac{\exp(-h\nu_i/2k_B
T)}{1-\exp(-h\nu_i/k_B T)}
</span></li>
<li>The vibrational frequencies <span class="math inline">\nu_i</span>
are needed for calculation <span class="math inline">q_{vib}</span>.
These are obtained from the force constant matrix and atomic
masses.</li>
<li>If the stationary point is a minimum on the potential energy
surface, the eigenvalues of the Hessian are all positive. If, however,
the stationary point is a TS (a first-order saddle point), one of the
eigenvalues becomes negative thus the frequency is imaginary number. In
this case, the number of vibrational modes reduced to 3N-7, and the
summation up to this number should be taken.</li>
</ul>
<h3 id="electronic-degrees-of-freedom">Electronic degrees of
freedom</h3>
<ul>
<li>The electronic partition function <span
class="math inline">q_{elec}</span> involves the sum over electronic
quantum states.</li>
<li>These are the solutions to the electronic Schrodinger equation,
i.e. the ground state and an possible excited states.</li>
<li>In almost all molecules, the energy difference between the ground
and excited states is large compared with <span class="math inline">k_B
T</span>, which means that only the first term (the ground state energy)
in the partition function summation is important. <span
class="math display">
g_{elec} = \sum_{i=0}^\infty g_i \exp(-\epsilon_i/k_B T) \approx g_0
\exp(-\epsilon_0/k_B T)
</span></li>
<li><span class="math inline">g_i</span> is the degeneracy of the <span
class="math inline">i</span>-th electronic wave function, and it may be
either in the spin part (1 for singlet, 2 for doublet, etc.) or in the
spatial part (1 for <span class="math inline">A</span>, <span
class="math inline">B</span>, <span class="math inline">\Sigma</span>
representation in the point group, or 2 for <span
class="math inline">E</span>, etc.). The large majority of stable
molecule have <span class="math inline">g_0=1</span>.</li>
</ul>
<h3 id="enthalpy-and-entropy-contributions">Enthalpy and entropy
contributions</h3>
<ul>
<li>Given the partition function, the enthalpy and entropy terms may be
calculated by carrying out the required differentiations in
Eq.(13.18).</li>
<li>For one mole of molecules, the results for a non-linear system are
<span class="math display">
H_{trans} = \frac{3}{2}RT \\
H_{rot} = \frac{3}{2}RT \\
H_{vib} = R\sum_i^{3N-6}\left\{ \frac{h \nu_i}{2k} + \frac{h \nu_i}{k}
\frac{1}{\exp(h \nu_i/k_B T)-1} \right\} \\
H_{elec}^{TS} = \Delta E^\ddagger \\
S_{trans} = \frac{5}{2}R + R\ln\left\{ \frac{V}{N_A}\left( \frac{2\pi M
k_B T}{h^2} \right)^{3/2} \right\} \\
S_{rot} = R \left[ \frac{3}{2} + \ln\left\{
\frac{\sqrt{\pi}}{\sigma}\left(\frac{8\pi^2 k_B
T}{h^2}^{3/2}\sqrt{I_1I_2I_3} \right) \right\} \right] \\
S_{vib} = R\sum_i^{3N-6} \left[ \frac{h\nu_i}{k_B T}\frac{1}{\exp(h
\nu_i/k_B T)-1} -\ln\left\{ 1-\exp(-h\nu_i/k_B T) \right\} \right]
</span></li>
<li>The rotational terms are slightly different for a linear molecule,
and the vibrational terms will contain one vibrational contribution
more. <span class="math display">
H_{rot}({\rm linear}) = RT \\
S_{rot}({\rm linear}) = R\left[1+\ln\left(\frac{8 \pi^2 I k_B T}{\sigma
h^2}\right)\right]
</span></li>
<li>In summary, to calculate rate and equilibrium constants we need to
calculate <span class="math inline">\Delta G^\ddagger</span> and <span
class="math inline">\Delta G_0</span>. This can be done within the RRHO
approximation if the geometry, energy, and force constants are known for
the reactant, TS, and product.</li>
<li>The translational and rotational contributions are trivial to
calculate, while the vibrational frequencies require the full force
constant matrix (i.e. all energy second derivatives), which may be a
significant computational effort.</li>
<li>The activation enthalpies and entropies in principle depend on
temperature (Eq.X), but only weakly. Thus, for a limited temperature
range they may be treated as constants. Obtaining these quantities from
experiments is possible by measuring the reaction rate as a function of
temperature, and plotting <span class="math inline">\ln(k/T)</span>
against <span class="math inline">T^{-1}</span>. <span
class="math display">
k = \frac{k_B T}{h}\exp \left( -\frac{\Delta G^\ddagger}{RT} \right) \\
\ln\left(\frac{k_{rate}}{T}\right) = \ln\left(\frac{k_B}{h}\right) +
\frac{\Delta S^\ddagger}{R} - \frac{\Delta H^\ddagger}{RT}
</span></li>
<li>Such plots should produce a straight line with the slope being equal
to <span class="math inline">-\Delta H^\ddagger / R</span> and the
intercept equal to <span class="math inline">\ln(k_B/h) + \Delta
S^\ddagger / R</span>.</li>
<li>Experimentalists often analyze their data in terms of an Arrhenius
expression instead of the TST expression of Eq.(13.39), by plotting
<span class="math inline">\ln(k_{rate})</span> against <span
class="math inline">T^{-1}</span>. <span class="math display">
k = A\exp\left(-\frac{\Delta E^\ddagger}{RT}\right) \\
\ln k = \ln A - \frac{\Delta E^\ddagger}{RT}
</span></li>
</ul>
<!-- Jensen end -->
<h2 id="thermodynamics">2-1. Thermodynamics</h2>
<h3 id="potential-energy">Potential energy</h3>
<ul>
<li>The strength of the interaction is measured by the change in
potential energy of the system as a function of the distance <span
class="math inline">z</span>, of the adsorbate above the surface: <span
class="math display">
\Delta E(z) = E_{pot}(z) - E_{pot}(\infty)
</span></li>
<li>This is called the <strong>potential energy curve</strong>, and its
two-dimensional version is called the <strong>potential energy surface
(PES)</strong>.</li>
<li>The lowest energy pathway from one potential minimum on as PES to
another is called the <strong>minimum energy path (MEP)</strong>. The
MEP is formally defined as the path of least action: at any point along
the path, the gradient of the potential has no component perpendicular
to the path.</li>
<li>MEP is often considered as the reaction coordinate, and the highest
energy along the MEP is the transition state. This will be discussed
later.</li>
</ul>
<h3 id="zero-point-energy">Zero-point energy</h3>
<p>(need some simple introduction) * The quantized energy solutions of
the harmonic oscillator are given by <span class="math display">
E(n) = E_{pot} + h\nu_i \left( n+\frac{1}{2} \right)
</span> where is <span class="math inline">\nu_i</span> is the
vibrational frequency, <span class="math inline">h</span> is the
Planck’s constant, and <span class="math inline">n</span> is the quantum
number. The ground state, which is the lowest energy level, <span
class="math inline">n=0</span>, thus has an energy <span
class="math display">
E_0 = E_{pot} + \frac{1}{2}h\nu_i
</span> * The contributions from different vibrational modes are
additive. Thus if there are <span class="math inline">M</span>
vibrational modes in the potential energy minimum, the total
<strong>zero-point energy (ZPE)</strong> correction would be <span
class="math display">
ZPE = \sum_i^M \frac{1}{2} g_i h\nu_i
</span> Note that one should add degeneracy factor (<span
class="math inline">g_i</span>) for degenerated modes; <span
class="math inline">g_i = 2 (E)</span>, and <span
class="math inline">g_i = 3 (T)</span> (CHECK). * Frequencies larger
than 1000 <span class="math inline">{\rm cm^{-1}}</span> have
contributions to the ZPE at ~0.1 eV order. The H2 frequency is, for
example, as high as 4395 <span class="math inline">{\rm cm^{-1}}</span>
thus has significant contribution from ZPE. * The reaction energy for
ammonia synthesis, for example, comes out as much as 0.83 eV too
exothermic if one does not account for the ZPE corrections. * Often
experimentally measured frequencies are used for the ZPE calculation.
NIST webbook is often used.[NIST webbook]</p>
<h3 id="internal-energy">Internal energy</h3>
<ul>
<li>The amount of energy that needs to be transferred to warm up the
system (per temperature increase at a given temperature) is called the
<strong>heat capacity</strong>.</li>
<li>The sum of the ZPE-corrected ground-state energy <span
class="math inline">E_0</span> and the thermal energy of the system is
called the <strong>internal energy</strong>, and if we know the heat
capacity (at constant pressure) this is expressed as <span
class="math display">
U(T) = E_0 + \int_{T=0}^{T} C_P(T&#39;)dT&#39;
</span></li>
</ul>
<h3 id="gibbs-free-energy">Gibbs free energy</h3>
<ul>
<li>The key thermodynamic concept for describing equilibria in chemical
process is the *Gibbs free energy**, which is defined as <span
class="math display">
G = H - TS
</span> where <span class="math inline">H</span> is the enthalpy and
<span class="math inline">S</span> is the entropy. Enthalpy is defined
from the internal energy <span class="math inline">U</span> as <span
class="math display">
H = U - pV
</span> where <span class="math inline">p</span> is the pressure and
<span class="math inline">V</span> is the volume.</li>
<li>The potential energy describes a mechanical systems’s potential for
carrying out mechanical work, while the Gibbs energy describes a closed
chemical systems’ potential for carrying out non-expansion work.</li>
<li>The maximum amount of work carried out by a mechanical system is
only possible if all motion is frictionless; likewise, the maximum
amount of work by a chemical system is achieved if all reactions are
reversible.</li>
<li>The equilibrium of the system requires that any possible chemical
reaction that the system could undertake must satisfy the relation <span
class="math display">
\Delta G = G_{final} - G_{initial} = 0
</span> where <span class="math inline">G_{initial}</span> and <span
class="math inline">G_{final}</span> are the Gibbs free energies of a
given set of atoms before and after, respectively, they undergo some
chemical reaction.</li>
<li>The absolute Gibbs free energy incorporates a certain level of
arbitrariness through the dependence of the internal energy on the
ground-state potential energy. The commonly accepted standardized choice
is to define a standard state for every substance at a set of standard
conditions.</li>
<li>The standard condition for gas is chosen to be p = 1 bar, while for
solution the molarity of C = 1 mol solute/kg solvent at the standard
pressure of p = 1 bar.</li>
<li>For historical reasons, <span class="math inline">G^0</span> is
defined to be zero for the pure elements in their reference states. For
other substances, <span class="math inline">G^0</span> is the reaction
Gibbs energy for making it in their standard state from the constituting
elements in their reference state.</li>
<li>One typically always need the Gibbs energies of reaction, not the
absolute Gibbs energies themselves. The following relation is therefore
often used <span class="math display">
\Delta G^0 = \Delta H^0 - T\Delta S^0
</span></li>
<li>The <span class="math inline">\Delta</span> here indicate a change
in the given quantity as a reaction is undertaken.</li>
<li>For a pure substance X, we can write the Gibbs free energy as <span
class="math display">
G(p) = G^0(p) + k_B T \ln \left( \frac{p}{p^0} \right)
</span> where <span class="math inline">p^0</span> is the standard
pressure.</li>
<li>For a reaction <span class="math inline">\ce{A -&gt; B}</span>, the
change in Gibbs free energy is given by <span class="math display">
\begin{split}
\Delta G
&amp;= \Delta G^0 + k_B T \left( \ln \frac{p_B}{p^0} - \ln
\frac{p_A}{p^0} \right) \\
&amp;= \Delta G^0 + k_B T \ln \frac{p_B}{p^A}
\end{split}
</span></li>
<li>At equilibrium <span class="math inline">\Delta G = 0</span> and we
thus obtain <span class="math display">
\left. \frac{p_B}{p_A} \right|_{eq} = \exp \left( -\frac{\Delta G^0}{k_B
T} \right) = K_{eq}
</span> where we have introduced the equilibrium constant of the
reaction, <span class="math inline">K_{eq}</span>, which is
unitless.</li>
<li>Consider as an example of the ammonia synthesis reaction: <span
class="math inline">\ce{N2 + 3H2 -&gt; 2NH3}</span>.</li>
<li>Using the experimental value at 700 K of <span
class="math inline">\Delta H^0 = -0.95\ eV</span> and <span
class="math inline">\Delta S^0 = -2.05\ meV/K</span>, <span
class="math inline">\Delta G^0 = 0.49\ eV</span> then <span
class="math inline">K_{eq} \approx 0.0002</span>.</li>
<li>Thus, at this temperature, the equilibrium is strongly shifted
toward the reactants (N2 and H2).</li>
</ul>
<h3 id="enthalpy">Enthalpy</h3>
<p><span class="math display">
C_P = k_B + C_{V,\rm trans} + C_{V,\rm rot} + C_{V,\rm vib} + C_{V, \rm
elec}
</span> * The translational heat capacity is <span
class="math inline">3/2 k_B</span>. The rotational heat capacity is
<span class="math inline">k_B</span> and <span class="math inline">3/2
k_B T</span> for linear and non-linear molecule, respectively. The
electronic heat capacity is zero. * The integrated form of the
vibrational heat capacity is <span class="math display">
\int C_{V,\rm vib} dT = \sum_{i}^{N_{\rm
mode}}\frac{\epsilon_i}{e^{\epsilon_i/k_B T}-1}
</span> * Here, the degree-of-freedom is <span
class="math inline">3N-5</span> and <span
class="math inline">3N-6</span> for linear and non-linear molecules,
respectively.</p>
<h3 id="entropy">Entropy</h3>
<ul>
<li><p>The entropy can be thought of as a measure of the number of
accessible quantum states of a system. The entropy is proportional to
the logarithm of the number of accessible states <span
class="math inline">\Omega</span>, as <span class="math display">
S = k_B \ln \Omega
</span></p></li>
<li><p>The ideal gas entropy can be calculated as a function of
temperature and pressure, as <span class="math display">
\begin{split}
S(T,P) &amp;= S(T,P^0) - k_B \ln\frac{P}{P^0} \\
&amp;= S_{\rm trans} + S_{\rm rot} + S_{\rm vib} + S_{\rm elec} - k_B
\ln\frac{P}{P^0}
\end{split}
</span> where <span class="math inline">S_{\rm trans}, S_{\rm rot},
S_{\rm vib}, S_{\rm elec}</span> are translational, rotational,
vibrational, and electronic components of entropy. These are calculated
as below.</p></li>
<li><p>The translation entropy is <span class="math display">
S_{\rm trans} = k_B\left\{ \ln\left[ \left(\frac{2\pi M k_B
T}{h^2}\right)^{3/2}\frac{k_B T}{P^0} \right] + \frac{5}{2} \right\}
</span></p></li>
<li><p>The rotational entropy is <span class="math display">
S_{\rm rot} = \left\{
\begin{split}
&amp;k_B \left[ \ln\left(\frac{8\pi^2 I k_B T}{\sigma h^2}\right)+1
\right] \\
&amp;k_B \left\{ \ln\left[ \frac{\sqrt{\pi I_A I_B
I_C}}{\sigma}\left(\frac{8\pi^2 k_B T}{h^2}\right)^{3/2} \right] +
\frac{3}{2} \right\}
\end{split}
\right.
</span> where the upper and lower is linear and non-linear molecules.
Here, <span class="math inline">I_x</span> is the principle moments of
inertia. <span class="math inline">I</span> is the degenerate moments of
inertia, and <span class="math inline">\sigma</span> is the symmetry
number of the molecule.</p></li>
<li><p>The vibrational entropy is <span class="math display">
S_{\rm vib} = k_B \sum_i \left[ \frac{\epsilon_i}{k_B
T(e^{\epsilon_i/k_B T}-1)} - \ln(1-e^{-\epsilon_i/k_B T}) \right]
</span></p></li>
<li><p>The electronic entropy is <span class="math display">
S_{\rm elec} = k_B (2S+1)
</span> where <span class="math inline">S</span> is the spin
multiplicity.</p></li>
</ul>
<h2 id="chemical-kinetics">2-2. Chemical Kinetics</h2>
<h3 id="stoichiometry-and-reaction-rate">Stoichiometry and reaction
rate</h3>
<ul>
<li><p>We assume that a chemical process can be described by a single
<strong>stoichiometric equation</strong> or <strong>overall reaction
equation</strong>. Real chemical systems corresponding to such a single
chemical reaction, that is, when the reactants react with each other
forming products immediately, are in fact very rare.</p></li>
<li><p>In most cases, the reaction of the reactants produces
intermediates, these intermediates react with each other, and the final
products are formed at the end of many coupled reaction steps. Each of
the individual steps is called an <strong>elementary reaction</strong>
or <strong>elementary step</strong>.</p></li>
<li><p>Within elementary reactions, these is no macroscopically
observable intermediates between the reactants and the
products.</p></li>
<li><p>The overall reaction equation of the production of water from
hydrogen and oxygen is very simple: <span class="math display">
\ce{2H2 + O2 = 2H2O}
</span></p></li>
<li><p>From a stoichiometric point of view, a chemical equation can be
rearranged, similarly to mathematical equation. For example, all terms
can be shifted to the right-hand side as <span class="math display">
\ce{0 = -2H2 -O2 + 2H2O}
</span></p></li>
<li><p>Let us denote the formula of the chemical species by the vector
<span class="math inline">{\bf A}=(A_1, A_2, A_2)=(&quot;\ce{H2}&quot;,
&quot;\ce{O2}&quot;, &quot;\ce{H2O}&quot;)</span> and <span
class="math inline">\nu_1 = -2, \nu_2 = -1, \nu_3 = +2</span>. The
corresponding general stoichiometric equation is <span
class="math display">
0 = \sum_{j=1}^{N_s}\nu_j A_j
</span> where <span class="math inline">N_s</span> is the number of
species.</p></li>
<li><p>The general stoichiometric equation of any chemical process can
be defined in the same way, where <span class="math inline">\nu_j</span>
is the stoichiometric coefficient of th <span
class="math inline">j</span>-th species and <span
class="math inline">A_j</span> is the chemical formula of the <span
class="math inline">j</span>-th species in the overall reaction
equation.</p></li>
<li><p>We show here the stoichiometric coefficients for an overall
reaction equation, but the same approach is taken for the elementary
reactions. In general, for elementary reactions within a chemical
mechanism, the stoichiometric coefficients are integers.</p></li>
<li><p>Let us think about the time-dependent behavior of a chemical
system and how we might describe it using information from the kinetic
reaction system.</p></li>
<li><p>By measuring the molar concentration <span
class="math inline">Y_j</span> of <span class="math inline">j</span>-th
species at several consecutive time points, then by applying a
finite-difference approach, the production rate of the <span
class="math inline">j</span>-th species <span
class="math inline">dY_j/dt</span> can be calculated.</p></li>
<li><p>The rate of chemical reaction defined by stoichiometric equation
is the following: <span class="math display">
r = \frac{1}{\nu_j}\frac{dY_j}{dt}
</span></p></li>
<li><p>Reaction rate <span class="math inline">r</span> is independent
of index <span class="math inline">j</span>. This means that the same
reaction rate is obtained when the production rate of any of the species
is measured.</p></li>
<li><p>Within a narrower range of concentrations, the reaction rate
<span class="math inline">r</span> can always be approximated by the
following equation <span class="math display">
r = k\prod_{j=1}^{N_s}Y_j^{\alpha_j}
</span> where the positive scalar <span class="math inline">k</span> is
called the <strong>rate coefficient</strong>. The exponents <span
class="math inline">\alpha_j</span> are positive real numbers or
zero.</p></li>
<li><p>When the reaction rate is calculated by Eq.X, molar
concentrations (such as <span class="math inline">mol cm^{-3}</span>)
should always be used.</p></li>
<li><p>The rate coefficient <span class="math inline">k</span> is
independent on the concentration, but may depend on temperatures,
pressures, etc. Thus, it is better to call this quantity as <em>rate
coefficient</em> and not <em>rate constant</em>.</p></li>
<li><p>The exponent <span class="math inline">\alpha_j</span> is called
the <em>reaction order of species <span
class="math inline">A_j</span></em> and the sum of exponents (<span
class="math inline">\alpha = \sum_j A_j</span>) is called the
<em>overall order of the reaction</em>.</p></li>
<li><p>The physical dimension of the rate coefficient <span
class="math inline">k</span> depends on the overall order of the
reaction step. When the order of the reaction step is 0, 1, 2 or 3, the
dimension of <span class="math inline">k</span> is <span
class="math inline">\text{(concentration)}\times\text{(time)}^{-1}</span>,
<span class="math inline">\text{(time)}^{-1}</span>, <span
class="math inline">\text{(concentration)}^{-1}\times\text{(time)}^{-1}</span>,
or <span
class="math inline">\text{(concentration)}^{-2}\times\text{(time)}^{-1}</span>,
respectively.</p></li>
<li><p>As stated above, intermediates are formed within most reaction
systems. Hence, in order to define the time-dependent dynamics of a
system appropriately, a reaction model should include elementary
reactions were such intermediates are formed from reactants and go on to
form products.</p></li>
<li><p>For example, we can propose a simple reaction mechanism for the
hydrogen combustion reaction (Eq.X) as <span class="math display">
\begin{align*}
&amp;R1\hspace{5mm} \ce{H2 + O2      = H + HO2} \\
&amp;R2\hspace{5mm} \ce{O2 + H       = OH + O} \\
&amp;R3\hspace{5mm} \ce{H2 + OH      = H + H2O} \\
&amp;R4\hspace{5mm} \ce{H2 + O       = H + OH} \\
&amp;R5\hspace{5mm} \ce{O2 + H (+ M) = HO2 (+ M)} \\
&amp;R6\hspace{5mm} \ce{H2O + OH     = H2O + OH} \\
\end{align*}
</span> where <span class="math inline">M</span> represents any species
in the mixture.</p></li>
<li><p>Each elementary reaction step <span class="math inline">i</span>
can be characterized by the following stoichiometric equation: <span
class="math display">
\sum_j\nu_{ij}^L A_j = \sum_j\nu_{ij}^R A_j
</span> where the stoichiometric coefficient on the left-hand side
(<span class="math inline">\nu_{ij}^L</span>) and the right-hand side
(<span class="math inline">\nu_{ij}^R</span>) of an elementary reaction
<span class="math inline">i</span> should be distinguished. The net
stoichiometric coefficient of species <span class="math inline">j</span>
can be obtained as <span class="math inline">\nu_{ij} = \nu_{ij}^R -
\nu_{ij}^L</span>.</p></li>
<li><p><span class="math inline">\nu_{ij}^L</span> and <span
class="math inline">\nu_{ij}^R</span> should be positive integers, so
<span class="math inline">\nu_{ij}</span> can be positive or
negative.</p></li>
<li><p>Elements <span class="math inline">\nu_{ij}^L</span>, <span
class="math inline">\nu_{ij}^R</span>, and <span
class="math inline">\nu_{ij}</span> constitute the left-hand side, the
right-hand side, and the overall <em>stoichiometric matrix</em>,
respectively.</p></li>
<li><p>To emphasize the analogy with mathematical equations, so far the
equality sign (<span class="math inline">=</span>) was always used for
chemical reactions. From now on, arrows will be used for one-way (or
irreversible) chemical reactions (such as <span
class="math inline">\ce{A -&gt; B}</span>). Reversible reactions will be
denoted by double arrows (<span class="math inline">\ce{A &lt;=&gt;
B}</span>).</p></li>
<li><p>The stoichiometric equation of the elementary reaction should
corresponds to the real molecular changes.</p></li>
<li><p>Because of this, most of the elementary reactions are
<em>unimolecular</em> or <em>bimolecular</em> reactions, where one and
two particles (atoms, molecules, ions) are involved,
respectively.</p></li>
<li><p>Unimolecular reactions include the photochemical reaction
(e.g. <span class="math inline">\ce{NO2 + h\nu -&gt; NO + O}</span>),
the isomerization reaction, etc.</p></li>
<li><p>Most elementary reactions are bimolecular reaction, in which two
particles meet and both particles change chemically.</p></li>
<li><p>In some elementary reactions, a <em>third-body</em> is involved.
This can be a molecule of the bath gas (in most experiments argon or
nitrogen).</p></li>
<li><p>The rates of elementary reactions can be calculated by assuming
the <strong>law of mass action</strong>, as <span class="math display">
r_i = k_k \prod_j^{N_S}Y_j^{\nu_{ij}^L}
</span> where <span class="math inline">r_i</span> and <span
class="math inline">k_i</span> are the rate and the rate coefficient,
respectively, of reaction step <span class="math inline">i</span> and
<span class="math inline">Y_j</span> is the molar concentration of
species <span class="math inline">j</span>.</p></li>
<li><p>The <em>kinetic system of ordinary differential equations
(ODEs)</em> defines the relationship between the production rates of the
species and rates of the reaction steps <span
class="math inline">r_i</span>: <span class="math display">
\frac{dY_j}{dt} = \sum_i^{N_R}\nu_{ij}r_i \hspace{5mm} j=1,2,\cdots,N_S
</span></p></li>
<li><p>The above equation can also be written in a simpler form using
the vector of concentrations <span class="math inline">{\bf Y}</span>,
the stoichiometric matrix <span class="math inline">{\boldsymbol
\nu}</span> and the vector of the rates of reaction steps <span
class="math inline">{\bf r}</span>, as <span class="math display">
\frac{d{\bf Y}}{dt} = {\boldsymbol \nu}{\bf r}
</span></p></li>
<li><p>This means the number of equations in the kinetic system ODEs is
equal to the number of species in the reaction mechanism.</p></li>
<li><p>The rates of the reaction steps can be very different and may
span (even 10-25) orders of magnitude. Such differential equations are
called <em>stiff ODEs</em>.</p></li>
</ul>
<h4 id="examples">Examples</h4>
<ul>
<li>The example for the creation of the kinetic system of ODEs will be
based on a hydrogen combustion mechanism.</li>
<li>Using the law of mass action, the rates <span
class="math inline">r_1</span> to <span class="math inline">r_6</span>
of the reaction steps can be calculated from the species concentrations
and rate coefficients <span class="math display">
\begin{align*}
&amp;R1\hspace{5mm} \ce{H2 + O2      = H + HO2}   &amp; &amp;r_1 =
k_1[\ce{H2}][\ce{O2}]\\
&amp;R2\hspace{5mm} \ce{O2 + H       = OH + O}    &amp; &amp;r_2 =
k_2[\ce{O2}][\ce{H}]\\
&amp;R3\hspace{5mm} \ce{H2 + OH      = H + H2O}   &amp; &amp;r_3 =
k_3[\ce{H2}][\ce{OH}]\\
&amp;R4\hspace{5mm} \ce{H2 + O       = H + OH}    &amp; &amp;r_4 =
k_4[\ce{H2}][\ce{O}]\\
&amp;R5\hspace{5mm} \ce{O2 + H (+ M) = HO2 (+ M)} &amp; &amp;r_5 =
k_5[\ce{O2}][\ce{H}][\ce{M}]\\
&amp;R6\hspace{5mm} \ce{H2O + OH     = H2O + OH}  &amp; &amp;r_6 =
k_6[\ce{HO2}][\ce{OH}]\\
\end{align*}
</span> Here <span class="math inline">[\ce{M}]</span> is the sum of the
concentration of all species present.</li>
<li>The calculation of the production rates is based on Eq.X. For
example, the hydrogen atom H is produced in R1, R3, and R4, and, it is
consumed in R2 and R5, and it is not present in R6.</li>
<li>The line of the kinetic system of ODEs, corresponding to the
production of H is the following: <span class="math display">
\frac{d[\ce{H}]}{dt} = k_1[\ce{H2}][\ce{O2}] - k_2[\ce{O2}][\ce{H}] +
k_3[\ce{H2}][\ce{OH}] + k_4[\ce{H2}][\ce{O}] -
k_5[\ce{O}][\ce{H}][\ce{M}]
</span></li>
<li>In a similar way, the production of water can be described by the
following equations: <span class="math display">
\frac{d[\ce{H2O}]}{dt} = k_3[\ce{H2}][\ce{OH}] + k_6[\ce{HO2}][\ce{OH}]
</span></li>
</ul>
<h4 id="parametrising-rate-coefficients">Parametrising rate
coefficients</h4>
<h5 id="temperature-dependence-of-rate-coefficients">Temperature
dependence of rate coefficients</h5>
<ul>
<li>The temperature dependence of rate coefficient <span
class="math inline">k</span> is usually described by the
<strong>Arrhenius equation</strong>: <span class="math display">
k = A\exp(-E/RT)
</span> where <span class="math inline">A</span> is the pre-exponential
factor or <span class="math inline">A</span>-factor, <span
class="math inline">E</span> is the activation energy, <span
class="math inline">R</span> is the gas constant. The dimension of <span
class="math inline">E/R</span> is temperature, thus <span
class="math inline">E/R</span> is called the <em>activation
temperature</em>.</li>
<li>If the temperature dependence of the rate coefficient can be
described by the Arrhenius equation, named after a Swedish chemist
Svante Arrhenius who proposed this equation in 1889. Plotting <span
class="math inline">\ln(k)</span> as a function <span
class="math inline">1/T</span>, or <em>Arrhenius plot</em>, gives a
straight line. The slope of this line is <span
class="math inline">-E/R</span>, and the intercept is <span
class="math inline">\ln(A)</span>.</li>
<li>In high-temperature gas-phase kinetic systems, such as combustion
and pyrolytic systems, the temperature dependence of the rate
coefficient is usually described by the <em>modified Arrhenius equation
(or extended Arrhenius equation)</em>: <span class="math display">
k = AT^n \exp(-E/RT)
</span></li>
</ul>
<h3 id="reversible-reaction-steps">Reversible reaction steps</h3>
<ul>
<li>In theory, all thermal elementary reactions are <em>reversible</em>,
which means that the reaction products may react with each other to
reform the reactants.</li>
<li>Within the terminology used for reaction kinetics, a reaction step
is called <em>irreversible</em>, either if the backward reaction is not
taken into account or the reverse reaction is represented by a pair of
opposing irreversible reaction steps.</li>
<li>The irreversible and reversible reactions are denoted by a single
arrow <span class="math inline">\ce{-&gt;}</span> and the two-way arrow
<span class="math inline">\ce{&lt;=&gt;}</span>, respectively.</li>
<li>In such cases, a forward rate expression may be given such as
Arrhenius forms, and the reverse rate is calculated from the
thermodynamics properties of the species through the equilibrium
constants. Hence, if the forward rate coefficient <span
class="math inline">k_{f_i}</span> is known, the reverse rate
coefficient can be calculated from <span class="math display">
k_{r_i} = \frac{k_{f_i}}{K_{c_i}}
</span> where <span class="math inline">K_{c_i}</span> is the
equilibrium constant expressed in molar concentrations. <span
class="math inline">K_{c_i}</span> is obtained from the thermodynamic
property of species.</li>
</ul>
<p>(overlapping with CFD section) * In combustion systems,
thermodynamics properties are often calculated from 14 fitted polynomial
coefficients called NASA polynomicals for each species. Seven are used
for the low-temperature range <span class="math inline">T_{\rm
low}</span> to <span class="math inline">T_{\rm mid}</span> and seven
for the high-temperature range <span class="math inline">T_{\rm
mid}</span> to <span class="math inline">T_{\rm high}</span>. Typical
values are <span class="math inline">T_{\rm low} = 300\ K</span>, <span
class="math inline">T_{\rm mid} = 1000\ K</span>, and <span
class="math inline">T_{\rm high} = 5000\ K</span>. * The polynomial
coefficients are determined by fitting to tables of thermochemical or
thermodynamics properties, which are either measured values or
calculated using theoretical methods and statistical thermodynamics. *
The polynomial coefficients can then be used to evaluate various
properties at a given temperature (<span class="math inline">T</span>),
such as standard molar heat capacity (<span class="math inline">C_p^{\rm
o}</span>), enthalpy (<span class="math inline">H^{\rm o}</span>) and
entropy (<span class="math inline">S^{\rm o}</span>) as follows: <span
class="math display">
\begin{align*}
\frac{C_p^{\rm o}}{R} &amp;= a_1 + a_2 T + a_3 T^2 + a_4 T^3 + a_5 T^4
\\
\frac{H^{\rm o}}{RT}  &amp;= a_1 + \frac{a_2}{2}T + \frac{a_3}{3}T^2 +
\frac{a_4}{4}T^3 + \frac{a_5}{5}T^4 + \frac{a_6}{T} \\
\frac{S^{\rm o}}{R}   &amp;= a_1\ln(T) + a_2 T + \frac{a_3}{2}T^2 +
\frac{a_4}{3}T^3 + \frac{a_5}{4}T^4 + a_7 \\
\end{align*}
</span> where <span class="math inline">a_n</span> parameters are the
NASA polynomial coefficients. (end overlapping) * The standard molar
reaction enthalpy of species <span class="math inline">j</span> (<span
class="math inline">\Delta_r H_j^{\rm o}</span>) and entropy (<span
class="math inline">\Delta_r S_j^{\rm o}</span>) can be calculated from
the following equations: <span class="math display">
\frac{\Delta_r S_j^{\rm o}}{R} = \sum_{i=1}^I \nu_{ij}\frac{S_i^{\rm
o}}{R} \\
\frac{\Delta_r H_j^{\rm o}}{R} = \sum_{i=1}^I \nu_{ij}\frac{H_i^{\rm
o}}{RT}
</span> * The equilibrium constant <span class="math inline">K</span> in
terms of normalized pressure <span class="math inline">p/p^{\rm
o}</span> is then obtained from <span class="math display">
\Delta_r G^{\rm o} = -RT\ln K = \Delta_r H^{\rm o} - T \Delta_r S^{\rm
o} \\
K = \exp\left(-\frac{\Delta_r H^{\rm o}}{RT}+\frac{\Delta_r S^{\rm
o}}{R}\right)
</span> where <span class="math inline">p^{\rm o}</span> is the standard
pressure (such as <span class="math inline">10^5</span> Pa, 1 atm, or 1
bar). * The equilibrium constant in concentration units <span
class="math inline">K_c</span> is related to the equilibrium constant in
normalized pressure units <span class="math inline">K</span> by the
following: <span class="math display">
K_c = K\left(\frac{p^{\rm o}}{RT}\right)^{\Delta \nu}
</span> where <span class="math inline">\Delta \nu = \sum_i \nu_i</span>
is the sum of stoichiometric coefficients. * In this way, the reverse
rate coefficient for a thermal reaction can be defined by its forward
rate coefficient and the appropriate NASA polynomials for the component
species within the reaction.</p>
<h3 id="sensitivity-analysis">Sensitivity analysis</h3>
<h4 id="local-sensitivity-analysis">Local sensitivity analysis</h4>
<ul>
<li>For a spatially homogeneous, dynamical system, the change of the
concentrations in time can be calculated by solving the following
initial value problem: <span class="math display">
\frac{d {\bf Y}}{dt} = {\bf f}({\bf Y}, {\bf x}), \hspace{5mm} {\bf
Y}(t_0) = {\bf Y}_0
</span> where the parameter vector <span class="math inline">{\bf
x}</span> having <span class="math inline">m</span> elements may include
rate coefficients, Arrhenius parameters, thermodynamics data, etc.</li>
<li>Let us now look at the effect of changing parameter values on the
solution over time. Assume that the solution of the system of
differential equation above is calculated from time <span
class="math inline">t = 0</span> to time <span class="math inline">t =
t_1</span>. Here the value of parameter <span
class="math inline">j</span> is changed by <span
class="math inline">\Delta x_j</span> and the solution of the ODE is
continued until time <span class="math inline">t_2</span>. We denote
<span class="math inline">Y_i(t_2)</span> as the original solution and
<span class="math inline">\tilde{Y}_i(t_2)</span> as the modified
solution at time <span class="math inline">t_2</span>. The sensitivity
coefficient can be approximately calculated by a finite-difference
approximation: <span class="math display">
\frac{\partial Y_i}{\partial x_j}(t_1, t_2) \approx \frac{\Delta
Y_i(t_2)}{\Delta x_j} = \frac{\tilde{Y}_i(t_2)-Y_i(t_2)}{\Delta x_j}
</span></li>
<li>The effect of changes in parameter set <span
class="math inline">{\bf x}</span> on the concentrations at a given time
can be characterized by the following Taylor expansion: <span
class="math display">
\begin{align*}
Y_i(t, x+\Delta x) =&amp; Y_i(t,x) + \sum_{j=1}^m\frac{\partial
Y_i}{\partial x_j}\Delta x_j \\
&amp;+\sum_{k=1}^m\sum_{j=1}^m\frac{\partial^2 Y_i}{\partial x_k
\partial x_j}\Delta x_k \Delta x_j + \cdots
\end{align*}
</span></li>
<li>Here, the partial derivative <span class="math inline">\partial
Y_i/\partial x_j</span> is called the first-order local <em>sensitivity
coefficient</em>. The second-order partial derivative <span
class="math inline">\partial^2 Y_i/\partial x_k \partial x_j</span> is
called the second-order local sensitivity coefficient, etc.</li>
<li>Usually, only the first-order sensitivity coefficients <span
class="math inline">\partial Y_j/\partial x_j</span> are calculated and
interpreted.</li>
<li>The local sensitivity coefficient shows how the model solution <span
class="math inline">Y_i</span> changes as a consequence of a change in
value of parameter <span class="math inline">x_j</span> by a small
amount, assuming that all other parameters are fixed at their nominal
values.</li>
<li>The <em>sensitivity matrix</em> <span class="math inline">S</span>
has <span class="math inline">S_{ij} = \partial Y_i/\partial x_j</span>
as its element, thus this matrix is the linear approximation of the
effects of parameter changes on the model solutions.</li>
<li>The value of the sensitivity coefficient depends on the units used,
such as the rate coefficients. However, the unit of the rate
coefficients differs for the first-order reaction, second-order
reaction, etc. Thus, to make the sensitivity coefficients comparable,
<em>normalized sensitivity coefficients</em> <span
class="math inline">x_j/Y_i(\partial Y_i/\partial x_j)</span> is often
used. Normalized sensitivity coefficients are dimensionless and their
values are independent of the units of the model solution and the model
parameters.</li>
<li>If the model solution <span class="math inline">Y_i</span> can be
zero, usually <em>semi-normalized sensitivity coefficients</em> <span
class="math inline">x_j(\partial Y_i/\partial x_j)</span> are
calculated.</li>
<li>The sensitivity coefficients can be used to assess the effect of
changing one of the parameters by <span class="math inline">\Delta
x_j</span> at time <span class="math inline">t_1</span> as follows:
<span class="math display">
\tilde{Y}_i(t_2) \approx Y_i(t_2) + \frac{\partial Y_i}{\partial
x_j}\Delta x_j
</span></li>
<li>When several parameters are changed simultaneously at time <span
class="math inline">t_1</span> according to the parameter vector <span
class="math inline">\Delta {\bf x}(t_1)</span>, then the “perturbed”
solution <span class="math inline">\tilde{\bf Y}</span> at time <span
class="math inline">t_2</span> can be calculated knowing the original
solution <span class="math inline">{\bf Y}(t_2)</span> and the
sensitivity matrix, as <span class="math display">
\tilde{\bf Y}(t_2) = {\bf Y}(t_2) + {\bf S}(t_1, t_2) \Delta {\bf
x}(t_1)
</span></li>
<li>The sensitivity matrix depends on the time <span
class="math inline">t_1</span> of the parameter perturbation and the
time <span class="math inline">t_2</span> of inspection of the effect of
the parameter perturbation. Usually, time <span
class="math inline">t_1</span> is set to be identical to the initial
time of the kinetic system of differential equations, which is usually
<span class="math inline">t = 0</span>.</li>
</ul>
<h4 id="the-brute-force-method">The brute force method</h4>
<ul>
<li>In general, the local sensitivity matrix can only be determined
numerically. If the original system of kinetic differential equations
can be solved numerically, then the local sensitivity matrix can also be
calculated using the finite-difference approximations.</li>
<li>To calculate the sensitivity matrix in this way, we have to known
the original solution and the <span class="math inline">m</span>
solution obtained by perturbing each parameter one by one. All in all,
the kinetic system of OEDs has to be solved <span
class="math inline">m+1</span> times. This procedure is called the
<em>brute force method</em>.</li>
</ul>
<h4
id="principal-component-analysis-of-the-sensitivity-matrix">Principal
component analysis of the sensitivity matrix</h4>
<ul>
<li>Elements of the local concentration sensitivity matrix show the
effect of changing a single parameter on the calculated concentration of
a species. However, we are frequently interested in the effect of
parameter changes on the concentrations of a group of species. This
effect is indicated by the <em>overall sensitivity</em>, <span
class="math display">
B_j = \sum_i\left(\frac{x_j}{Y_i}\frac{\partial Y_i}{\partial
x_j}(t)\right)^2
</span></li>
<li>Quantity <span class="math inline">B_j</span> shows the effect of
changing parameter <span class="math inline">x_j</span> on the
concentration of all species present in the simulation at time <span
class="math inline">t</span>.</li>
<li>The utilization of such overall sensitivity measures for identifying
unimportant species or reactions, as part of the model reduction process
which will be discussed further in Sec. X.</li>
<li>If a group of species is important for us in the time interval <span
class="math inline">[t_1, t_2]</span>, we may be interested in which
parameters are highly influential on the measured concentrations. To
answer this question, the following scalar valued function, called the
objective function, will be used. <span class="math display">
Q(x) =
\int_{t_1}^{t_2}\sum_i\left(\frac{\tilde{Y}_i(t)-Y_i(t)}{Y_i(t)}\right)^2
dt
</span> where <span class="math inline">Y_i(t)</span> is the value of
variable <span class="math inline">i</span> at time <span
class="math inline">t</span> calculated by the original parameter set
and <span class="math inline">\tilde{Y}_i(t)</span> is the corresponding
value calculated with the altered parameter set. The objective function
shows the relative deviation of the two values, integrated over the time
interval <span class="math inline">[t_1, t_2]</span>.</li>
<li>The <em>principal component analysis</em> of matrix <span
class="math inline">{\bf S}</span> investigates the effect of the change
in parameters on the value of the objective function. The objective
function <span class="math inline">Q</span> can be approximated using
the local sensitivity matrix <span class="math inline">{\bf S}</span>:
<span class="math display">
Q({\boldsymbol \alpha}) = (\Delta{\boldsymbol \alpha}^T)\tilde{{\bf
S}}^{\rm T}\tilde{{\bf S}}(\Delta{\boldsymbol \alpha})
</span> where <span class="math inline">\Delta {\boldsymbol \alpha} =
\Delta \ln{\bf x}</span>, index <span class="math inline">T</span>
indicates the transpose and matrix <span class="math inline">\tilde{\bf
S}</span> is defined in the following way: <span class="math display">
\tilde{\bf S} = [\tilde{\bf S}_1, \tilde{\bf S}_2, \cdots, \tilde{\bf
S}_l]^T
</span></li>
<li>Sensitivity matrices <span class="math inline">\tilde{\bf S}_m =
{\partial \ln Y_i(t_m)/\partial \ln x_k}</span> belong to a series of
<span class="math inline">l</span> time points within time interval
<span class="math inline">[t_1, t_2]</span>, and the rows of these
matrices belong to the variables present in the summation of the
objective function. From the calculation of matrix <span
class="math inline">\tilde{{\bf S}}^{\rm T}\tilde{{\bf S}}</span>, the
sum of elements of matrices <span class="math inline">\tilde{\bf
S}_m</span> is obtained, and therefore the integral present in Eq.X is
replaced by a summation in Eq.X.</li>
<li>Let us denote <span class="math inline">{\boldsymbol \lambda}</span>
as the vector of eigenvalues of <span class="math inline">\tilde{{\bf
S}}^{\rm T}\tilde{{\bf S}}</span> and <span class="math inline">{\bf
U}</span> the matrix of eigenvectors. Another form of the objective
function is the following: <span class="math display">
Q({\boldsymbol \alpha}) = \sum_i\lambda_i(\Delta \Psi_i)^2
</span> where the transformed parameters <span
class="math inline">\Delta {\boldsymbol \Psi} = {\bf U}^{\rm
T}\Delta{\boldsymbol \alpha}</span> are called principal
components.</li>
<li>The eigenvector belonging to the largest eigenvalue defined a
parameter groups which have the largest influence on the objective
function.</li>
<li>On the other hand, the eigenvectors belonging to the small
eigenvalues has little effect on the solution of the model.</li>
<li>Thus, the principal component analysis provides a useful way to
interpret complex sensitivity information and to identify important
parameters that influence target outputs.</li>
</ul>
<h3 id="reduction-of-reaction-mechanisms">Reduction of reaction
mechanisms</h3>
<h4 id="directed-relation-graph-method">Directed relation graph
method</h4>
<ul>
<li><p>Methods for species and reaction removal based on directed
relation graphs (DRGs) with specified accuracy requirements have been
introduced by Lu and Law[Ref].</p></li>
<li><p>In their development of the method, Lu and Law suggested that
graph-based methods are highly suited to exploring couplings between
species.</p></li>
<li><p>This means that such methods may be applied to remove groups of
species that may be internally coupled, through, for example, fast
reactions, but are not strongly coupled to important processes with the
mechanism.</p></li>
<li><p>Each node in the DRG represents a species from the mechanism, and
an edge from vertex A to vertex B exists if and only if the removal of
species B would directly induce significant error to the production rate
of species A.</p></li>
<li><p>This means that an edge from A to B means that B has to be kep in
the mechanism to correctly evaluate the production rate of species
A.</p></li>
<li><p>DRG methods start from the selection of important species, called
“target species” in the DRG terminology. Using a DRG method, all species
closely connected to the target species are identified.</p></li>
<li><p>The various DRG-based reduction methods all state a
<em>connection weight</em> between paris of species.</p></li>
<li><p>These weights define the directed relation graph
structure.</p></li>
<li><p>Starting from the target species, an importance coefficient is
calculated for all other species, which quantifies how strongly a given
species is connected to the target species.</p></li>
<li><p>Then, all species are eliminated from the mechanism (with their
reactions) whose importance coefficient is below a user-defined
threshold.</p></li>
<li><p>The original DRG method of Lu and Law defines the connection
weight from species <span class="math inline">i</span> to species <span
class="math inline">j</span> in the following way: <span
class="math display">
R_{i \rightarrow j} = \frac{\sum_{\alpha \in C(i,j)}|\nu_{i
\alpha}r_{\alpha}|}{\sum_{\alpha \in R(i)}|\nu_{i \alpha}r_{\alpha}|}
</span> where <span class="math inline">R(i)</span> is the set of
reactions that are related to species <span
class="math inline">i</span>. <span class="math inline">C(i,j)</span> is
the set of reactions in which both species <span
class="math inline">i</span> and <span class="math inline">j</span>
participate. <span class="math inline">\nu_{i \alpha}</span> is the
stoichiometric coefficient of species <span class="math inline">i</span>
in reaction <span class="math inline">\alpha</span> and <span
class="math inline">r_{\alpha}</span> is the net reaction rate i.e. the
difference of the forward and backward rates.</p></li>
<li><p>A variant of the DRG method was suggested by Luo et al for the
reduction of reaction mechanism containing many isomers. Luo et
al. recommended the application of the maximum norm instead of the
summation: <span class="math display">
R_{i \rightarrow j} = \frac{\max_{\alpha \in C(i,j)}|\nu_{i
\alpha}r_{\alpha}|}{\max_{\alpha \in R(i)}|\nu_{i \alpha}r_{\alpha}|}
</span></p></li>
<li><p>The original DRG method of Lu and Law defines the importance
coefficient of species <span class="math inline">i</span> as <span
class="math display">
I_i =
\left\{
\begin{align*}
&amp; 1 \hspace{5mm} (\text{if species i is a target species}) \\
&amp; \max_{j \in S}(\min(R_{j \rightarrow i},\ I_j)) \hspace{5mm}
(\text{otherwise})
\end{align*}
\right.
</span></p></li>
<li><p>Here <span class="math inline">S</span> is the full set of
chemical species and <span class="math inline">R_{j\rightarrow i}</span>
is a connection weight, and it is simply assumed that if two species are
not connected, then <span class="math inline">R_{j\rightarrow i}</span>
= 0.</p></li>
<li><p>This approach defines the importance coefficient for species
<span class="math inline">i</span> as the smallest connection on any
path towards a target species.</p></li>
<li><p><span class="math inline">I_i</span> is calculated
iteratively.</p></li>
<li><p>A small threshold value <span class="math inline">\epsilon</span>
can be defined, and if <span class="math inline">I_i &lt;
\epsilon</span>, then species <span class="math inline">i</span> is
considered to be redundant for the simulation of the target
species.</p></li>
<li><p>Hence, in Fig.X, if A is an target species, then D must be
retained within the scheme since although it is not directly coupled to
A, it is part of the dependent set of A by meing directly coupled to B,
where B is coupled to A.</p></li>
<li><p>The DRG method was first applied to model system of ethylene
combustion (Lu and Law 2005, Lue 2011) with a full scheme of 70
species.</p></li>
<li><p>A value of <span class="math inline">\epsilon</span> of 0.16 gave
a skelton of 33 species, i.e. quite a substantial degree of
reduction.</p></li>
<li><p>In application to <span class="math inline">n</span>-heptane and
<span class="math inline">iso</span>-octane combustion using full
schemes of 561 and 857 species (Lu and Law 2006), <span
class="math inline">\epsilon</span> values of 0.19 and 0.17 resulted in
reduced schemes of 188 and 233 species, respectively.</p></li>
</ul>
<h4 id="from-chemkin">from CHEMKIN</h4>
<ul>
<li>The directed relation graph (DRG) method identifies unimportant
species in a reaction mechanism by resolving species coupling without
any a priori knowledge of the system.</li>
<li>It has a distinct advantage over the principle component analysis in
that it does not require the sensitivity analysis results.</li>
<li>Direct species coupling can be defined by the immediate error to the
production rate of a species <span class="math inline">A</span>,
introduced by the removal of another species <span
class="math inline">B</span> from the mechanism. Such immediate error,
noted as <span class="math inline">r_{AB}</span>, can be expressed as
<span class="math display">
r_{AB} =
\frac{\sum|\nu_{A,i}\omega_i\delta_{B,i}|}{\sum|\nu_{A,i}\omega_i|}
</span> where <span class="math display">
\delta_{B,i} =
\left\{
\begin{align*}
&amp; 1 \hspace{5mm} (\text{if the i-th reaction involves species B}) \\
&amp; 0 \hspace{5mm} (\text{otherwise})
\end{align*}
\right.
</span> Here, <span class="math inline">A</span> and <span
class="math inline">B</span> indicate the species, <span
class="math inline">i</span> indicate the <span
class="math inline">i</span>-th reaction of the mechanism, <span
class="math inline">\nu_{A_i}</span> indicates the stoichiometric
coefficient of species <span class="math inline">A</span> in teh <span
class="math inline">i</span>-th reaction, and <span
class="math inline">\omega_i</span> is the reaction rate of the <span
class="math inline">i</span>-th reaction.</li>
<li>When the immediate error <span class="math inline">r_{AB}</span> is
larger than a user-specified error-tolerance level, it means that the
removal of species <span class="math inline">B</span> from the mechanism
will introduce an error to the production rate of species <span
class="math inline">A</span> that is beyond that acceptable to the
user.</li>
</ul>
<h4 id="section">?</h4>
<ul>
<li>One can combine a series of elementary reactions into a complete
catalytic process. For example in the ammonia synthesis, the overall
reaction <span class="math display">
\ce{N2 + 3H2 -&gt; 2NH3}
</span> can be divided into following six elementary reactions <span
class="math display">
\begin{split}
\ce{&amp; N2 + 2$*$     -&gt; 2N$*$} \\
\ce{&amp; H2 + 2$*$     -&gt; 2H$*$} \\
\ce{&amp; N$*$ + H$*$   -&gt; NH$*$ + $*$} \\
\ce{&amp; NH$*$ + H$*$  -&gt; NH2$*$ + $*$} \\
\ce{&amp; NH2$*$ + H$*$ -&gt; NH3$*$ + $*$} \\
\ce{&amp; NH3$*$        -&gt; NH3 + $*$} \\
\end{split}
</span></li>
<li>Each elementary reactions have their own PED. Thus, one can combine
these PEDs into one, which consists of the PED for the full ammonia
synthesis reaction. The potential energy difference between the initial
and final states is the reaction energy of NH3 synthesis.</li>
</ul>
<h3 id="tof">TOF</h3>
<ul>
<li>For heterogeneous reactions, the areal rate is a good choice.
However, the catalyst can have the same surface area but different
concentrations of active sites. Thus, a definition of the rate based on
the number of active sites appears to be the best choice. The
<strong>turnover frequency (TOF)</strong> is the number of times the
catalytic cycle is completed (or turned-over) per active site per unit
time, and expressed as <span class="math display">
r_t = \frac{1}{S}\frac{dn}{dt}
</span> where <span class="math inline">S</span> is the number of active
sites.</li>
<li>Note that <span class="math inline">r_t</span> is a rate and not a
rate constant, so it is always necessary to specify all conditions such
as temperature or pressure.</li>
</ul>
<h3 id="transition-state-theory-1">Transition state theory</h3>
<ul>
<li><p>In this section we take up the question of how DFT calculations
can be used to calculated the rates of chemical process.</p></li>
<li><p>Everything is based on the potential energy surface
(PES).</p></li>
<li><p>In situations where the energy required for a chemical process is
considerably larger than the typical thermal energy, the net rate of the
process can be calculated using the transition state theory
(TST)</p></li>
<li><p>The fundamental idea of the TST is that the rate constant of the
process is (MORE) <span class="math display">
\begin{align*}
k = (\text{average thermal velocity of crossing the border}) \\
\times(\text{probability of finding atom at TS})
\end{align*}
</span></p></li>
<li><p>TST can be applied under the following assumptions:</p>
<ul>
<li>When developing a rate theory based on the existence of a PES, we
are therefore implicitly involving the Born-Oppenheimer approximation.
This approximation assumes that motion of the electrons is instantaneous
compared with the motion of the nuclei, such that for whatever motion,
we shall never move on an electronically excited state.</li>
<li>We shall in addition assume that the rate of quantum tunneling
through the potential barriers is negligible compared with the rate
obtained from the classical treatment.</li>
<li>The last assumption is that once the system attains a TS
configuration with a velocity toward the product region, it will
necessarily “react” and become the product. For such a configuration to
read to a reactive event, the system should not re-enter the reaction
region again shortly after moving into the product region.</li>
</ul></li>
<li><p>The rate at which the system traverses the infinitesimal region
of thickness around the TS, <span class="math inline">\delta x</span>,
is given by the average velocity orthogonal to the configuration space
TS: <span class="math display">
r = \frac{|v|}{\delta x}
</span> The average orthogonal velocity can be evaluated directly from
the Boltzmann distribution <span class="math display">
\begin{split}
&amp;|v| = |{\bf v} \cdot {\bf n}({\bf x})| \\
&amp;= \frac{\int_{TS}dx \int_{-\infty}^{\infty}dv |v\cdot n(x)|
                  e^{-V(x)/k_B T}
                  e^{-\sum_i\frac{1}{2}m_i v_i^2/k_B T}}
     {\int_{TS}dx\int_{-\infty}^{\infty}dv
                  e^{-V(x)/k_B T}
                  e^{-\sum_i\frac{1}{2}m_i v_i^2/k_B T}} \\
&amp;= \sqrt{\frac{k_B T}{2\pi\mu}}
\end{split}
</span></p></li>
<li><p>The probability of being in the <span class="math inline">\delta
x</span> region compared to the reactant region is given <span
class="math display">
P = \frac{q^{TS\pm \frac{\delta x}{2}}}{q^R}
= \frac{\sum_{i} \exp(-\epsilon_i/k_B T)}{\sum_{k} \exp(-\epsilon_k/k_B
T)}
</span></p></li>
</ul>
<p><span class="math display">
E_n = \frac{h^2 n^2}{8\mu \delta x^2}
</span></p>
<p><span class="math display">
q^{\delta x} = \sum \exp(-\epsilon_n/k_B T) = \sum \exp\left(
-\frac{h^2n^2}{8\mu\delta x^2}/k_B T \right)
</span></p>
<p><span class="math display">
q^{\delta x} \approx \int_{n=0}^{\infty} \exp\left(
-\frac{h^2n^2}{8\mu\delta x^2} /k_B T \right) dn
= \sqrt{\frac{2\pi\mu k_B T}{h^2}}\cdot \delta x
</span></p>
<p><span class="math display">
P = \frac{q^{TS\pm\frac{\delta x}{2}}}{q^R}
  = \frac{q^{\delta x}\cdot q^{TS}}{q^R}
    = \sqrt{\frac{2\pi\mu k_B T}{h^2}} \delta x \frac{q^{TS}}{q^R}
</span></p>
<ul>
<li>This gives us the TST rate constant as the product of the rate at
which the TS is traversed multiplied by the probability of the system to
be found in the TS: <span class="math display">
k_{TST} = r\cdot P =
\left( \sqrt{\frac{k_B T}{2\pi\mu}} \frac{1}{\delta x} \right)
\left( \sqrt{\frac{2\pi\mu k_B T}{h^2}} \delta x \frac{q^{TS}}{q^R}
\right)
</span> which reduces to <span class="math display">
k_{TST} = \frac{k_B T}{h}\cdot\frac{q^{TS}}{q^R}
</span></li>
<li>The partition function, <span class="math inline">q^{TS}</span>, is
now the partition function for being “in” the TS and not just the <span
class="math inline">\pm \delta/2</span> vicinity of the TS, thus now
excluding the mode perpendicular to the TS.</li>
<li>The relative partition function expression, <span
class="math inline">q^{TS}/q^R</span>, is as mentioned earlier an
expression for the relative probability of finding the system in the TS
compared to finding it in the reactant state.</li>
<li>Since one of the fundamental assumptions underlying the TST is that
the distribution of states in the reactant region and the TS is
thermally equilibrated. Thus it is reasonable to set the relative
partition functions equal to an equilibrium constant, which is defined
through the differences in standard Gibbs energy between the TS and the
reactant state: <span class="math display">
K_{TST} = \frac{q^{TS}}{q^R} = \exp\left( -\frac{G_{TS}^0 - G_R^0}{k_B
T} \right)
= \exp\left(-\frac{\Delta G_{TS}^0}{k_B T}\right)
</span> This means the overall rate constant has a very simple form:
<span class="math display">
k_{TST} = \frac{k_B T}{h}\exp\left(-\frac{\Delta G_{TS}^0}{k_B T}\right)
</span></li>
<li>It is expected that the TS for a unimolecular reaction may have a
structure similar to that of the reactant except for bond elongation
prior to breakage. If this is the case, <span class="math display">
\frac{k_B T}{h} \approx 10^{13} s^{-1}
</span></li>
<li>It has been experimentally verified that numerous unimolecular
reactions have rate constants with pre-exponential factors on the order
of <span class="math inline">10^{13} s^{-1}</span>. However, the
pre-exponential factor can be either larger or smaller than <span
class="math inline">10^{13} s^{-1}</span> depending on the details of
the TS.</li>
</ul>
<h3 id="pre-exponential">pre-exponential</h3>
<ul>
<li>Based on the collision theory, pre-exponential factor for the
adsorption is calculated with following equation <span
class="math display">
A_{ads} = \frac{\sigma^0(T,\theta)P_A A_{site}}{\sqrt{2\pi m_A k_B T}}
</span> where <span class="math inline">A_{site}</span> is the area of a
single active site for adsorption, <span class="math inline">m_A</span>
is the molecular mass. <span class="math inline">\sigma^0(T,
\theta)</span> is the sticking probability.</li>
</ul>
<h3 id="microkinetics">microkinetics</h3>
<ul>
<li>A catalytic reaction often involves several species and elementary
reactions.</li>
<li>Microkinetic analysis (or detailed reaction mechanism) treats a set
of elementary reactions.</li>
<li>Therefore, if is often more accurate than the kinetic analysis based
on the global rate expression.</li>
<li>If the thermal fluctuations are small enough compared with the
configuration? of the potential energy surface, but large enough that
the adsorbates can slowly diffuse around, the adsorbate structuring on
the surface will occur.</li>
<li>This complexity is often difficult to treat exactly, and the
solution of such problems with many interacting bodies is a key research
area of statistical mechanics. In statistical mechanics, an
often-utilized approximation to a solution is the so-called <strong>mean
field model</strong>.</li>
<li>In a mean field model, one replaces all the detailed interactions
between any one body and the rest of the system with an average or
“effective” interaction.</li>
<li>This replacement turns a many-body problem into a set of one-body
problems.</li>
<li>In catalysis, the term “mean field microkinetic modeling” commonly
refers to the specific microkinetic model in which all repulsive (or
attractive) interactions between adsorbates have been removed.</li>
</ul>
<h4
id="microkinetics-of-elementary-surface-processes-can-be-omitted">Microkinetics
of elementary surface processes (CAN BE OMITTED?)</h4>
<ul>
<li>Let us assume we have determined a rate constant, <span
class="math inline">k_{-}</span>, for the desorption of species A from a
surface. The rate at which desorption occurs from a given site on the
surface is proportional to the product of the rate constant and the
probability that a given site is occupied by A. This probability is
equal to the fractional coverage of the adsorbate on the surface, <span
class="math inline">\theta_A</span>. So, <span class="math display">
r_\text{desorption} = k_{-}\theta_{\rm A}
</span></li>
<li>Likewise, we would expect <span
class="math inline">r_\text{adsorption}</span> to be proportional to the
probability that a site is unoccupied, <span
class="math inline">\theta_{*}</span>. At equilibrium, this process is
described by <span class="math display">
r_\text{adsorption} = k_{+}p_{\rm A}\theta_*
</span></li>
<li>For the elementary reaction <span class="math display">
\ce{A + $*$ &lt;=&gt; A$*$}
</span> we can define the reaction fractions by <span
class="math display">
\left. \frac{\theta_{\rm A}}{p_{\rm A}\theta_*}\right|_{\rm eq} = K_{\rm
ads} = \exp\left(-\frac{\Delta G^o}{k_B T}\right)
</span> and at equilibrium, <span class="math display">
\gamma = \frac{\frac{\theta_{\rm A}}{p_{\rm
A}\theta_*}}{\left.\frac{\theta_{\rm A}}{p_{\rm A}\theta_*}\right|_{\rm
eq}}
</span></li>
<li>It is convenient to define the <strong>approach to
equilibrium</strong> (also sometimes called the
<strong>reversibility</strong>) for an elementary reaction or for an
overall reaction as the rate of the backward reaction divided by the
rate of the forward reaction.</li>
</ul>
<h4
id="microkinetics-of-several-coupled-elementary-surface-processes">Microkinetics
of several coupled elementary surface processes</h4>
<ul>
<li>Let us first focus on the simple catalytic cycle, whereby two
reactant gases, A2 and B reaction to form the gas AB. We assume that the
process proceeds in the two elementary steps, <span
class="math display">
\begin{align*}
\ce{A2 + 2$*$ &amp;-&gt; 2A$*$}&amp;    \ &amp;(\text{R1})\\
\ce{A$*$ + B  &amp;-&gt; AB + $*$}&amp; \ &amp;(\text{R2})
\end{align*}
</span> and that the rate constants for the elementary reactions have
already been determined.</li>
<li>We can now write up the reaction rate expressions <span
class="math display">
\begin{align*}
&amp; R_1 = r_1 - r_{-1} = k_1 p_{\rm A_2}\theta_*^2 - k_{-1}\theta_A^2
\\
&amp; R_2 = r_2 - r_{-2} = k_2 p_{\rm B}\theta_{\rm A} - k_{-2}p_{\rm
AB}\theta_*
\end{align*}
</span></li>
<li>In these expressions, <span class="math inline">R_1</span> describes
the net rate of <span class="math inline">\ce{A_2}</span> removal, and
<span class="math inline">R_2</span> describes the net rate of AB
formation. Since both of the two elementary reactions need to occur in
order for the product to be formed, and also since step1 changes the
coverage that goes into step 2, the two rate expressions must be solved
simultaneously in order to obtain the overall reaction rate.</li>
<li>If we think of the net rates in terms of what surface species they
create and remove, we see that reaction 1 creates 2A<em>, while reaction
2 removes 1A</em>. This establishes a differential equation for the time
development of the coverages of A: <span class="math display">
\frac{\partial \theta_{\rm A}}{\partial t} = 2 R_1 - R_2 = 2k_1 p_{\rm
A_2}\theta_*^2 - 2 k_{-1}\theta_{\rm A}^2 - k_2 p_{\rm B}\theta_{\rm A}
+ k_{-2}p_{\rm AB}\theta_*
</span></li>
<li>Though there are two coverages i.e. <span
class="math inline">\theta_A</span> and <span
class="math inline">\theta_{*}</span>, one differential equation is
enough to completely specify the reaction, because the fractional
coverage should sum to one (<em>site conservation</em> or <em>site
balance</em>), as <span class="math display">
\sum_i \theta_i = 1
</span></li>
<li>Significant reduction in the complexity of solving the microkinetic
equations can be achieved if we employ the approximation that the rate
of change of all the coverages is zero, that is, the <em>steady-state
approximation</em>: <span class="math display">
\frac{\partial\theta_i}{\partial t} = 0 \ \text{for all i}
</span></li>
<li>The steady-state approximation effectively turns the microkinetic
model from a set of coupled non-linear differential equations in time
into a time-independent algebraic root-finding problem, which is simpler
to solve.</li>
<li>For the reactions R1 and R2, the steady-state approximation amounts
to <span class="math display">
2k_1p_{\rm A_2}(1-\theta_{\rm A}^2) - 2k_{-1}\theta_{\rm A}^2 -
k_2p_{\rm B}\theta_{\rm A} + k_{-2}p_{\rm AB}(1-\theta_{\rm A}) = 0
</span></li>
<li>For many heterogeneous catalytic reactions, the overall reaction
rate is typically determined by one specific elementary reaction being
particularly “slow”.</li>
<li>Here, a useful concept is that of a <em>strongly rate-determining
reaction step</em>. By that, we shall mean a reaction step that is so
difficult that all the other reaction steps are equilibrated.
(Langmuir-Hishelwood-Hougen-Watson?)</li>
<li>To solve the reaction set (R1 and R2) in the strongly
rate-determining approximation, we write the rates in terms of the
following reversibilities: <span class="math display">
\begin{align*}
R_1 = k_1 p_{\rm A_2} \theta_*^2 (1-\gamma_1),\hspace{5mm}  \gamma_1 =
\frac{\theta_{\rm A}^2}{p_{\rm A_2}\theta_*^2}\frac{1}{K_1} \\
R_2 = k_2 p_{\rm B} \theta_{\rm A}(1-\gamma_2),\hspace{5mm} \gamma_2 =
\frac{p_{\rm AB}\theta_*}{p_{\rm B}\theta_{\rm A}}\frac{1}{K_2}
\end{align*}
</span></li>
<li>We note that a general feature for a serial catalytic cycle, which
relies on reaction step <span class="math inline">i</span> being carried
out <span class="math inline">n_i</span> times, the overall equilibrium
constant is given by <span class="math inline">K_{\rm eq} = \prod_i
K_i^{n_i}</span> and the reversibility of the overall reaction is <span
class="math inline">\gamma = \prod_i\gamma_i^{n_i}</span>. For the
reaction in question, we have <span class="math inline">n_1 = 1</span>
and <span class="math inline">n_2 = 2</span>, so the overall equilibrium
constant is <span class="math inline">K_{\rm eq} = K_1 \cdot
K_2^2</span>, and the overall reversibility is <span
class="math inline">\gamma_{\rm eq} =
\gamma_1\cdot\gamma_2^2</span>.</li>
<li>Let us now assume that R1 is the rate-determining step. This means
that <span class="math inline">\gamma_2 = 1</span> and thus <span
class="math inline">\gamma_1 = \gamma_{\rm eq}</span>.</li>
<li>From Eq.X, we get the coverage of free sites as <span
class="math display">
\theta_{*} = \frac{1}{1+p_{\rm AB}p_{\rm B}^{-1}K_2^{-1}}
</span> and the coverage of A as <span class="math display">
\theta_{A} = \frac{p_{\rm AB}p_{\rm B}^{-1}K_2^{-1}}{1+p_{\rm AB}p_{\rm
B}^{-1}K_2^{-1}}
</span></li>
<li>The rate of reaction then found by taking the rate of the
rate-determining step (R1) as the rate of R2 is zero. By inserting the
appropriate coverages and using the reversibility of the overall
reaction (<span class="math inline">\ce{A2 + 2B -&gt; 2AB}</span>) <span
class="math display">
\gamma = \frac{p_{\rm AB}^2}{p_{\rm A_2}p_{\rm B}^2}\frac{1}{K_{\rm eq}}
= \frac{p_{\rm AB}^2}{p_{\rm A_2}p_{\rm B}^2 K_1K_2^2}
</span> one finally has the rate of the overall reaction as <span
class="math display">
R = k_1p_{\rm A_2}\theta_{*}^2(1-\gamma) = k_1p_{\rm
A_2}\frac{1}{(1+p_{\rm AB}p_{\rm B}^{-1}K_2^{-1})^2}\left(1-\frac{p_{\rm
AB}^2}{p_{\rm A_2}p_{\rm B}^2 K_1K_2^2}\right)
</span></li>
</ul>
<h3 id="activity-map">Activity map</h3>
<h4 id="one-dimensional">one-dimensional</h4>
<ul>
<li>From the scaling relation between <span class="math inline">\Delta
E</span> and <span class="math inline">E_a</span>, there is only one
independent variable, which we choose to be <span
class="math inline">\Delta E</span>.</li>
<li>Based on this feature, the reaction rate R or turn-over-frequency
(TOF) can be evaluated as the function of <span
class="math inline">\Delta E</span>, i.e. <span class="math inline">R =
f(\Delta E)</span>.</li>
<li>Here, following assumptions are made
<ul>
<li>the reaction energy of the overall reaction is set to <span
class="math inline">-0.3\ eV</span></li>
<li>the entropies of all the gas-phase species (A2, AB, and B) are set
to <span class="math inline">0.001\ eV/K</span></li>
<li>the entropy of A adsorbed on the surface is assumed to be
negligible</li>
<li>the pre-exponential factor for the dissociative adsorption of A2
(R1) is set to <span class="math inline">k_B T/h</span></li>
<li>dissociation of A2 follows a transition state scaling relationship
of <span class="math inline">\alpha = 0.87</span> and <span
class="math inline">\beta = 1.34\ eV</span>.</li>
</ul></li>
<li>The dependence of <span class="math inline">k_1</span> and <span
class="math inline">\theta_*</span> on <span class="math inline">\Delta
E</span> are shown in Fig.X.</li>
<li>Since the reaction rate or TOF depends on the product of <span
class="math inline">k_1</span> and <span
class="math inline">\theta_*</span>, it also depends on <span
class="math inline">\Delta E</span>, as shown in the Figure.</li>
<li>By decreasing the <span class="math inline">\Delta E</span>, the
number of free sites <span class="math inline">\theta_*</span> decreases
dur to the poisoning of the surface by species <span
class="math inline">A*</span>, while <span
class="math inline">k_1</span> increases because it leads to the smaller
Ea value.</li>
<li>As a result, the maximum TOF is obtained at <span
class="math inline">\theta_* ~ 0.5?</span>.</li>
<li>This represents the <strong>Sabatier principle</strong>, which
states that the catalytic activity for a given reaction follows a
volcano-shape curve, because only an intermediate binding of
intermediates on the surface of a catalyst will give a reasonably active
catalyst.</li>
</ul>
<h4 id="two-dimensional">two-dimensional</h4>
<ul>
<li>Scaling relations always provide a way to reduce the number of
independent variables characterizing the catalyst, but in most cases,
more than one descriptor is necessary.</li>
<li>An example where two descriptors are necessary is the CO methanation
reaction (or Sabatier reaction) <span class="math display">
\ce{CO + 3H2 -&gt; CH4 + H2O}
</span></li>
<li>The elementary reactions should be <span class="math display">
\begin{align*}
\ce{should} \\
\ce{see} \\
\ce{the paper}
\end{align*}
</span></li>
<li>The reaction rate is given by <span class="math display">
R = k_2 \theta_\ce{CO}\theta_*(1-\gamma)
</span></li>
<li>The activity map for the CO hydrogenation is shown in Figure X. It
shows a single maximum for <span class="math inline">(\Delta E_C, \Delta
E_O) \approx (0.5\ eV, -3.0 \ eV)</span>, thus Ru and Co is the
transition metal elements closest to the maximum. This agrees with the
experimental trends.</li>
<li>Knowing the optimum value for (<span class="math inline">\Delta E_C,
\Delta E_O</span>) allows a search for other catalysts for this
process.</li>
<li>SUMMARY: to draw the activity map, one should (i) express the
overall reaction rate by some descriptors, (ii) draw the rate by the
function of selected descriptors. The number of descriptors is equal to
the dimension of the activity map.</li>
</ul>
<h2 id="x.-chemical-process-on-surface">3-X. Chemical Process on
Surface</h2>
<h3 id="adsorption-and-desorption">adsorption and desorption</h3>
<ul>
<li><p>There are two types of adsorptions. One is
<strong>physisorption</strong>, mainly driven by van der Waals forces.
This occurs due to an attraction between mutually induced dipoles of the
electron clouds surrounding the atom or molecule and in the
surface.</p></li>
<li><p>Close to the surface, when the electron clouds of the adsorbate
and surface begins overlapping, chemical bonds may for or broken. This
stronger form of adsorption is called
<strong>chemisorption</strong>.</p></li>
<li><p>In principle, the adsorption energy can be measured; from the
measured rate of desorption (<strong>temperature-programmed desorption
(TPD)</strong>). Another way is to measure the temperature increase of a
surface when it is covered by adsorbates
(<strong>calorimetry</strong>)</p></li>
<li><p>Many of the interesting things that happen with surfaces, of
course, occur when other chemicals are present on them.</p></li>
<li><p>As an example, let us perform some calculations to understand how
H atoms bind on Cu(100) surface.</p></li>
<li><p>Perhaps the simplest question we can ask is: where on the surface
does H prefer to be? If we look at the Cu(100) surface, there are
several sites with special symmetry that are intuitively appearing as
the potential binding sites for H.</p></li>
<li><p>We define a supercell containing a slab model of Cu(100), place
an H atom relatively close to the top layer of the surface in some
positions, and then minimize the systems’s energy while allowing several
of the surface layers and the H atoms positions to relax.</p></li>
<li><p>How strongly do the atoms prefer to be on the surface instead of
building in the gas phase? This question is usually answered by
calculating the adsorption energy os species on the surface. One
possible definition for this quantity is <span class="math display">
E^{atomic}_{ads} = E_{H/surf} - [E_{H(gas)} + E_{surf}]
</span> Here, the three terms on the right are the total energy of
surface with H adsorbed on int, the total energy of a single H atom by
itself in the gas phase, and the total energy of the bare surface. This
definition is easy to use, but chemically unnatural because H atoms
rarely exist by themselves for very long. A more physically meaningful
quantity is the energy gained (or lost) by pulling two H atoms off the
surface and forming an H2 molecule in the gas phase. This is <span
class="math display">
E_{ads} = E_{H/surf} - [1/2E_{H_2(gas)} + E_{surf}]
</span></p></li>
<li><p>The surface coverage possible contributes the adsorption energy.
Because we are using periodic boundary conditions, putting one adsorbate
oin our supercell automatically means that each adsorbate “sees” a copy
of itself in each of the neighboring supercell.</p></li>
<li><p>The size of the supercell controls the distance between
adsorbates. If the supercell is small, it defines a surface with a high
density (or coverage) of adsorbates. If the supercell is large, surfaces
with lower coverages can be defined. When there is one adsorbate per
surface atom, the adsorbate layer is often said to have a coverage of 1
monolayer (ML). If these is one adsorbate per two surface atoms, the
coverage is 0.5 ML and so on.</p></li>
</ul>
<h4 id="adsorbate-adsorbate-interaction">adsorbate-adsorbate
interaction</h4>
<ul>
<li>The adsorption energy will in general depend on the presence of
other adsorbates on the surface.</li>
<li>The adsorbate-adsorbate interaction for O atoms on the close-packed
Pt surface is, for example, the repulsion at short distance.</li>
<li>This is typically the case for strongly chemisorbed adsorbates on
metal surfaces.</li>
<li>There can also be attractive interactions between adsorbates.</li>
<li>The attractive/repulsive interaction leads to the formation of
ordered patterns.</li>
</ul>
<h3 id="diffusion">diffusion</h3>
<ul>
<li>It is generally so that diffusion barriers for simple adsorbates on
metal surfaces are not much higher than 0.5 eV. As a result, diffusion
is very fast at temperatures above 300 K where most industrial catalytic
processes take place.</li>
<li>If, however, there are high coverages of adsorbates, such that there
are not free sites available to diffuse into, this picture may
change.</li>
<li>There is a liner relationship between adsorption energy and
diffusion barrier.[Nilekar, AngewChemIntEd, 2006, 45, 7046]</li>
<li>On metal oxide surface or other inorganic compound catalysts, the
distance between adsorption sites are larger than that on the metal
surfaces. Thus the diffusion barriers are often found to be larger.</li>
</ul>
<h3 id="surface-reaction">surface reaction</h3>
<ul>
<li>After the reactants are adsorbed and perhaps dissociated, they will
diffuse and recombine to form new molecules before the product is
desorbed in gas or liquid phase. This kind of chemical event is
categorized in to the surface reaction.</li>
</ul>
<h1 id="theoreticalcomputational-approach-for-reaction-engineering">3.
Theoretical/Computational Approach for Reaction Engineering</h1>
<h2 id="reactor-and-reaction-engineering">3-1. Reactor and Reaction
Engineering</h2>
<ul>
<li>There are several questions that can be put forth about the
operation of reactors and they can be used to form the basis of
classifying and defining ideal conditions that are desireable for the
proper measurements of reaction rates.</li>
<li>The first question is whether the system exchange mass with its
surroundings. If it does not, then the system is called a <strong>batch
reactor</strong>. If it does, then the system is classified as a
<strong>flow reactor</strong>.</li>
<li>The second question involves the exchange of heat between the
reactor and its surroundings. If there is no heat exchange, the reactor
is <strong>adiabatic</strong>. If the reactor makes very good thermal
contact with the surroundings, it can be held at a constant temperature
and is thus <strong>isothermal</strong>.</li>
<li>The third question is that the reactor at constant pressure or
constant volume.</li>
<li>The fourth question is whether time spent in the reactor by each
volume element of fluid is the same. If it is not the same, there may
exist a distribution of residence time, and the opposite extreme of a
unique residence time is an exponential distribution.</li>
<li>The fifth question focuses on a particular fixed volume element in
the reactor and whether it changes as a function of time. If it does
not, then the reactor is said to operate at a stationary state. If there
are time variations, then the reactor is operating under transient
conditions.</li>
</ul>
<h1 id="theoretical-background-of-electrocatalysis">4. Theoretical
Background of Electrocatalysis</h1>
<h3 id="basic">basic</h3>
<ul>
<li><p>The reversible potential, also called equilibrium potential, is a
voltage at which there is no net ion flux.</p></li>
<li><p>The potential difference between the anode and the cathode gives
rise to a variation in the electrostatic potential through the cell.
Since the electrolyte is conducting, there is no electrical field there
and the potential is constant. The potential variation happens in the
so-called dipole layer. They are formed near the two electrodes and sets
up strong electrical fields there. The field is set up by the electrons
in the electrode (or holses for a positive electrode) and the
counterions in the electrolyte.</p></li>
<li><p>We will discuss three? important ways in which elementary surface
electrochemical reactions may differ from their gas-phase
counterparts:</p>
<ol type="1">
<li>The chemical potential of the electrons entering the reaction is
controlled by the potential of the electrode. This is by far the largest
effect. Changing the potential by 1 V changes the reaction free energy
by 1 eV, when one <span class="math inline">e^{-}</span> is involved,
for example.</li>
<li>The surface species will be solvated by the electrolyte. This effect
is notably larger for water due to the hydrogen bonding network.</li>
<li>The electronic field at the solid-electrolyte interface will change
the adsorption energy.</li>
</ol></li>
<li><p>Since the energy of the electron entering is now
potential-dependent, it means that the potential energy diagram becomes
potential-dependent.</p></li>
<li><p>The energy-scaling relationship also holds in the electrochemical
reaction. This means that one can tune the activation energy by shifting
the reaction energy, as <span class="math display">
E_a = \gamma \Delta E + \xi
</span></p></li>
<li><p>Since the reaction energy <span class="math inline">\Delta
E</span> depends on the potential as <span class="math display">
\Delta E = \Delta E (U=0) + eU = \Delta E_0 + eU
</span> the activation energy depends on the potential as <span
class="math display">
E_a(U) = \gamma(\Delta E_0 + eU) + \xi = \gamma eU + E_{a0}
</span> If we neglect variations in the coverage of intermediates with
potential, the rate of elementary step will vary with potential as <span
class="math display">
\begin{split}
r(U) &amp;= \nu \exp(-E_a(U)/k_B T)  \\
   &amp;= \nu \exp(-E_{a0}/k_BT) \exp(-\gamma eU / k_B T) \\
   &amp;= A \exp(-\gamma eU / k_B T)
\end{split}
</span> which is the Tafel equation. A plot of the logarithm of the rate
versus U should give a linear plot, known as the <strong>Tafel
plot</strong>, with slope <span
class="math inline">\gamma</span>.</p></li>
<li><p>One can calculated the <strong>polarization curve</strong>
(current density vs. potential) from the theoretical PED.[Hansen, JPC.C,
2014, 118, 6706]</p></li>
</ul>
<h3 id="example-oerorr">example: OER/ORR</h3>
<ul>
<li><p>Since energy barriers are quite small for proton transfer
reactions and since the barrier scales with the reaction energy, it is
often useful to consider simplified free energy diagrams where only the
energies of intermediates are included.</p></li>
<li><p>The potential dependence of the reaction is easily seen by
showing the variation for the free energy diagram with
potential.</p></li>
<li><p>For all the electrocatalysts, the OER does not start to have an
applicable current density <span class="math inline">j</span> until a
substantial overpotential <span class="math display">
\eta(j) = |U(j) - U_{eq}|
</span> is applied.</p></li>
<li><p>Typically, the best OER catalysts (<span
class="math inline">\ce{RuO2}</span> and <span
class="math inline">\ce{IrO2}</span>) and ORR catalyst (Pt) only give
current densities above <span class="math inline">|j| = 5 mA/cm^2</span>
at potential that are <span class="math inline">|\eta| \approx 0.3
V</span> above or below the equilibrium potential, <span
class="math inline">U_{eq} = 1.23 V</span>.</p></li>
<li><p>The OER/ORR is considered possible if and only if all the
involved reaction steps are neutral or downhill in the Gibbs free
energy. For a given reaction we can determine the lowest potential at
which this is the case. This is the limiting potential.</p></li>
<li><p>If one neglect the barrier, this would be a lower bound to the
overpotential.</p></li>
<li><p>We can write the free energy change for any elementary step <span
class="math inline">i</span> iin an electrochemical reaction with a
transfer of one electron and a proton as <span class="math display">
\Delta G_i(U) = \Delta G_{0,i} \pm eU
</span> where the sign of the last term depends on whether the electron
transfer is from or to the surface.</p></li>
<li><p>We can now define the limiting potential for elementary reaction
step <span class="math inline">i</span> as the potential where the free
energy difference for the reaction is zero: <span class="math display">
U_{L,i} = \frac{\mp\Delta G_{0,i}}{e}
</span></p></li>
<li><p>For the ORR, the electrons are transferred from the surface to
the reactant (thus plus sign). The minimum of the U for the elementary
steps defines the potential where all steps are exergonic, and this
potential is termed the <strong>limiting potential</strong> for the
reaction <span class="math display">
U_{L,red} = \min(U_{L,i})
</span></p></li>
<li><p>We define the theoretical overpotential as <span
class="math display">
\eta_{red} = U_{eq} - U_{L,red}
</span></p></li>
<li><p>For ORR, <span class="math display">
U_{L,ox} = \max(U_{L,i})
</span> and the theoretical overpotential is <span class="math display">
\eta_{ox} = U_{L,ox} - U_{eq}
</span></p></li>
</ul>
<h3 id="nernst-equation">Nernst equation</h3>
<ul>
<li>The relationship between the electrode potential and the activity is
expressed by the <strong>Nernst equation</strong>. For the reaction
<span class="math inline">\ce{aA + bB &lt;=&gt; cC + dD}</span>, <span
class="math display">
\begin{split}
E &amp;= E^0 - \frac{k_B T}{ne}\ln K \\
&amp;= E^0 - \frac{k_B T}{ne}\ln \frac{a_C^c a_D^d}{a_A^a a_B^b}
\end{split}
</span> at standard temperature, <span class="math display">
E = E^0 - \frac{0.059}{n}\log\frac{a_C^c a_D^d}{a_A^a a_B^b}
</span></li>
<li>when the reaction involves proton, <span
class="math inline">E</span> can be expressed as the function of <span
class="math inline">pH</span> by using <span class="math display">
pH = -\log_{10}a_{H^+}
</span></li>
<li>If the electrode potential is raised above the equilibrium
potential, oxidation is preferred, while reduction is preferred if below
the equilibrium potential.</li>
<li>use <span class="math inline">\ln(10) = 2.303</span> to convert
<span class="math inline">\ln</span> to <span
class="math inline">\log</span></li>
</ul>
<h3 id="pourbaix-diagrams">Pourbaix diagrams</h3>
<ul>
<li><p>As shown in Section X, ab initio thermodynamics is able to
evaluate the stability of the surface structure under reaction
conditions as a function of the temperature and the reactant partial
pressure. In electrocatalysis, rather than temperature and pressure, the
pH value and the electrostatic potential (<span
class="math inline">U</span>) are extra variables, and these are
actually more important variables to control the electrochemical
reaction. Thus, the surface phase diagrams depending on these variables
are desirable. In this section, we will see how to construct such
diagram by ab initio method.</p></li>
<li><p>Potential-pH diagrams are usually called <strong>Pourbaix
diagram</strong>, after the name of their originator Marcel Pourbiax
(1904-1998), a Russian-born Belgian chemist. In such diagrams, the redox
potential is plotted on a vertical axis and the pH on a horizontal axis.
Pourbaix diagrams show the most stable bulk phase of an element as
function of pH and potential.</p></li>
<li><p>Water splitting potentials in acid and alkaline electrolytes are
known from cyclic voltammetry. However, the molecular structure of the
surface is not known. It is obvious that the molecular structures on the
surface is dependent on the metal, potential, and pH of the
electrolyte.</p></li>
<li><p>These diagrams constructed from the calculation based on Nernst
equation.</p></li>
<li><p>A horizontal line represents a reaction that does not involve pH:
that is, neither <span class="math inline">\ce{H+}</span> or <span
class="math inline">\ce{OH-}</span> is involved.</p></li>
<li><p>A vertical line involves <span class="math inline">\ce{H+}</span>
or <span class="math inline">\ce{OH-}</span> but not electrons</p></li>
<li><p>A sloping line involve <span class="math inline">\ce{H+}</span>,
<span class="math inline">\ce{OH-}</span>, and electrons.</p></li>
</ul>
<h4 id="e.g.-water-electrolysis">e.g. water electrolysis</h4>
<ul>
<li><p>anode reaction: <span class="math inline">\ce{H2 &lt;=&gt; 2H+ +
2e-}</span></p></li>
<li><p>cathode reaction: <span class="math inline">\ce{1/2O2 + 2H+ + 2e-
&lt;=&gt; H2O}</span> <span class="math display">
\begin{split}
E_1 &amp;= E^0 - 2.303\frac{RT}{zF}\log\frac{1}{[H^+]^2} = - 0.059\times
pH \\
E_2 &amp;= E^0 - 2.303\frac{RT}{zF}\log\frac{1}{[H^+]^2} = 1.229 -
0.059\times pH
\end{split}
</span></p></li>
<li><p>Below the E_1 line, the reduction is preferred in the anode
reaction thus H2 is stable. Above it, H+ is formed.</p></li>
<li><p>Similarly in E_2 line, below it the H2O is stable but above it O2
is generated.</p></li>
<li><p><strong>Surface Pourbaix diagrams</strong> predict the
thermodynamically most stable adsorbed species and thier coverage as a
function of pH and the potential.</p></li>
<li><p>The Pourbaix diagram can be also made for the molecular systems,
which is interpreted as the phase diagram that shows the pH and
potential at which certain molecular species are energetically
stable.</p></li>
</ul>
<h4 id="orr-example">ORR example</h4>
<ul>
<li><p>Hansen et al. have shown that the ab initio surface Pourbaix
diagram is quite useful in analyzing the oxygen reduction reaction (ORR)
by metals such as Ag, Pt, or Ni.[PCCP] <span class="math display">
\ce{O2 + 4H+ + 4e- -&gt; 2H2O}
</span></p></li>
<li><p>Here it is assumed that the surface is in equilibrium with
protons and liquid water at 298 K, so that O and OH may be exchanged
between the surface and a reference electrolyte through the following
steps <span class="math display">
\ce{H2O(l) + $*$ &lt;=&gt; OH$*$ + H+(aq) + e-} \\
\ce{OH$*$ &lt;=&gt; O$*$ + H+(aq) + e-}
</span></p></li>
<li><p>When we assume the computational hydrogen electrode (CHE), the H2
evolution reaction becomes equilibrium at zero pH and zero potential
vs. SHE (<span class="math inline">U_{\rm SHE}</span>); <span
class="math display">
\ce{H+(aq) + e- &lt;=&gt; 1/2H2(g)}
</span></p></li>
<li><p>Using this, the above equations become <span
class="math display">
\ce{H2O(l) + $*$ &lt;=&gt; OH$*$ + 1/2H2(g)} \\
\ce{OH$*$ &lt;=&gt; O$*$ + 1/2H2(g)}
</span></p></li>
<li><p>The Gibbs energy change along the H2 evolution (Eq.X) depends on
pH and potential as <span class="math display">
\Delta G = e U_{\rm SHE} + k_B T \ln10 {\rm pH}
</span></p></li>
<li><p>In this case, adsorption Gibbs energy of OH* is, for example,
<span class="math display">
G(\ce{OH$*$}) = \Delta G_0(\ce{OH$*$}) - e U_{\rm SHE} - k_B T \ln10
{\rm pH}
</span> where <span class="math inline">\Delta G_0</span> is the
reaction Gibbs energy of Eq.X at zero pH and zero <span
class="math inline">U_{\rm SHE}</span>. <span class="math inline">\Delta
G_{\rm field}</span> is the change in the adsorption energy due to the
electric field in the electrochemical double layer. This term can be
neglected.</p></li>
<li><p>Among the terms in Eq.X, one should evaluate <span
class="math inline">\Delta G_0</span> i.e. the Gibbs energy of
adsorption at standard condition. This term can be calculated with ab
initio method, as <span class="math display">
\Delta G_0 = \Delta E + \Delta ZPE - T\Delta S
</span> where <span class="math inline">\Delta E</span> is the total
energy <span class="math inline">\Delta ZPE</span> is the change in
zero-point energy of the adsorbate. The entropy change along the
adsorption <span class="math inline">\Delta S</span> is approximated
from the loss of entropy of the gas phase molecules upon binding them to
the surface.</p></li>
<li><p>Thus, in summary, the Pourbaix diagram for the ORR can be
constructed by ab initio method likewise the ab initio thermodynamics
diagram (Section X). In the Pourbaix diagram case, the variables in the
Gibbs energy of adsorption is <span class="math inline">U_{\rm
SHE}</span> and pH, as seen in Eq.X. We can then construct the diagram
along these two variables.</p></li>
<li><p>We can start from the one-dimensional version of Pourbaix diagram
by fixing pH. See Fig.X, in which the Gibbs energy of O* and OH* on
Ag(111) at pH = 0 are plotted as a function of potential <span
class="math inline">U_{\rm SHE}</span> and pH. The Gibbs energy
dependence on these variables are evaluated by Eq.X. In the plot, the
lowest line determines the surface with the lowest Gibbs energy at a
given potential.</p></li>
<li><p>The usual (or two-dimensional) Pourbaix diagram is readily
plotted by extending this plot by evaluating the Gibbs energy by <span
class="math inline">U_{\rm SHE}</span> and pH; see Fig.X.</p></li>
<li><p>The potential for reversible water oxidation will show up as
lines with a slope of <span class="math inline">-k_B T/e\ln 10</span>
(or <span class="math inline">-0.059*pH (\text{in V, at 298 K})</span>)
in the Pourbaix diagram.</p></li>
<li><p>From this Pourbaix diagram, following features are found;</p>
<ul>
<li>at acidic condition, dissolution of the Ag electrode occurs at <span
class="math inline">U_{\rm SHE} &gt; 0.8\ V</span>.</li>
<li>at moderately acidic condition, water oxidation occurs before the Ag
dissolution.</li>
<li>at basic condition, the substitution of Ag atoms by O atoms are
observed. This can be seen as the onset of the Ag electrode
oxidation.</li>
<li>at pH = 14, water oxidation occurs at <span
class="math inline">U_{\rm SHE} = 0.10\ V</span> (or <span
class="math inline">U_{\rm RHE} = 0.93\ V</span>). This value can be
compared with cyclic voltammogram experiment, as confirmed in their
work.</li>
</ul></li>
<li><p>The difference between the potential vs. SHE (<span
class="math inline">U_{\rm SHE}</span>)or the potential vs. reversible
hydrogen electrode (RHE) (<span class="math inline">U_{\rm RHE}</span>)
is explained in Section X. The RHE easier to use in experiments thus
more often used, and their values are related as follows; <span
class="math display">
U_{\rm RHE} = U_{\rm SHE} + \frac{k_B T}{e} \ln10
</span></p></li>
</ul>
<h1 id="modelling-catalytic-systems">5. Modelling Catalytic Systems</h1>
<h2 id="modeling-heterogeneous-systems">5-1. Modeling Heterogeneous
Systems</h2>
<h3 id="basic-1">basic</h3>
<ul>
<li><p>Facets are usually denoted by their Miller indices. The most
common facets are the most close packed, which for the fcc crystal
structure is the (111) and the slightly more open (100) surface
structure.</p></li>
<li><p>Undercoordinated sites at edges and corners are often
particularly important for catalysis. The same kind of sites is found at
steps on the surface. For the fcc structure, a (211) step is often used
to model undercoordinated sites.</p></li>
<li><p>The PED for elementary surface reactions generally depends
strongly on the surface structure. For example, the CO dissociation on
Ni surface is strongly dependent on the facet.[Andersson, J.Catal.,
2008, 255, 6]</p></li>
<li><p>The number density of surface atoms in the stable planes of
transition metal is the order of <span class="math inline">\approx
10^{15} = (6 \times 10^{23})^{2/3}</span> (CHECK), regardless of crystal
face. This value of surface atom density is a good starting point for
estimating the total number of adsorption sites or active sites on metal
surfaces.</p></li>
<li><p>Perhaps the most common method for measuring the number density
of exposed metal atoms is selective chemisorption of a probe molecule
like <span class="math inline">\ce{H2}</span>, <span
class="math inline">\ce{CO}</span>, or <span
class="math inline">\ce{O2}</span>.</p></li>
</ul>
<h3 id="solid-state-physicschemistry">solid-state physics/chemistry</h3>
<ul>
<li><p>There is no packing of hard spheres in space that creates higher
density than the fcc and hcp structures.</p></li>
<li><p>We defined the shape of the cell that is repeated periodically in
space, the supercell, by lattice vectors <span class="math inline">{\bf
a}_1</span>, <span class="math inline">{\bf a}_2</span>, and <span
class="math inline">{\bf a}_3</span>. If we solve the Schrödinger
equation for this periodic system, the solution must satisfy a
fundamental property known as a <strong>Bloch’s theorem</strong>, which
states that the solution can be expressed as a sum of terms with the
form <span class="math display">
\phi_{\bf k}({\bf r}) = \exp(i{\bf k}\cdot{\bf r}) u_{\bf k}({\bf r})
</span> where <span class="math inline">u_{\bf k}({\bf r})</span> is
periodic in space with the same periodicity as the supercell. That is,
<span class="math inline">u_{\bf k}({\bf r}) = u_{\bf k}({\bf r}+n_1{\bf
a}_1+n_2{\bf a}_2+n_3{\bf a}_3)</span> for anu integers <span
class="math inline">n_1</span>, <span class="math inline">n_2</span>,
and <span class="math inline">n_3</span>.</p></li>
<li><p>Because the functions <span class="math inline">\exp(i{\bf
k}\cdot{\bf r})</span> are called plane waves, calculations based on
this idea are frequently referred to as plane-wave
calculations.</p></li>
<li><p>The space of vectors <span class="math inline">{\bf r}</span> is
called real space, and the space of vectors <span
class="math inline">{\bf k}</span> is called reciprocal space (or
k-space).</p></li>
<li><p>A primitive cell is that it is a cell that is minimal in terms of
volume but still contains all the information we need. We can define a
primitive cell in reciprocal space, and it is called <strong>Brillouin
zone</strong>.</p></li>
<li><p>We need to evaluate <span class="math display">
\bar{g} = \frac{V_{\rm cell}}{(2\pi)^3}\int_{BZ}g({\bf k})d{\bf k}
</span></p></li>
<li><p>The Monkhorst-Pack scheme is often used, in which all that is
needed is to specify how many k-points are to be used in each direction
in reciprocal space. If <span class="math inline">M</span> k-points are
used in each direction, it is usual to label the calculation as using
<span class="math inline">M\times M\times M</span> k-points.</p></li>
<li><p>The symmetries of solid mean that the integrals in k-space do not
need to be evaluated using the entire Brillouin zone. Instead, they can
just be evaluated in a reduced portion of the zone that can ben be
extended without approximation to fill the entire Brillouin zone using
symmetry. This reduced region in k-space is called <strong>irreducible
Brillouin zone</strong>. For very symmetricmaterials such as the perfect
fcc crystal, using just the irreducible Brillouin zone reduced the
numerical effort required to perform integrals in k-space.</p></li>
<li><p>In a metal, the Brillouin zone can be divided into regions that
are occupied and unoccupied by electrons. The surface in k-space that
separates these two regions is called the <strong>Fermi space</strong>.
This is significant complication numerically, because the functions that
ar eintegrated change discontinuously from nonzero values to zero at the
Fermi surface.</p></li>
<li><p>One approach to this is the smearing method. The idea of these
methods is to force the function being integrated to be continuous by
“smearing” out the discontinuity. An example of a smearing function is
the Fermi-Dirac function: <span class="math display">
f\left(\frac{k-k_0}{\sigma}\right) =
\frac{1}{\exp\left[\left(\frac{k-k_0}{\sigma}\right)+1\right]}
</span></p></li>
<li><p>As <span class="math inline">\sigma \rightarrow 0</span>, the
function approaches to a step function. Ideally, the result of the
calculation should be obtained using some method that extrapolates the
final result to the limit where the smearing is eliminated (i.e. <span
class="math inline">\sigma \rightarrow 0</span>).</p></li>
<li><p>One widely used smearing method is <strong>Methfessel-Paxton
method</strong>, in which more complicated smearing functions are
used.</p></li>
</ul>
<h3 id="k-point-tips">k-point tips</h3>
<ul>
<li>Increasing the volume of supercell reduced the number of k-points
needed to achieve convergence, because volume increases in real space
correspond to volume decreases in reciprocal space.</li>
</ul>
<h3 id="cutoff-energy">Cutoff energy</h3>
<ul>
<li>The solution of the Schrödinger equation for supercell have the form
<span class="math display">
\phi_{\bf k}({\bf r}) = \exp(i{\bf k \cdot r})u_{\bf k}({\bf r})
</span> where <span class="math inline">u_{\bf k}({\bf r})</span> is
periodic in shace with the same periodicity as the supercell. The
periodicity of <span class="math inline">u_{\bf k}({\bf r})</span> means
that it can be expanded in terms of a special set of plane waves; <span
class="math display">
u_{\bf k}({\bf r}) = \sum_{\bf G}\exp(i{\bf G \cdot r})
</span> where the summation is all over vectors defined by ${} = m_1{}_1
+ m_2{}_2 + m_3{}_3 $ with integer values for <span
class="math inline">m_i</span>. These set of vectors defined by <span
class="math inline">{\bf G}</span> in reciprocal space are defined so
that any real-space lattice vector <span class="math inline">{\bf
a}_i</span> satisfies <span class="math inline">{\bf G}{\bf a}_i = 2\pi
m_i</span>.</li>
<li>Combining two equation gives <span class="math display">
\phi_{\bf k}({\bf r}) = \sum_{\bf G}c_{\bf k+G}\exp\left[i({\bf
k+G}){\bf r}\right]
</span> This corresponds to the solution of the Schrödinger equation
with kinetic energy <span class="math display">
E = \frac{\hbar^2}{2m}|{\bf k+G}|^2
</span> It is reasonable to expect that solution with lower energies are
more physically important than solutions with high energies. Thus, it is
usual to truncate the infinite sum over <span
class="math inline">G</span> to include only solutions with kinetic
energy less than the <strong>cutoff energy</strong> <span
class="math display">
E_{cut} = \frac{\hbar^2}{2m}G_{cut}^2
</span> The infinite sum then reduced to <span class="math display">
\phi_{\bf k}({\bf r}) = \sum_{{\bf |k+G|}&lt;G_{cut}}c_{\bf
k+G}\exp\left[i({\bf k+G}){\bf r}\right]
</span></li>
</ul>
<h3 id="miller-index">Miller index</h3>
<ul>
<li>Miller indices form a notation system in crystallography for
directions and planes in crystal lattice. Lattice planes are determined
by the three integers <span class="math inline">(h, k, l)</span> also
called Miller indices.</li>
<li>In a cubic lattice, these indices coincide with the inverse
intercepts along the lattice vectors. Thus, <span
class="math inline">(hkl)</span> simply denotes a plane that intercepts
at the three lattice vectors at the points <span
class="math inline">a/h</span>, <span class="math inline">b/k</span>,
and <span class="math inline">c/l</span>. If one of the indices is zero,
the planes are parallel to that axis.</li>
</ul>
<h3 id="miller-index-2">Miller index 2</h3>
<ul>
<li>The orientation of the surface plane can be defined by stating the
direction of a vector normal to the plane.</li>
<li>To decide which of these many vectors to used, it is usual to
specify the points at which the plane intersects the three axes of the
material’s primitive cell or the conventional cell. The reciprocals of
these intercepts are then multiplied by a scaling factor that makes each
reciprocal an integral and also makes each integer as small as possible.
The resulting set of number is called the <strong>Miller index</strong>
of the surface. For example, the plane intersects the z axis of the
conventional cell at 1 (in units of lattice constant) and does not
intersect the x and y axes, the reciprocals of the intersects are
(1/<span class="math inline">infty</span>, 1/<span
class="math inline">infty</span>, 1/1) and thus the surface is denoted
(001).
<ul>
<li>If the vectors defining the surface normal requires a negative sign,
that component of the Miller index is denoted with an overbar.</li>
<li>The plane is usually identified by three indices enclosed in
parentheses (hkl), the vector that is normal to the plane (in cubic
systems) is enclosed in square brackets: [hkl].</li>
</ul></li>
<li>When the plane intercepts the x, y, and z axes at 1, 1, and 1, the
reciprocals of these intercepts are (1/1, 1/1/, 1/1) thus (111) surface.
This surface is an important one because it has the highest possible
density of atoms in the surface layer of any possible Miller index
surface of an fcc material. Surfaces with the highest atom densities for
a particular crystal structure are typically the most stable, and thus
play an important role in real crystal at equilibrium.</li>
<li>Note that, for bcc materials the surface with the highest density of
atoms is the (110) surface.</li>
<li>The low-index surfaces are important in the real world because of
their stability. However, high-index surfaces have important properties
as well. For example, (311) surface has regions with monoatomic steps.
The atoms located at step edges have a lower coordination number than
other atoms in the surface, which often leads to high reactivity. The
step edge atoms play an important role in the catalytic synthesis of
ammonia, for example.</li>
<li>In the hexagonal close-packed (hcp) structure, spheres are arranged
in a single close-packed layer to form a basal plane with each atoms
surrounded by six other atoms. The next layer is added by placing
spheres in alternating threefold hollows of the basal plane. If a third
layer is added such that the sphere s are directly above the spheres in
the basal plane, we obtain the hcp structure. If the third layer atoms
are added in the hollows not directly above the basal plane, the fcc
structure is obtained (<strong>MOVE TO BULK PART?</strong>)</li>
<li>hcp materials have a sixfold symmetry axis normal to the basal
plane. Using a three-axis system to defined the Miller indices for this
structure is unsatisfactory, because some planes with different Miller
index might be equivalent by symmetry.</li>
<li>A solution to this is to use a four axis, four-index system for hcp
solids. The Miller indices are formed as before by taking the
reciprocals of the intercepts of the plane with the four axes. Because
the four axes are not independent, the first three indices will always
sum to zero.</li>
</ul>
<h3 id="slab-model">slab model</h3>
<ul>
<li>If our goal is to study a surface, our ideal model would be a slice
of material that is infinite in two dimensions, but finite along the
surface normal. In order to accomplish this, it may seem natural to take
advantage of periodic boundary conditions in two dimensions, but not the
third.</li>
<li>This is achieved by a slab model. In this model, the empty space has
been left above the atoms in the top portion of the supercell, and the
supercell is repeated in all three dimensions. It defines a series of
stacked slabs of solid material separated by empty spaces.</li>
<li>The empty space separating periodic images of the slab along the
z-direction is called the vacuum space. It is important when using such
a model that there is enough vacuum space so that the electron density
of the material tails off to zero in the vacuum and the top of one slab
has essentially no effect on the bottom of the next.</li>
<li>The number of atoms mimicking the surface layer is arbitrary. So,
how many layers are enough? Typically, more layers are better, but using
more layers also inevitably means using more computational time. The
same thing is true of the vacuum layer thickness. There questions can be
answered by carrying out calculations to see how some property (such as
surface energy or adsorption energy) varies as teh number of layers
increases. The number of layers and the vacuum layers thickness would be
a compromise between computational cost and physical accuracy.</li>
<li>The fact that the long dimension in the supercell includes a vacuum
region leads some computational advantages: The “long” dimension in real
space means the “short” dimension in the reciprocal space. Thus, if the
vacuum region is large enough, the accurate results are possible using
just one k-point in the surface-normal direction. As a result, it is
usual in slab calculations to use an MxNx1 k-point mesh, where M and N
are chosen to adequately sample k^space in the plane of the
surface.</li>
</ul>
<h3 id="surface-relaxation">surface relaxation</h3>
<ul>
<li>It is natural to expect that the spacings between layers near the
surface might be somewhat different from those in the bulk. This
phenomenon is called surface relaxation. Surface relaxation implies that
the relaxed surface has a lower energy than the original surface. We
imagine the bottom of the slab as representing the bulk part of the
material, and constrain the atoms in the bottom layers in their ideal,
bulk positions.</li>
<li>The calculation then involves a minimization of the total energy of
the supercell as a function of the positions of the atoms, with only the
atoms in the top layers are allowed to move.</li>
<li>Often the surface relaxation leads to a decrease in the distance
between the first and second atomic layers.</li>
</ul>
<h3 id="surface-energy">surface energy</h3>
<ul>
<li>The surface energy, <span class="math inline">\sigma</span>, is the
energy needed to cleave the bulk crystal. This quantity can be defined
from a slab calculation using <span class="math display">
\sigma = \frac{1}{A}\left[ E_{slab} - n E_{bulk} \right]
</span> where <span class="math inline">E_{slab}</span> is the total
energy of the slab model for the surface, <span
class="math inline">E_{bulk}</span> is the energy of one atom or formula
unit of the material in the bulk, <span class="math inline">n</span> is
the number of atoms or formula units in the slab model, and <span
class="math inline">A</span> is the total area of the surface in the
slab model.</li>
<li>Surface energy is typically expressed in units of Joules / meters
squared (<span class="math inline">J/m^2</span>) in macroscopically,
while it is expressed as electron volt per angstrom (<span
class="math inline">eV/\r{A}</span>) in calculation (note that $ 1 J/m^2
= 16.02 eV/^2 $)</li>
</ul>
<h3 id="wulff-construction">Wulff construction</h3>
<ul>
<li>The equilibrium shape of finite mesoscopic crystals can be directly
derived from the surface energies by the so-called <strong>Wulff
construction</strong> which is based on the concept that the crystal
seeks to minimize its total surface energy subject to the constraint of
fixed volume.</li>
</ul>
<h3 id="metal-support-interaction">metal-support interaction</h3>
<h3 id="volcano-curve">Volcano curve</h3>
<ul>
<li><p>For the adsorption of reactant, the Bronsted-Evans-Polanyi (BEP)
relationship is well-established for the dissociative adsorption of many
diatomic molecules, such as CO, NO and N2.[Chem.Rev, 110, 2005, 2009;
JCatal, 191, 301, 2000; JCP, 114, 8244, 2001; JCatal, 197, 229, 2001;
JPC.C, 112, 1308 2008]</p></li>
<li><p>This fact means that the barriers of dissociative adsorption are
correlated to the enthalpy change across the periodic table. For
instance, the barrier of CO dissociative adsorption is related to the
stability of C and O; the more stable the C and O are, the lower the
barrier is fo CO dissociative adsorption.</p></li>
<li><p>Regarding the desorption step, the desorption steps of carbon,
nitrogen and oxygen forming CH4, NH3 and H2O on many metal surfaces were
calculated, and a linear relationship was found between the effective
desorption barrier and the enthalpy change.</p></li>
<li><p>In other words, the more stable the intermediate is, the higher
the barrier is for the desorption step.</p></li>
<li><p>Based on the result mention above, a heterogeneous catalytic
reaction can be approximated to be two steps: adsorption and desorption,
the barriers of which are both related to the stability of the key
intermediate.</p></li>
<li><p>Thus, the reaction rate can be represented as a function of
enthalpy change. By solving the kinetic equation of the two-step
model,[JPC.C, 112, 1308 2008] the plot of reaction rate in terms of
turnover frequency (TOF) against enthalpy change is shown in Figure
X.</p></li>
<li><p>If the adsorption step is assumed to be rate-determining, the
green curve in Fig.X will be found between the reaction rate and the
enthalpy change, while the blue curve is obtained when the desorption
step is rate-determining.</p></li>
<li><p>By taking both curves into account, a volcano-shaped curve will
be found between TOF and deltaH.</p></li>
<li><p>For catalysts binding strongly with adsorbates, the enthalpy
change will be too negative, resulting in a high barrier for the
desorption step. Thus, the desorption will be rate-determining, and the
activity of this type of catalysts can be found on the blue curve in
Fig.X</p></li>
<li><p>On the other hand, a low adsorption energy between the surface
and adsorbates will lead to a high barrier for the adsorption step.
Therefore, the adsorption will limit the overall activity, which is the
case on the green curve.</p></li>
<li><p>In summary, based on the BEP relation and the two-step model, a
volcano-shaped curve can be obtained between the stability of key
intermediate and the overall activity of the catalysts.</p></li>
<li><p>A good catalyst should have the proper adsorption energy of key
intermediate.</p></li>
<li><p>Therefore, adsorption energy may be a good indicate for rational
catalyst design.</p></li>
<li><p>The above model assumed that only one reactant and one product
involved in the catalytic reaction. This two-step model is a reasonable
simplification for many reactions in which only one adsorption or
desorption is dominant in the overall activity.</p></li>
<li><p>For example in the NH3 synthesis, the dissociative adsorption on
N2 and the desorption of NH3 are mainly affects the overall
activity.</p></li>
<li><p>However, in some complex surface reaction, more than one
reactants or products affect the overall reaction rate. This leads to
the three-dimensional volcano surface for the catalyst
activity.</p></li>
</ul>
<h3 id="scaling-relationship">Scaling relationship</h3>
<ul>
<li>the presence of linear correlations between adsorption energies of
similar adsorbates, known as <strong>scaling relations</strong>, reduces
the complexity of DFT-based catalytic models and facilitates the
simultaneous analysis of numerous materials through Sabatier-type
activity plots.</li>
</ul>
<h4 id="scaling-among-adsorption-energy">Scaling among adsorption
energy</h4>
<ul>
<li>It is known that adsorption energies of different surface
intermediates that bind to the surface through the same atom scale with
each other. Abild-Pederen et al. have found that, for example, the
scaling relationship of CHn (n = 1, 2, 3) adsorption energy; there is a
linear relationship between the C atom adsorption energy and the CHn
adsorption energy over a number of metal surfaces
(Fig.X).[Abild-Pedersen, PRL, 99, 016105, 2007]</li>
<li>It is evident from the earlier discussion that scaling among
adsorption energies should not be limited to transition metal surfaces.
In fact, even for metal-terminated surfaces of more complex systems like
transition metal compounds (oxides, nitrides, sulfides, and carbides),
where there is mixed covalent, ionic bonding between the surface cations
and anions, there is scaling between electronically similar
adsorbates.[Fernandez, AngewChemIntEd, 47, 4683, 2008]</li>
</ul>
<h4 id="scaling-among-e_a-and-delta-e">Scaling among <span
class="math inline">E_a</span> and <span class="math inline">\Delta
E</span></h4>
<ul>
<li><p>It is not surprising that transition state energies also
correlate with adsorption energies. As for the relationships between
adsorption energies, scaling between adsorption energies and
transition-state energies is extremely important in building an
understanding of heterogeneous catalysis.</p></li>
<li><p>They provide guidance in building kinetic models to understand
trends in catalytic activity.</p></li>
<li><p>Let <span class="math inline">E^{TS}</span> be a set of energies
describing the energy needed to move between two minima on potential
energy surface for a set of different catalysts. Furthermore, let <span
class="math inline">\Delta E_i</span> be a set of adsorption energies,
relevant ofr the process of moving between two minima. We can now define
a functional form of <span class="math inline">E^{TS}(\Delta
E_i)</span>, which is a map from the space of adsorption energies to the
space of transition state energies.</p></li>
<li><p>To first order in <span class="math inline">\Delta E_i</span>,
<span class="math inline">E^{TS}</span> will be give as a linear
combination of <span class="math inline">\Delta E_i</span>: <span
class="math display">
E^{TS} = \sum_i\gamma_i \Delta E_i + \xi
</span></p></li>
<li><p>The set of functions defined above constitute a class of linear
relations - the linear transition state energy scaling
relations.</p></li>
<li><p>The transition-state scaling relations imply the scaling relation
for the activation energy <span class="math inline">E_a</span> of
surface chemical reaction.</p></li>
<li><p>Linear correlations between activation (free) energies and
reaction (free) energies is a well-established approach in the
understanding of trends in chemical relationship that dates back to
Bronstead in 1928 and Evans and Polanyi 10 years later.</p></li>
<li><p>We note that in principle there is a different line for every
surface geometry, sone one should think of a family of transition state
caling lines. For example in the NO dissociation, a large number of
geometries have been investigated, and the lines for the close-packed
and the stepped surface basically define the upper and lower bound to
the scaling lines.</p></li>
<li><p>It turns out that if one compares dissociation of a number of
similar molecules, their transition state energy scale with the
dissociative chemisorption energy in much the same way (Fig.X). This is
a remarkable result indicating that the nature of the relationship
between the transition state and the final state are quite similar among
these molecules.</p></li>
<li><p>The universal relationship for the close-packed surfaces is found
to be <span class="math display">
E^{TS} = (0.90\pm0.04)\Delta E_{\rm diss} + (2.07\pm0.07)\ {\rm eV}
</span> and the relationship for the stepped surface is <span
class="math display">
E^{TS} = (0.87\pm0.05)\Delta E_{\rm diss} + (1.34\pm0.09)\ {\rm eV}
</span></p></li>
<li><p>The slopes of the relations are similar to each other, indicating
the transition states of the reactants considered are final-state
like.</p></li>
<li><p>The intercepts are different, and this difference identifies the
structure dependence of the relationship; the stepped surfaces have
barriers that are much smaller than on the closed-packed
surfaces.[JCatal, 209, 275, 2002]</p></li>
<li><p>Note that there are some exceptions to these scalings, especially
when molecules with weak interatomic bonds are considered suc as in the
dissociation of H2.</p></li>
</ul>
<h3 id="ab-initio-thermodynamics">Ab initio thermodynamics</h3>
<ul>
<li><p>Ab initio atomistic simulations are, under the Born-Oppenheimer
approximation, useful tool to evaluate the total energy (i.e. electronic
plus nuclear repulsion) from atomic configurations. This total energy
is, however, a zero-temperature and zero-pressure quantity. Since
catalytic reactions often take place at high-temperature and/or
high-pressure condition, this temperature or pressure gap should be
filled somehow. This is indeed possible, when the thermodynamic
potentials like Gibbs free energies are evaluated from ab initio
atomistic simulations.</p></li>
<li><p>In this section, such approach called <strong>ab initio
(atomistic) thermodynamics (AITD)</strong> is introduced.</p></li>
<li><p>Under the condition of fixed temperature <span
class="math inline">T</span> and pressure <span
class="math inline">p</span>, the appropriate thermodynamics potential
to consider is the Gibbs free energy <span
class="math inline">G(T,p)</span>.</p></li>
<li><p>The oxidation of metal <span class="math inline">M</span> surface
is considered as an example here, because it is one of the most common
application of the AITD technique.</p></li>
<li><p>The stability of a particular surface is given by its surface
free energy per unit area <span class="math display">
\gamma = \frac{1}{A}\left[ G(T, p_i, N_{\rm M}, N_{\rm O}) - N_{\rm
M}g_{\rm M}(T, p) - N_{\rm O} \mu_{\rm O}(T, p) \right]
</span> where <span class="math inline">\mu_{\rm O}</span> is the
chemical potential of O atom. The number of metal and O atoms are
denoted as <span class="math inline">N_{\rm M}</span> and <span
class="math inline">N_{\rm O}</span>, respectively.<span
class="math inline">g_{\rm M}</span> is the Gibbs free energy per metal
atom, which can be replaced by the total energy of bulk or surface
divided by <span class="math inline">N_{\rm M}</span>.</p></li>
<li><p>When discussing the stability of phases that result from
adsorbing species at surface, it is convenient to choose some reference
surface. One can introduce the surface free energy of the clean surface
as <span class="math display">
\gamma^{\rm clean}(T,p) = \frac{1}{A}\left[G(T,p,0,N_{M}^{\rm
clean})-N_{\rm M}^{\rm clean}E_{\rm M}^{\rm total}\right]
</span> and the Gibbs free energy of adsorption can be measured from the
clean surface as <span class="math display">
\begin{align*}
\Delta G^{\rm ad}(T,p)
&amp;= \gamma(T,p,N_{\rm O},N_{\rm M}) - \gamma(T,p,0,N_{\rm M}^{\rm
clean}) \\
&amp;= \frac{1}{A}[ G(T,p,N_{\rm O},N_{\rm M}) - G(T,p,0,N_{\rm M}^{\rm
clean}) \\
&amp;- N_{\rm O}\mu_{\rm O}(T,p) - (N_{\rm M}-N_{\rm M}^{\rm
clean})E_{\rm M}^{\rm total} ]
\end{align*}
</span></p></li>
<li><p>The last term arises only when clean and adsorbed surfaces have
different number of metal atoms.</p></li>
<li><p>We are interested in describing the thermodynamic stability of a
metal, M, in equilibrium with gas-phase <span
class="math inline">\ce{O2}</span> at pressure <span
class="math inline">P_{\ce{O2}}</span> and temperature <span
class="math inline">T</span>. We assume that we already know a series of
candidate crystal structures for the metal and its oxide. As an example,
we will examine the copper and copper oxide surfaces, and thus crystal
structures of <span class="math inline">\ce{Cu}</span> and <span
class="math inline">\ce{Cu2O}</span> are assumed to be known from
experiments.</p></li>
<li><p>Thermodynamically, we would like to know which material minimizes
the free energy of a system containing gaseous <span
class="math inline">\ce{O2}</span> and a solid at the specified
conditions. A useful way to do this is to define the grand (canonical?)
potential associated with each crystal structure. The grand potential
for a metal oxide containing <span class="math inline">N_M</span> metal
atoms and <span class="math inline">N_O</span> oxygen atoms is defined
by <span class="math display">
\Omega(T, \mu_O, \mu_M) = E(N_M, N_O) - TS - \mu_O N_O - \mu_M N_M
</span> where <span class="math inline">E</span> is the internal energy
of the metal oxide, <span class="math inline">S</span> is the material’s
entropy, and <span class="math inline">\mu_X</span> is the chemical
potential of atomic species <span class="math inline">X</span>.</p></li>
<li><p>If we have a series of different materials (<span
class="math inline">i = 1, 2, \cdots</span>), then we can use this
expression to define the grand potential of each material, <span
class="math inline">\Omega_i</span>.</p></li>
<li><p>We can interpret the internal energy in the grand potential as
simply the total energy from a DFT calculation for the
material.</p></li>
<li><p>It is then sensible to compare the grand potentials of the
different materials by normalizing the DFT energies so that every DFT
calculation describes a material with the same number of metals atoms.
If we do this, <span class="math inline">\Omega_i</span> can be
rewritten as <span class="math display">
\Omega_i(T, \mu_O) = E_i - TS_i - \mu_O N_{O,i} - \Omega^M
</span> where <span class="math inline">\Omega^M</span> is an additive
constant that is the same for every material.</p></li>
<li><p>For ideal gases, the chemical potential can be rigorously derived
from statistical mechanism. A useful definition of the chemical
potential for <span class="math inline">\ce{O2}</span> is <span
class="math display">
\mu_{\ce{O2}} = E_{\ce{O2}}^{\rm total} + E_{\ce{O2}}^{\rm ZPE} + \Delta
\mu_{\ce{O2}}(T, P^o) + kT\ln(P/P^o)
</span> Here, <span class="math inline">E_{\ce{O2}}^{\rm total}</span>
and <span class="math inline">E_{\ce{O2}}^{\rm ZPE}</span> are the total
energy of an isolated <span class="math inline">\ce{O2}</span> molecule
at T = 0 K and the zero-point energy (O2). We can obtain them from a
simple DFT calculation.</p></li>
<li><p><span class="math inline">\tilde{\mu_{\ce{O2}}}</span> is the
difference in the chemical potential of <span
class="math inline">\ce{O2}</span> between T = 0 K and the temperature
of interest (at the reference pressure). This chemical potential
difference (and also ZPEs) for standard gases species are tabulated in
the <em>NIST-JANAF Thermodynamical Tables</em>.</p></li>
<li><p>Now we have derived the chemical potential of oxygen molecule.
Since the chemical potential of molecular oxygen and atomic oxygen are
related by <span class="math display">
\mu_{\ce{O}} = \frac{1}{2}\mu_{\ce{O2}}
</span> , we can calculated <span class="math inline">\mu_{O}</span> as
<span class="math display">
\mu_O(T, p) = \frac{1}{2}E_{\ce{O2}}^{\rm total} +
\frac{1}{2}E_{\ce{O2}}^{\rm ZPE} + \Delta \mu_O(T) + \frac{1}{2}k_B T
\ln\left(\frac{p}{p^0}\right)
</span></p></li>
</ul>
<h4 id="pd100-case">Pd(100) case</h4>
<ul>
<li>The Gibbs free energy change by adsorption is <span
class="math display">
\begin{align*}
\Delta G^{\rm ad}(T, p) &amp;= \frac{1}{A}[ E^{\rm total}(N_{\rm O},
N_{\rm M}) - E^{\rm total}(0, N_{\rm M}^{\rm clean}) \\
&amp;-(N_{\rm M}-N_{\rm M}^{\rm clean})E_{\rm M}^{\rm total}
-\frac{N_{\rm O}}{2}E_{\ce{O2}}^{\rm total}
-N_{\rm O}\Delta\mu_{\rm O}(T, p) ]
\end{align*}
</span></li>
<li>This above equation allows to directly plot the Gibbs free energy of
adsorption for each surface model as a function of <span
class="math inline">\Delta \mu_{\rm O}</span>; see Figure X.</li>
<li>This yields a straight line for each model, and at any given <span
class="math inline">\Delta \mu_{\rm O}</span> the model with the lowest
lying line is identified as the most stable as it has the lowest <span
class="math inline">\Delta G^{\rm ad}</span>.</li>
<li>If one concentrate only on the most stable structures, it is
possible to convert range of chemical potential into (T, p) ranges, and
plot these stability ranges in surface phase diagram (Fig.X)</li>
</ul>
<h4 id="ag">Ag</h4>
<ul>
<li>A good application of the ab initio thermodynamics to catalysis is
the ethylene epoxidation by Ag. Ag is a well-known commercial catalyst
for epoxidation of ethylene, where the reaction takes place with an
<span class="math inline">\ce{O2}</span> pressure of approximately
atmospheric pressure and temperature of 200-300 <span
class="math inline">^oC</span>.</li>
<li>If the reaction is attempted using clean Ag under ultra-high-vacuum
conditions, the surface is found to be effectively inactive as a
catalyst. Therefore, the surface of active Ag catalyst under industrial
conditions is not mettalics Ag.</li>
<li>An example of theoretical phase diagram for oxygen interacting with
the Ag(111) surface was given by Li, Stampfk, and Scheffler.[Ref]</li>
<li>It can be seen from Fig.X that, at most temperatures, there is a
range of pressures spanning several orders of magnitude for which the
surface oxide structure is more stable than either the bulk oxide or the
clean metal surface.</li>
<li>This phase diagram strongly suggests that the working catalyst under
industrial conditions is a surface oxide rather than bare Ag.</li>
</ul>
<h4 id="two-dimensional-1">two-dimensional</h4>
<ul>
<li>As a matter of fact, the AITD technique is not limited to the
oxidation of metal surface. Moreover, one can extend above formulation
when gas phase has two components.</li>
<li>One good example for this is the CO oxidation reaction on RuO2(110)
surface studies by Reuter and Scheffler.[PRL, 90, 046103, 2003] In this
case, CO and O2 are present in gas phase and CO oxidation to CO2 take
place with the surface reaction since gas-phase CO oxidation is quite
slow. CO molecule and O atom (as a result of O2 dissociative adsorption)
may take several adsorption positions on the RuO2(110) surface, while in
this case two Ru sites (Ru bridge, <span class="math inline">{\rm
Ru_{br}}</span> or Ru coordinatively unsaturated site <span
class="math inline">{\rm Ru_{cus}}</span>) are possible.</li>
<li>To identify thermodynamically stable surfaces, AITD diagram would be
helpful. Since the surface energy of RuO2-CO-O system is calculated
likewise the Eq.X as follows; <span class="math display">
\begin{align*}
\gamma(T, p_{\ce{CO}}, p_{\ce{O2}}) =
&amp; \frac{1}{A}[G(T, p_{\ce{CO}}, p_{\ce{O2}})-G_{\rm clean}(T) \\
&amp;-N_{\rm CO}\mu_{\rm CO}(T, p_{\ce{CO}})-N_{\rm O}\mu_{\rm O}(T,
p_{\ce{O2}})]
\end{align*}
</span></li>
<li>The AITD diagram in this case should be three-dimensional (<span
class="math inline">\mu_{\rm CO}, \mu_{\rm O}, \gamma</span>) but when
only the lowest-energy surface structures are plotted it becomes a
two-dimensional plot; see Fig.X for the result.</li>
<li>In the figure, four stable surface structures (<span
class="math inline">{\rm O^{br}/-}</span>, <span
class="math inline">{\rm O^{br}/O^{cus}}</span>, <span
class="math inline">{\rm O^{br}/CO^{cus}}</span>, <span
class="math inline">{\rm CO^{br}/CO^{cus}}</span>) are shown. Among
them, <span class="math inline">{\rm O^{br}/CO^{cus}}</span> surface is
directly related to the function for the catalytic CO oxidation on RuO2
surface, because both CO and O are co-exist in the proximity on the
surface. On the other hand, other three cases the surface is covered
with only one reactant or adsorption of CO is weak (<span
class="math inline">{\rm O^{br}/-}</span>). Therefore, we can expect the
higher catalytic activity for CO oxidation in <span
class="math inline">(\mu_{\rm CO}, \mu_{\rm O})</span> regions
corresponding to <span class="math inline">{\rm
O^{br}/CO^{cus}}</span>.</li>
</ul>
<h2 id="modeling-homogeneous-systems">5-2. Modeling Homogeneous
Systems</h2>
<h3 id="solution">solution</h3>
<h2 id="comparing-experiment-and-computational-results">5-3. Comparing
Experiment and Computational Results</h2>
<h4 id="tpd">TPD</h4>
<ul>
<li>Temperature-programmed desorption (TPD)</li>
<li>TPD spectrum can be simulated with microkinetic analysis, by using
the first-order Polanyi-Wigner equation <span class="math display">
r(t) = \frac{d\theta}{dt} = \nu\theta\exp\left(-\frac{G_a}{RT}\right)
</span> where <span class="math inline">r(t), \theta, \nu, G_a</span>
are the reaction (desorption) rate at time <span
class="math inline">t</span>, surface coverage, pre-exponential factor,
and desorption free energy.</li>
</ul>
<h1 id="computational-tools-for-catalytic-chemistry">6. Computational
Tools for Catalytic Chemistry</h1>
<h2 id="tools-in-electronic-structure-theory">6-1. Tools in Electronic
Structure Theory</h2>
<h3 id="vasp">VASP</h3>
<h3 id="gaussian">Gaussian</h3>
<h2 id="tools-in-chemical-kinetics">6-2. Tools in Chemical Kinetics</h2>
<h3 id="chemkin">Chemkin</h3>
<h2 id="tools-in-chemical-engineering">6-3. Tools in Chemical
Engineering</h2>
<h3 id="comsol">COMSOL</h3>
<h3 id="openfoam">OpenFOAM</h3>
<h3 id="ansys">ANSYS</h3>                    
                </div>
            </div>
            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
